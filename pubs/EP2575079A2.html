<!doctype html>
<html lang="en">
  <head>
    <title>EP2575079A2 - Method and apparatus for processing images 
        - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/EP2575079A2/en">
    <meta name="description" content="
     A method and apparatus for processing images. A sequence of images for a scene is received from an imaging system. An object in the scene is detected using the sequence of images. A viewpoint of the imaging system is registered to a model of the scene using a region in the model of the scene in which an expected behavior of the object is expected to occur.
 
   
   ">
    
    <meta name="DC.type" content="patent">
    
    <meta name="DC.title" content="Method and apparatus for processing images 
       ">
    
    <meta name="DC.date" content="2012-09-27" scheme="dateSubmitted">
    
    <meta name="DC.description" content="
     A method and apparatus for processing images. A sequence of images for a scene is received from an imaging system. An object in the scene is detected using the sequence of images. A viewpoint of the imaging system is registered to a model of the scene using a region in the model of the scene in which an expected behavior of the object is expected to occur.
 
   
   ">
    
    <meta name="citation_patent_application_number" content="EP:12186437A">
    
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/70/7c/08/ffafe6ab3df707/EP2575079A2.pdf">
    
    <meta name="citation_patent_publication_number" content="EP:2575079:A2">
    
    <meta name="DC.date" content="2013-04-03">
    
    <meta name="DC.contributor" content="Yuri Owechko" scheme="inventor">
    
    <meta name="DC.contributor" content="Shinko Y. Cheng" scheme="inventor">
    
    <meta name="DC.contributor" content="Kyungnam Kim" scheme="inventor">
    
    <meta name="DC.contributor" content="Boeing Co" scheme="assignee">
    
    <meta name="citation_reference" content="None" scheme="references">
    
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <style>
      body { transition: none; }
    </style>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-27188110-4', 'auto');

      version = 'patent-search.search_20191120_RC00';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.profilePicture = "https:\/\/lh4.googleusercontent.com\/-jksfid8w7L8\/AAAAAAAAAAI\/AAAAAAAAAAA\/4nKKEmF_j5w\/s32-c-mo\/p.png?sourceid=navclient";

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.html">
    
  </head>
  <body unresolved>
    
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.js"></script>
    
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">EP2575079A2 - Method and apparatus for processing images 
        - Google Patents</h1>
  <span itemprop="title">Method and apparatus for processing images 
       </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/70/7c/08/ffafe6ab3df707/EP2575079A2.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">EP2575079A2</dd>
    <meta itemprop="numberWithoutCodes" content="2575079">
    <meta itemprop="kindCode" content="A2">
    <meta itemprop="publicationDescription" content="Publication of application without search report">
    
    <span>EP2575079A2</span>
    
    <span>EP12186437A</span>
    
    <span>EP12186437A</span>
    
    <span>EP2575079A2</span>
    
    <span>EP 2575079 A2</span>
    
    <span>EP2575079 A2</span>
    
    <span>EP 2575079A2</span>
    
    <span>EP 12186437 A</span>
    
    <span>EP12186437 A</span>
    
    <span>EP 12186437A</span>
    
    <span>EP 12186437 A</span>
    
    <span>EP12186437 A</span>
    
    <span>EP 12186437A</span>
    
    <span>EP 2575079 A2</span>
    
    <span>EP2575079 A2</span>
    
    <span>EP 2575079A2</span>
    

    <dt>Authority</dt>
    <dd itemprop="countryCode">EP</dd>
    <dd itemprop="countryName">European Patent Office</dd>

    <dt>Prior art keywords</dt>
    
    <dd itemprop="priorArtKeywords" repeat>scene</dd>
    <dd itemprop="priorArtKeywords" repeat>imaging system</dd>
    <dd itemprop="priorArtKeywords" repeat>images</dd>
    <dd itemprop="priorArtKeywords" repeat>object</dd>
    <dd itemprop="priorArtKeywords" repeat>model</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2011-09-29">2011-09-29</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Pending</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">EP12186437A</dd>

  <dt>Other languages</dt>
  <dd itemprop="otherLanguages" itemscope repeat>
    <a href="/patent/EP2575079A2/de">
      <span itemprop="name">German</span> (<span itemprop="code">de</span>)
    </a>
  </dd><dd itemprop="otherLanguages" itemscope repeat>
    <a href="/patent/EP2575079A2/fr">
      <span itemprop="name">French</span> (<span itemprop="code">fr</span>)
    </a>
  </dd>

  <dt>Other versions</dt>
  <dd itemprop="directAssociations" itemscope repeat>
    
    <a href="/patent/EP2575079A3/en">
      <span itemprop="publicationNumber">EP2575079A3</span>
      (<span itemprop="primaryLanguage">en</span>
    </a>
  </dd>

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>Yuri Owechko</dd>
  <dd itemprop="inventor" repeat>Shinko Y. Cheng</dd>
  <dd itemprop="inventor" repeat>Kyungnam Kim</dd>
  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    Boeing Co
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>Boeing Co</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2011-09-29">2011-09-29</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2012-09-27">2012-09-27</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2013-04-03">2013-04-03</time></dd>

  

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2011-09-29">2011-09-29</time>
    <span itemprop="title">Priority to US13/249,064</span>
    <span itemprop="type">priority</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US8891820B2/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2012-09-27">2012-09-27</time>
    <span itemprop="title">Application filed by Boeing Co</span>
    <span itemprop="type">filed</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    <span itemprop="assigneeSearch">Boeing Co</span>
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2013-04-03">2013-04-03</time>
    <span itemprop="title">Publication of EP2575079A2</span>
    <span itemprop="type">publication</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/EP2575079A2/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2014-12-24">2014-12-24</time>
    <span itemprop="title">Publication of EP2575079A3</span>
    <span itemprop="type">publication</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/EP2575079A3/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2019-12-14">2019-12-14</time>
    <span itemprop="title">Application status is Pending</span>
    <span itemprop="type">legal-status</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  

  <h2>Links</h2>

  <ul>
    

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="http://worldwide.espacenet.com/publicationDetails/biblio?CC=EP&amp;NR=2575079A2&amp;KC=A2&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="gpiLink">
          <a href="https://data.epo.org/gpi/EP2575079A2" itemprop="url" target="_blank"><span itemprop="text">EPO GPI</span></a>
        </li>
      

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="epRegisterLink">
        <a href="https://register.epo.org/espacenet/application?number=EP12186437" itemprop="url" target="_blank"><span itemprop="text">EP Register</span></a>
      </li>

    
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="globalDossierLink">
          <a href="http://globaldossier.uspto.gov/#/result/publication/EP/2575079/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
        </li>

      

      

      

      
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="stackexchangeLink">
          <a href="https://patents.stackexchange.com/questions/tagged/EP2575079A2" itemprop="url"><span itemprop="text">Discuss</span></a>
        </li>
  </ul>

  
  <ul itemprop="concept" itemscope>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003384</span>
      <span itemprop="name">imaging method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">252</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000002245</span>
      <span itemprop="name">particles</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">10</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">58</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003860</span>
      <span itemprop="name">storage</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">34</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000006399</span>
      <span itemprop="name">behavior</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">28</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009826</span>
      <span itemprop="name">distribution</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">27</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004422</span>
      <span itemprop="name">calculation algorithm</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">23</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000002609</span>
      <span itemprop="name">media</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">20</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000015654</span>
      <span itemprop="name">memory</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">14</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002085</span>
      <span itemprop="name">persistent</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">13</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009833</span>
      <span itemprop="name">condensation</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">9</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000875</span>
      <span itemprop="name">corresponding</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">5</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007514</span>
      <span itemprop="name">turning</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">5</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000004744</span>
      <span itemprop="name">fabric</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">4</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003287</span>
      <span itemprop="name">optical</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">4</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003331</span>
      <span itemprop="name">infrared imaging</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005070</span>
      <span itemprop="name">sampling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001721</span>
      <span itemprop="name">combination</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004891</span>
      <span itemprop="name">communication</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001186</span>
      <span itemprop="name">cumulative</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009963</span>
      <span itemprop="name">fulling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006011</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001931</span>
      <span itemprop="name">thermography</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001131</span>
      <span itemprop="name">transforming</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">210000003813</span>
      <span itemprop="name">Thumb</span>
      <span itemprop="domain">Anatomy</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000003086</span>
      <span itemprop="name">colorant</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004590</span>
      <span itemprop="name">computer program</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000011162</span>
      <span itemprop="name">core materials</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000694</span>
      <span itemprop="name">effects</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000003365</span>
      <span itemprop="name">glass fiber</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001976</span>
      <span itemprop="name">improved</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000644</span>
      <span itemprop="name">propagated</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004044</span>
      <span itemprop="name">response</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000004065</span>
      <span itemprop="name">semiconductor</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
  </ul>
  

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/f3/3f/98/f3ad5847aac231/imgf0001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ad/e8/48/0ea88b5e396995/imgf0001.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="102">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="445">
              <meta itemprop="top" content="182">
              <meta itemprop="right" content="493">
              <meta itemprop="bottom" content="256">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="data processing system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1287">
              <meta itemprop="top" content="2330">
              <meta itemprop="right" content="1333">
              <meta itemprop="bottom" content="2405">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="108">
            <meta itemprop="label" content="roads">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1569">
              <meta itemprop="top" content="2036">
              <meta itemprop="right" content="1618">
              <meta itemprop="bottom" content="2113">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="110">
            <meta itemprop="label" content="sidewalks">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1574">
              <meta itemprop="top" content="1842">
              <meta itemprop="right" content="1629">
              <meta itemprop="bottom" content="1924">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="112">
            <meta itemprop="label" content="trees">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1669">
              <meta itemprop="top" content="1578">
              <meta itemprop="right" content="1718">
              <meta itemprop="bottom" content="1653">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="120">
            <meta itemprop="label" content="pedestrian">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1286">
              <meta itemprop="top" content="1869">
              <meta itemprop="right" content="1354">
              <meta itemprop="bottom" content="1937">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="124">
            <meta itemprop="label" content="sidewalk">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1491">
              <meta itemprop="top" content="2096">
              <meta itemprop="right" content="1542">
              <meta itemprop="bottom" content="2176">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="126">
            <meta itemprop="label" content="Pedestrian">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1058">
              <meta itemprop="top" content="1252">
              <meta itemprop="right" content="1137">
              <meta itemprop="bottom" content="1339">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="128">
            <meta itemprop="label" content="road">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1192">
              <meta itemprop="top" content="1222">
              <meta itemprop="right" content="1243">
              <meta itemprop="bottom" content="1298">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="130">
            <meta itemprop="label" content="intersection">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="996">
              <meta itemprop="top" content="1150">
              <meta itemprop="right" content="1043">
              <meta itemprop="bottom" content="1226">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="132">
            <meta itemprop="label" content="vehicle">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1020">
              <meta itemprop="top" content="1030">
              <meta itemprop="right" content="1071">
              <meta itemprop="bottom" content="1116">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="140">
            <meta itemprop="label" content="imaging systems">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="689">
              <meta itemprop="top" content="1989">
              <meta itemprop="right" content="737">
              <meta itemprop="bottom" content="2061">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="142">
            <meta itemprop="label" content="aerial vehicle">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="481">
              <meta itemprop="top" content="2035">
              <meta itemprop="right" content="533">
              <meta itemprop="bottom" content="2120">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="144">
            <meta itemprop="label" content="imaging systems">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="362">
              <meta itemprop="top" content="488">
              <meta itemprop="right" content="409">
              <meta itemprop="bottom" content="565">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="146">
            <meta itemprop="label" content="aerial vehicle">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="149">
              <meta itemprop="top" content="530">
              <meta itemprop="right" content="198">
              <meta itemprop="bottom" content="604">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="148">
            <meta itemprop="label" content="imaging systems">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1166">
              <meta itemprop="top" content="1837">
              <meta itemprop="right" content="1217">
              <meta itemprop="bottom" content="1958">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="150">
            <meta itemprop="label" content="robotic ground vehicle">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1268">
              <meta itemprop="top" content="1958">
              <meta itemprop="right" content="1341">
              <meta itemprop="bottom" content="2059">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="158">
            <meta itemprop="label" content="wireless communications links">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="493">
              <meta itemprop="top" content="700">
              <meta itemprop="right" content="539">
              <meta itemprop="bottom" content="785">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/71/9d/4e/4c65b6285e6ad7/imgf0002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/18/49/dd/1b758631a5fdd3/imgf0002.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="200">
            <meta itemprop="label" content="data processing system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="119">
              <meta itemprop="top" content="529">
              <meta itemprop="right" content="222">
              <meta itemprop="bottom" content="582">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="202">
            <meta itemprop="label" content="sensor data">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="374">
              <meta itemprop="top" content="1496">
              <meta itemprop="right" content="464">
              <meta itemprop="bottom" content="1548">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="204">
            <meta itemprop="label" content="sensor systems">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="163">
              <meta itemprop="top" content="656">
              <meta itemprop="right" content="257">
              <meta itemprop="bottom" content="708">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="206">
            <meta itemprop="label" content="data processing module">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="184">
              <meta itemprop="top" content="2488">
              <meta itemprop="right" content="276">
              <meta itemprop="bottom" content="2540">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="208">
            <meta itemprop="label" content="first sensor system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="204">
              <meta itemprop="top" content="781">
              <meta itemprop="right" content="299">
              <meta itemprop="bottom" content="833">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="210">
            <meta itemprop="label" content="second sensor system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1091">
              <meta itemprop="top" content="783">
              <meta itemprop="right" content="1192">
              <meta itemprop="bottom" content="835">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="212">
            <meta itemprop="label" content="imaging system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="242">
              <meta itemprop="top" content="977">
              <meta itemprop="right" content="339">
              <meta itemprop="bottom" content="1031">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="214">
            <meta itemprop="label" content="second imaging system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1072">
              <meta itemprop="top" content="979">
              <meta itemprop="right" content="1149">
              <meta itemprop="bottom" content="1030">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="216">
            <meta itemprop="label" content="imaging data">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="373">
              <meta itemprop="top" content="1620">
              <meta itemprop="right" content="469">
              <meta itemprop="bottom" content="1674">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="218">
            <meta itemprop="label" content="images">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="427">
              <meta itemprop="top" content="1766">
              <meta itemprop="right" content="531">
              <meta itemprop="bottom" content="1815">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="220">
            <meta itemprop="label" content="images">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="885">
              <meta itemprop="top" content="1769">
              <meta itemprop="right" content="955">
              <meta itemprop="bottom" content="1817">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="222">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1197">
              <meta itemprop="top" content="70">
              <meta itemprop="right" content="1290">
              <meta itemprop="bottom" content="122">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="223">
            <meta itemprop="label" content="objects">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1192">
              <meta itemprop="top" content="204">
              <meta itemprop="right" content="1280">
              <meta itemprop="bottom" content="259">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="224">
            <meta itemprop="label" content="communications links">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="643">
              <meta itemprop="top" content="2251">
              <meta itemprop="right" content="740">
              <meta itemprop="bottom" content="2304">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="225">
            <meta itemprop="label" content="object">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1169">
              <meta itemprop="top" content="428">
              <meta itemprop="right" content="1258">
              <meta itemprop="bottom" content="479">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="226">
            <meta itemprop="label" content="computer system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="171">
              <meta itemprop="top" content="2259">
              <meta itemprop="right" content="263">
              <meta itemprop="bottom" content="2310">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="227">
            <meta itemprop="label" content="viewpoint">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="260">
              <meta itemprop="top" content="1166">
              <meta itemprop="right" content="355">
              <meta itemprop="bottom" content="1219">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="229">
            <meta itemprop="label" content="viewpoint">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1050">
              <meta itemprop="top" content="1167">
              <meta itemprop="right" content="1123">
              <meta itemprop="bottom" content="1219">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/ee/29/11/09ef2b43769407/imgf0003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/eb/bc/ee/e4e955ec4a8631/imgf0003.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="202">
            <meta itemprop="label" content="sensor data">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="208">
              <meta itemprop="top" content="2494">
              <meta itemprop="right" content="310">
              <meta itemprop="bottom" content="2596">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="216">
            <meta itemprop="label" content="imaging data">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="481">
              <meta itemprop="top" content="1958">
              <meta itemprop="right" content="533">
              <meta itemprop="bottom" content="2036">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="218">
            <meta itemprop="label" content="images">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="555">
              <meta itemprop="top" content="2463">
              <meta itemprop="right" content="608">
              <meta itemprop="bottom" content="2548">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="220">
            <meta itemprop="label" content="images">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="834">
              <meta itemprop="top" content="2463">
              <meta itemprop="right" content="886">
              <meta itemprop="bottom" content="2547">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="304">
            <meta itemprop="label" content="registration module">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="384">
              <meta itemprop="top" content="962">
              <meta itemprop="right" content="435">
              <meta itemprop="bottom" content="1045">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="306">
            <meta itemprop="label" content="fusion module">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1704">
              <meta itemprop="top" content="966">
              <meta itemprop="right" content="1756">
              <meta itemprop="bottom" content="1037">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="308">
            <meta itemprop="label" content="projection module">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1494">
              <meta itemprop="top" content="1853">
              <meta itemprop="right" content="1544">
              <meta itemprop="bottom" content="1934">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="313">
            <meta itemprop="label" content="types">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="320">
              <meta itemprop="top" content="1654">
              <meta itemprop="right" content="373">
              <meta itemprop="bottom" content="1740">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="314">
            <meta itemprop="label" content="detections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="588">
              <meta itemprop="top" content="1225">
              <meta itemprop="right" content="641">
              <meta itemprop="bottom" content="1311">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="315">
            <meta itemprop="label" content="types">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="719">
              <meta itemprop="top" content="1655">
              <meta itemprop="right" content="772">
              <meta itemprop="bottom" content="1741">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="320">
            <meta itemprop="label" content="tracks">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1136">
              <meta itemprop="top" content="1522">
              <meta itemprop="right" content="1189">
              <meta itemprop="bottom" content="1602">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="322">
            <meta itemprop="label" content="tracks">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1098">
              <meta itemprop="top" content="1259">
              <meta itemprop="right" content="1151">
              <meta itemprop="bottom" content="1343">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="324">
            <meta itemprop="label" content="model">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="464">
              <meta itemprop="top" content="471">
              <meta itemprop="right" content="527">
              <meta itemprop="bottom" content="541">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="333">
            <meta itemprop="label" content="state estimation algorithm">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="442">
              <meta itemprop="top" content="575">
              <meta itemprop="right" content="509">
              <meta itemprop="bottom" content="669">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="334">
            <meta itemprop="label" content="projections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1178">
              <meta itemprop="top" content="433">
              <meta itemprop="right" content="1231">
              <meta itemprop="bottom" content="506">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="336">
            <meta itemprop="label" content="projections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1275">
              <meta itemprop="top" content="477">
              <meta itemprop="right" content="1321">
              <meta itemprop="bottom" content="560">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="340">
            <meta itemprop="label" content="projection pair">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1562">
              <meta itemprop="top" content="87">
              <meta itemprop="right" content="1619">
              <meta itemprop="bottom" content="177">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="342">
            <meta itemprop="label" content="threshold">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1667">
              <meta itemprop="top" content="84">
              <meta itemprop="right" content="1726">
              <meta itemprop="bottom" content="176">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="344">
            <meta itemprop="label" content="final projections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1775">
              <meta itemprop="top" content="88">
              <meta itemprop="right" content="1831">
              <meta itemprop="bottom" content="185">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="346">
            <meta itemprop="label" content="Inverse homography algorithm">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1637">
              <meta itemprop="top" content="1681">
              <meta itemprop="right" content="1689">
              <meta itemprop="bottom" content="1765">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="902">
            <meta itemprop="label" content="second video">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="194">
              <meta itemprop="top" content="2217">
              <meta itemprop="right" content="255">
              <meta itemprop="bottom" content="2324">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/83/ce/b8/d01c4358010a23/imgf0004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/49/ee/fb/0c1b9e605c2c41/imgf0004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="401">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="486">
              <meta itemprop="top" content="20">
              <meta itemprop="right" content="582">
              <meta itemprop="bottom" content="150">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="402">
            <meta itemprop="label" content="viewpoint">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="352">
              <meta itemprop="top" content="2384">
              <meta itemprop="right" content="406">
              <meta itemprop="bottom" content="2459">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="404">
            <meta itemprop="label" content="imaging system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="558">
              <meta itemprop="top" content="2362">
              <meta itemprop="right" content="611">
              <meta itemprop="bottom" content="2448">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="406">
            <meta itemprop="label" content="location">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="620">
              <meta itemprop="top" content="2522">
              <meta itemprop="right" content="690">
              <meta itemprop="bottom" content="2624">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="3">
            <meta itemprop="id" content="414">
            <meta itemprop="label" content="position">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="878">
              <meta itemprop="top" content="1739">
              <meta itemprop="right" content="931">
              <meta itemprop="bottom" content="1824">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/da/e5/69/7df71767be0494/imgf0005.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/f5/d1/4a/2ec70c360806d2/imgf0005.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="302">
            <meta itemprop="label" content="feature detection module">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="748">
              <meta itemprop="top" content="699">
              <meta itemprop="right" content="863">
              <meta itemprop="bottom" content="814">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="401">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="264">
              <meta itemprop="top" content="60">
              <meta itemprop="right" content="361">
              <meta itemprop="bottom" content="193">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="414">
            <meta itemprop="label" content="position">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="997">
              <meta itemprop="top" content="1476">
              <meta itemprop="right" content="1054">
              <meta itemprop="bottom" content="1569">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/28/ef/65/e0a87c230630fe/imgf0006.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/e4/1c/8b/c843f92cdb3413/imgf0006.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="401">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="200">
              <meta itemprop="top" content="19">
              <meta itemprop="right" content="293">
              <meta itemprop="bottom" content="140">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="402">
            <meta itemprop="label" content="viewpoint">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="535">
              <meta itemprop="top" content="953">
              <meta itemprop="right" content="590">
              <meta itemprop="bottom" content="1042">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="404">
            <meta itemprop="label" content="imaging system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="319">
              <meta itemprop="top" content="491">
              <meta itemprop="right" content="384">
              <meta itemprop="bottom" content="594">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="406">
            <meta itemprop="label" content="location">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="553">
              <meta itemprop="top" content="665">
              <meta itemprop="right" content="606">
              <meta itemprop="bottom" content="758">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="408">
            <meta itemprop="label" content="pedestrian likelihood distribution">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="858">
              <meta itemprop="top" content="1742">
              <meta itemprop="right" content="910">
              <meta itemprop="bottom" content="1827">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="410">
            <meta itemprop="label" content="potential state distribution">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="889">
              <meta itemprop="top" content="971">
              <meta itemprop="right" content="943">
              <meta itemprop="bottom" content="1070">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="608">
            <meta itemprop="label" content="potential state distributions">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1029">
              <meta itemprop="top" content="1027">
              <meta itemprop="right" content="1084">
              <meta itemprop="bottom" content="1114">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/86/2c/4c/dd25e2b9bf627e/imgf0007.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/b8/a9/59/80da0e0735d058/imgf0007.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="400">
            <meta itemprop="label" content="map">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="931">
              <meta itemprop="top" content="125">
              <meta itemprop="right" content="984">
              <meta itemprop="bottom" content="233">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="402">
            <meta itemprop="label" content="viewpoint">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1330">
              <meta itemprop="top" content="1576">
              <meta itemprop="right" content="1384">
              <meta itemprop="bottom" content="1663">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="404">
            <meta itemprop="label" content="imaging system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1096">
              <meta itemprop="top" content="1584">
              <meta itemprop="right" content="1149">
              <meta itemprop="bottom" content="1670">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/84/2d/94/f895299b569780/imgf0008.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/a5/5e/52/121783b91a741d/imgf0008.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="800">
            <meta itemprop="label" content="viewpoint">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="944">
              <meta itemprop="top" content="920">
              <meta itemprop="right" content="1054">
              <meta itemprop="bottom" content="980">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="804">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1388">
              <meta itemprop="top" content="176">
              <meta itemprop="right" content="1499">
              <meta itemprop="bottom" content="238">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="806">
            <meta itemprop="label" content="detections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="697">
              <meta itemprop="top" content="1531">
              <meta itemprop="right" content="792">
              <meta itemprop="bottom" content="1585">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="808">
            <meta itemprop="label" content="pedestrian likelihood distribution">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="400">
              <meta itemprop="top" content="376">
              <meta itemprop="right" content="503">
              <meta itemprop="bottom" content="433">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="808">
            <meta itemprop="label" content="pedestrian likelihood distribution">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="850">
              <meta itemprop="top" content="445">
              <meta itemprop="right" content="950">
              <meta itemprop="bottom" content="505">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="7">
            <meta itemprop="id" content="810">
            <meta itemprop="label" content="sidewalks">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="881">
              <meta itemprop="top" content="782">
              <meta itemprop="right" content="985">
              <meta itemprop="bottom" content="840">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/fe/e2/c9/c541deb75fc203/imgf0009.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ad/85/63/2ad42851b52876/imgf0009.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="900">
            <meta itemprop="label" content="first video">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1121">
              <meta itemprop="top" content="122">
              <meta itemprop="right" content="1216">
              <meta itemprop="bottom" content="177">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="902">
            <meta itemprop="label" content="second video">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1117">
              <meta itemprop="top" content="1109">
              <meta itemprop="right" content="1216">
              <meta itemprop="bottom" content="1163">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="903">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1383">
              <meta itemprop="top" content="64">
              <meta itemprop="right" content="1483">
              <meta itemprop="bottom" content="120">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="903">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1386">
              <meta itemprop="top" content="1055">
              <meta itemprop="right" content="1481">
              <meta itemprop="bottom" content="1109">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="904">
            <meta itemprop="label" content="first tracks">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="808">
              <meta itemprop="top" content="424">
              <meta itemprop="right" content="899">
              <meta itemprop="bottom" content="477">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="906">
            <meta itemprop="label" content="second tracks">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="955">
              <meta itemprop="top" content="1516">
              <meta itemprop="right" content="1041">
              <meta itemprop="bottom" content="1569">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/42/f1/d9/3d6a86dc8168aa/imgf0010.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/f3/50/9e/468ab787f4b303/imgf0010.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1000">
            <meta itemprop="label" content="map">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1463">
              <meta itemprop="top" content="2354">
              <meta itemprop="right" content="1519">
              <meta itemprop="bottom" content="2467">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1002">
            <meta itemprop="label" content="first projections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="560">
              <meta itemprop="top" content="1799">
              <meta itemprop="right" content="613">
              <meta itemprop="bottom" content="1916">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1004">
            <meta itemprop="label" content="second projections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1357">
              <meta itemprop="top" content="1810">
              <meta itemprop="right" content="1414">
              <meta itemprop="bottom" content="1924">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1005">
            <meta itemprop="label" content="sensor fusion">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="844">
              <meta itemprop="top" content="1270">
              <meta itemprop="right" content="902">
              <meta itemprop="bottom" content="1387">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="1006">
            <meta itemprop="label" content="final projections">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="956">
              <meta itemprop="top" content="480">
              <meta itemprop="right" content="1008">
              <meta itemprop="bottom" content="597">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="903">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="145">
              <meta itemprop="top" content="2296">
              <meta itemprop="right" content="197">
              <meta itemprop="bottom" content="2381">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="9">
            <meta itemprop="id" content="903">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="543">
              <meta itemprop="top" content="162">
              <meta itemprop="right" content="598">
              <meta itemprop="bottom" content="251">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/4d/00/ec/cc9f180dd0b327/imgf0011.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/f1/2e/8a/9c7c77def7ed07/imgf0011.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1100">
            <meta itemprop="label" content="tracks">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1594">
              <meta itemprop="top" content="145">
              <meta itemprop="right" content="1651">
              <meta itemprop="bottom" content="279">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="903">
            <meta itemprop="label" content="scene">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="445">
              <meta itemprop="top" content="188">
              <meta itemprop="right" content="501">
              <meta itemprop="bottom" content="265">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/09/82/11/73ff44f9c6e683/imgf0012.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/96/06/7a/76a3fbed293087/imgf0012.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1200">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="173">
              <meta itemprop="top" content="354">
              <meta itemprop="right" content="338">
              <meta itemprop="bottom" content="419">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1204">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="176">
              <meta itemprop="top" content="787">
              <meta itemprop="right" content="304">
              <meta itemprop="bottom" content="842">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1206">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="176">
              <meta itemprop="top" content="1150">
              <meta itemprop="right" content="297">
              <meta itemprop="bottom" content="1206">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1208">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="176">
              <meta itemprop="top" content="1496">
              <meta itemprop="right" content="299">
              <meta itemprop="bottom" content="1554">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/bf/85/30/094b29601f40c2/imgf0013.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/ba/36/cf/ca853893f00a32/imgf0013.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1304">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="725">
              <meta itemprop="top" content="584">
              <meta itemprop="right" content="849">
              <meta itemprop="bottom" content="638">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1306">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="184">
              <meta itemprop="top" content="960">
              <meta itemprop="right" content="305">
              <meta itemprop="bottom" content="1013">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1308">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="643">
              <meta itemprop="top" content="1117">
              <meta itemprop="right" content="760">
              <meta itemprop="bottom" content="1171">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1314">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="659">
              <meta itemprop="top" content="2247">
              <meta itemprop="right" content="776">
              <meta itemprop="bottom" content="2301">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1316">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="197">
              <meta itemprop="top" content="2475">
              <meta itemprop="right" content="314">
              <meta itemprop="bottom" content="2529">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/51/9b/af/f382ce04c47792/imgf0014.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/d2/8a/87/68931ec6aba71a/imgf0014.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1400">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="153">
              <meta itemprop="top" content="266">
              <meta itemprop="right" content="281">
              <meta itemprop="bottom" content="321">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1404">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="153">
              <meta itemprop="top" content="858">
              <meta itemprop="right" content="277">
              <meta itemprop="bottom" content="916">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1408">
            <meta itemprop="label" content="Operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="161">
              <meta itemprop="top" content="1475">
              <meta itemprop="right" content="283">
              <meta itemprop="bottom" content="1532">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="13">
            <meta itemprop="id" content="1412">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="163">
              <meta itemprop="top" content="1955">
              <meta itemprop="right" content="278">
              <meta itemprop="bottom" content="2013">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/ad/17/16/f494b7de10a3ae/imgf0015.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/50/58/8a/c755489199c3df/imgf0015.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1500">
            <meta itemprop="label" content="data processing system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1402">
              <meta itemprop="top" content="87">
              <meta itemprop="right" content="1525">
              <meta itemprop="bottom" content="141">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1502">
            <meta itemprop="label" content="communications fabric">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="685">
              <meta itemprop="top" content="694">
              <meta itemprop="right" content="806">
              <meta itemprop="bottom" content="750">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1504">
            <meta itemprop="label" content="processor unit">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="352">
              <meta itemprop="top" content="422">
              <meta itemprop="right" content="475">
              <meta itemprop="bottom" content="479">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1506">
            <meta itemprop="label" content="memory">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="799">
              <meta itemprop="top" content="352">
              <meta itemprop="right" content="921">
              <meta itemprop="bottom" content="410">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1508">
            <meta itemprop="label" content="persistent storage">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1434">
              <meta itemprop="top" content="353">
              <meta itemprop="right" content="1564">
              <meta itemprop="bottom" content="409">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1510">
            <meta itemprop="label" content="Communications unit">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="401">
              <meta itemprop="top" content="1165">
              <meta itemprop="right" content="524">
              <meta itemprop="bottom" content="1223">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1512">
            <meta itemprop="label" content="output unit">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="987">
              <meta itemprop="top" content="1164">
              <meta itemprop="right" content="1110">
              <meta itemprop="bottom" content="1221">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1514">
            <meta itemprop="label" content="Display">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1419">
              <meta itemprop="top" content="1165">
              <meta itemprop="right" content="1538">
              <meta itemprop="bottom" content="1221">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1516">
            <meta itemprop="label" content="storage devices">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="563">
              <meta itemprop="top" content="377">
              <meta itemprop="right" content="691">
              <meta itemprop="bottom" content="433">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1518">
            <meta itemprop="label" content="program code">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="878">
              <meta itemprop="top" content="1780">
              <meta itemprop="right" content="1001">
              <meta itemprop="bottom" content="1837">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1520">
            <meta itemprop="label" content="readable media">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="766">
              <meta itemprop="top" content="2389">
              <meta itemprop="right" content="896">
              <meta itemprop="bottom" content="2445">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1522">
            <meta itemprop="label" content="computer program product">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1415">
              <meta itemprop="top" content="2094">
              <meta itemprop="right" content="1536">
              <meta itemprop="bottom" content="2150">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1524">
            <meta itemprop="label" content="readable storage media">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="767">
              <meta itemprop="top" content="2053">
              <meta itemprop="right" content="892">
              <meta itemprop="bottom" content="2110">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="14">
            <meta itemprop="id" content="1526">
            <meta itemprop="label" content="readable signal media">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1049">
              <meta itemprop="top" content="2010">
              <meta itemprop="right" content="1168">
              <meta itemprop="bottom" content="2065">
            </span>
          </li>
        </ul>
      </li>
      </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    
    <ul>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06K</span>&mdash;<span itemprop="Description">RECOGNITION OF DATA; PRESENTATION OF DATA; RECORD CARRIERS; HANDLING RECORD CARRIERS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06K9/00</span>&mdash;<span itemprop="Description">Methods or arrangements for reading or recognising printed or written characters or for recognising patterns, e.g. fingerprints</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06K9/00624</span>&mdash;<span itemprop="Description">Recognising scenes, i.e. recognition of a whole field of perception; recognising scene-specific objects</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06K9/00771</span>&mdash;<span itemprop="Description">Recognising scenes under surveillance, e.g. with Markovian modelling of scene activity</span>
            <meta itemprop="Leaf" content="true">
            
            <meta itemprop="FirstCode" content="true">
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/00</span>&mdash;<span itemprop="Description">Image analysis</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/20</span>&mdash;<span itemprop="Description">Analysis of motion</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/277</span>&mdash;<span itemprop="Description">Analysis of motion involving stochastic approaches, e.g. using Kalman filters</span>
            <meta itemprop="Leaf" content="true">
            
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/00</span>&mdash;<span itemprop="Description">Image analysis</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/30</span>&mdash;<span itemprop="Description">Determination of transform parameters for the alignment of images, i.e. image registration</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/33</span>&mdash;<span itemprop="Description">Determination of transform parameters for the alignment of images, i.e. image registration using feature-based methods</span>
            <meta itemprop="Leaf" content="true">
            
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/00</span>&mdash;<span itemprop="Description">Image analysis</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/30</span>&mdash;<span itemprop="Description">Determination of transform parameters for the alignment of images, i.e. image registration</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/33</span>&mdash;<span itemprop="Description">Determination of transform parameters for the alignment of images, i.e. image registration using feature-based methods</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/344</span>&mdash;<span itemprop="Description">Determination of transform parameters for the alignment of images, i.e. image registration using feature-based methods involving models</span>
            <meta itemprop="Leaf" content="true">
            
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10</span>&mdash;<span itemprop="Description">Image acquisition modality</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10016</span>&mdash;<span itemprop="Description">Video; Image sequence</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10</span>&mdash;<span itemprop="Description">Image acquisition modality</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10032</span>&mdash;<span itemprop="Description">Satellite or aerial image; Remote sensing</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10</span>&mdash;<span itemprop="Description">Image acquisition modality</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10032</span>&mdash;<span itemprop="Description">Satellite or aerial image; Remote sensing</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10044</span>&mdash;<span itemprop="Description">Radar image</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10</span>&mdash;<span itemprop="Description">Image acquisition modality</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10048</span>&mdash;<span itemprop="Description">Infrared image</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/20</span>&mdash;<span itemprop="Description">Special algorithmic details</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/20076</span>&mdash;<span itemprop="Description">Probabilistic image processing</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      </ul>
  </section>

  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA109707087" lang="EN" load-source="patent-office">
    <div num="pa01" class="abstract">A method and apparatus for processing images. A sequence of images for a scene is received from an imaging system. An object in the scene is detected using the sequence of images. A viewpoint of the imaging system is registered to a model of the scene using a region in the model of the scene in which an expected behavior of the object is expected to occur.
</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><div> <ul mxw-id="PDES58506724" lang="EN" load-source="patent-office" class="description">
    
    <heading>
      <b>BACKGROUND INFORMATION</b>
    </heading>
    <heading>
      <b>1. Background:</b>
    </heading>
    <li> <para-num num="[0001]"> </para-num> <div num="p0001" class="description-line">The present disclosure relates generally to processing different types of sensor data. Still more particularly, the present disclosure relates to a method and apparatus for registering different types of sensor data to a common model.</div>
    </li> <li> <para-num num="[0002]"> </para-num> <div num="p0002" class="description-line">Information about a scene may be identified using different types of sensor data. A scene may be any physical area for which sensor data can be generated. For example, without limitation, a scene may be an area in a city, a neighborhood, an area in a forest, an underwater region, a region of airspace, an area in a manufacturing facility, a room, a surface of a structure, or some other suitable type of scene.</div>
    </li> <li> <para-num num="[0003]"> </para-num> <div num="p0003" class="description-line">The different types of sensor data that may be generated for a scene include, but are not limited to, acoustic data, biometric data, imaging data, voltage readings, vibration data, and other suitable types of sensor data. These different types of sensor data may be used in performing operations, such as, for example, without limitation, detecting the presence of objects in the scene, identifying the objects in the scene, tracking the movement of objects in the scene, detecting changes in an environment of the scene, measuring distances between objects in the scene, and other suitable operations.</div>
    </li> <li> <para-num num="[0004]"> </para-num> <div num="p0004" class="description-line">As one illustrative example, different types of imaging data may be used for detecting, identifying, and/or tracking objects in a scene. The different types of imaging data may include, for example, without limitation, electro-optical (EO) images, infrared (IR) images, thermal images, radar images, ultraviolet images, and other suitable types of imaging data.</div>
    </li> <li> <para-num num="[0005]"> </para-num> <div num="p0005" class="description-line">Oftentimes, sensor data generated from multiple sources may be combined such that the resulting information may be more accurate, more complete, and/or more reliable as compared to the sensor data generated by a single source. The process of combining the sensor data from the different sources may be referred to as &#34;sensor fusion.&#34; In particular, when the different sources are of the same modality, the process may be referred to as &#34;unimodal sensor fusion.&#34; Further, when the different sources are of different modalities, the process may be referred to as &#34;multi-modal sensor fusion.&#34;</div>
    </li> <li> <para-num num="[0006]"> </para-num> <div num="p0006" class="description-line">As one illustrative example of multi-modal sensor fusion, electro-optical images for a scene may be combined with infrared images for the same scene to generate overall information for the scene. This overall information may be used to track objects in the scene more accurately as compared to using only one of these types of images.</div>
    </li> <li> <para-num num="[0007]"> </para-num> <div num="p0007" class="description-line">Oftentimes, performing sensor fusion for sensor data generated by different types of sources includes matching features between the different types of sensor data. For example, with currently-available systems for performing sensor fusion for two different types of images, features identified from the two different types of images may be matched. For example, features may be matched based on the features identified in the two different types of images having similar colors, brightness, shapes, and/or textures.</div>
    </li> <li> <para-num num="[0008]"> </para-num> <div num="p0008" class="description-line">The identification of features in images is typically based on pixel values in the images. As a result, the accuracy of sensor fusion may depend on factors, such as, for example, sensor response, lighting, viewpoint of the sensor system, type of image, and/or other suitable factors. For example, matching features identified in two different types of images that are generated from different viewpoints may be more difficult than desired.</div>
    </li> <li> <para-num num="[0009]"> </para-num> <div num="p0009" class="description-line">Therefore, it would be advantageous to have a method and apparatus that takes into account at least some of the issues discussed above, as well as possibly other issues.</div>
    </li> <heading>
      <b>SUMMARY</b>
    </heading>
    <li> <para-num num="[0010]"> </para-num> <div num="p0010" class="description-line">In one illustrative embodiment, a method for processing images is provided. A sequence of images for a scene is received from an imaging system. An object in the scene is detected using the sequence of images. A viewpoint of the imaging system is registered to a model of the scene using a region in the model of the scene in which an expected behavior of the object is expected to occur.</div>
    </li> <li> <para-num num="[0011]"> </para-num> <div num="p0011" class="description-line">In another illustrative embodiment, an apparatus comprises a computer system. The computer system is configured to receive a sequence of images for a scene from an imaging system. The computer system is further configured to detect an object in the scene using the sequence of images. The computer system is further configured to register a viewpoint of the imaging system to a model of the scene using a region in the model of the scene in which an expected behavior of the object is expected to occur.</div>
    </li> <li> <para-num num="[0012]"> </para-num> <div num="p0012" class="description-line">The features, functions, and advantages can be achieved independently in various embodiments of the present disclosure or may be combined in yet other embodiments in which further details can be seen with reference to the following description and drawings.</div>
    </li> <heading>
      <b>BRIEF DESCRIPTION OF THE DRAWINGS</b>
    </heading>
    <li> <para-num num="[0013]"> </para-num> <div num="p0013" class="description-line">The novel features believed characteristic of the illustrative embodiments are set forth in the appended claims. The illustrative embodiments, however, as well as a preferred mode of use, further objectives, and advantages thereof will best be understood by reference to the following detailed description of an illustrative embodiment of the present disclosure when read in conjunction with the accompanying drawings, wherein:
</div> </li> <ul> <li> <figref idrefs="f0001"> <b>Figure 1</b> </figref> is an illustration of an environment in which information about a scene is processed in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0002"> <b>Figure 2</b> </figref> is an illustration of a data processing system in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0003"> <b>Figure 3</b> </figref> is an illustration of a data processing module in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0004"> <b>Figure 4</b> </figref> is an illustration of a map in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0005"> <b>Figure 5</b> </figref> is an illustration of the estimated state distribution for an imaging system in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0006"> <b>Figure 6</b> </figref> is an illustration of the estimated state distribution for an imaging system in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0007"> <b>Figure 7</b> </figref> is an illustration of a registration of a viewpoint of an imaging system to a map and the final state distribution in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0008"> <b>Figure 8</b> </figref> is an illustration of a registration of viewpoint of an imaging system to a map in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0009"> <b>Figure 9</b> </figref> is an illustration of imaging data generated by two different types of imaging systems in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0010"> <b>Figure 10</b> </figref> is an illustration of sensor fusion in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0011"> <b>Figure 11</b> </figref> is an illustration of back-projection of tracks onto video in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0012"> <b>Figure 12</b> </figref> is an illustration of a flowchart of a process for processing images in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0013"> <b>Figure 13</b> </figref> is an illustration of a flowchart of a process for performing sensor fusion in accordance with an illustrative embodiment;</li> <li> <figref idrefs="f0014"> <b>Figure 14</b> </figref> is an illustration of a flowchart of a process for using sensor fusion to improve tracking the movement of objects in a scene in accordance with an illustrative embodiment; and</li> <li> <figref idrefs="f0015"> <b>Figure 15</b> </figref> is an illustration of a data processing system in accordance with an illustrative embodiment.</li> </ul>
    <heading>
      <b>DETAILED DESCRIPTION</b>
    </heading>
    <li> <para-num num="[0014]"> </para-num> <div num="p0014" class="description-line">The different illustrative embodiments recognize and take into account many different considerations. For example, the different illustrative embodiments recognize and take into account that currently-available systems for performing sensor fusion with different types of imaging data are primarily based on finding matches between features identified in the different types of imaging data. These features are typically identified based on pixel values.</div>
    </li> <li> <para-num num="[0015]"> </para-num> <div num="p0015" class="description-line">Further, the different illustrative embodiments recognize and take into account that some currently-available systems may take into account the position of objects in an image relative to other objects in the image to register the image to a model. However, the different illustrative embodiments recognize and take into account that these currently-available systems do not take into account the behaviors of moving objects with respect to the scene in which these objects are present.</div>
    </li> <li> <para-num num="[0016]"> </para-num> <div num="p0016" class="description-line">The different illustrative embodiments recognize and take into account that it may be desirable to have a system for combining the imaging data generated by different types of imaging systems that does not rely solely on the values of pixels in the imaging data. In particular, the different illustrative embodiments recognize and take into account that it may be desirable to have a system for registering the imaging data generated by different types of imaging systems to a model that is more accurate than currently-available systems.</div>
    </li> <li> <para-num num="[0017]"> </para-num> <div num="p0017" class="description-line">With reference now to the figures and, in particular, with reference to <figref idrefs="f0001"> <b>Figure 1</b> </figref>, an illustration of an environment in which information about a scene is processed is depicted in accordance with an illustrative embodiment. Environment <b>100</b> includes scene <b>102</b> and data processing system <b>104</b> that is configured to collect sensor data about scene <b>102.</b> In this illustrative example, scene <b>102</b> is an area of a city.</div>
    </li> <li> <para-num num="[0018]"> </para-num> <div num="p0018" class="description-line">Scene <b>102</b> includes buildings <b>106,</b> roads <b>108,</b> sidewalks <b>110,</b> trees <b>112,</b> intersections <b>114,</b> pedestrians <b>116,</b> and vehicles <b>118.</b> As depicted, pedestrians <b>116</b> are walking along sidewalks <b>110,</b> crossing roads <b>108</b> at intersections <b>114,</b> and entering and exiting buildings <b>106.</b> For example, pedestrian <b>120</b> and pedestrian <b>122</b> are walking on sidewalk <b>124.</b> Pedestrian <b>126</b> is crossing road <b>128</b> at intersection <b>130.</b> Further, vehicles <b>118</b> are traveling along roads <b>108</b> and turning at intersections <b>114.</b> For example, vehicle <b>132</b> and vehicle <b>134</b> are traveling along road <b>128</b> in opposite directions. Vehicle <b>136</b> is turning at intersection <b>138.</b> </div>
    </li> <li> <para-num num="[0019]"> </para-num> <div num="p0019" class="description-line">In this illustrative example, data processing system <b>104</b> includes imaging system <b>140</b> on unmanned aerial vehicle <b>142,</b> imaging system <b>144</b> on unmanned aerial vehicle <b>146,</b> imaging system <b>148</b> on robotic ground vehicle <b>150,</b> and control station <b>152.</b> Imaging systems <b>140, 144,</b> and <b>148</b> are configured to collect sensor data in the form of imaging data for scene <b>102.</b> In particular, these imaging systems are configured to generate images of scene <b>102.</b> </div>
    </li> <li> <para-num num="[0020]"> </para-num> <div num="p0020" class="description-line">As depicted, imaging system <b>140</b> on unmanned aerial vehicle <b>142</b> and imaging system <b>144</b> on unmanned aerial vehicle <b>146</b> are configured to generate images of scene <b>102</b> while unmanned aerial vehicle <b>142</b> and unmanned aerial vehicle <b>146</b> fly over scene <b>102.</b> Further, imaging system <b>148</b> on robotic ground vehicle <b>150</b> is configured to generate images of scene <b>102</b> while robotic ground vehicle <b>150</b> moves on ground <b>154</b> of scene <b>102.</b> In this manner, different types of images of scene <b>102</b> may be collected from different viewpoints.</div>
    </li> <li> <para-num num="[0021]"> </para-num> <div num="p0021" class="description-line">In this illustrative example, imaging systems <b>140, 144,</b> and <b>148</b> have different modalities. In other words, these imaging systems generate different types of images using different types of sensors. For example, imaging system <b>140</b> may generate electro-optical (EO) images using electro-optical sensors. Imaging system <b>144</b> may generate infrared (IR) images using infrared sensors. Imaging system <b>148</b> may generate thermal images using thermographic sensors.</div>
    </li> <li> <para-num num="[0022]"> </para-num> <div num="p0022" class="description-line">Additionally, imaging systems <b>140, 144,</b> and <b>148</b> also may be configured to send these images to control station <b>152</b> for processing. For example, imaging systems <b>140, 144,</b> and <b>148</b> may send images to control station <b>152</b> using wireless communications links <b>156, 158,</b> and <b>160,</b> respectively.</div>
    </li> <li> <para-num num="[0023]"> </para-num> <div num="p0023" class="description-line">Control station <b>152</b> may use these images to detect, identify, and/or track objects in scene <b>102,</b> such as, for example, without limitation, pedestrians <b>116</b> and/or vehicles <b>118</b> in scene <b>102.</b> In one illustrative example, these images may be used in performing surveillance of scene <b>102.</b> In another illustrative example, these images may be used to monitor the activity of pedestrians <b>116</b> entering and exiting buildings <b>106.</b> </div>
    </li> <li> <para-num num="[0024]"> </para-num> <div num="p0024" class="description-line">The different illustrative embodiments recognize and take into account that objects in scene <b>102</b> may be detected in the images generated by each of imaging systems <b>140, 144,</b> and <b>148.</b> Further, the different illustrative embodiments recognize and take into account that combining the detections of objects in the different types of images generated by imaging systems <b>140, 144,</b> and <b>148</b> may allow the movement of these objects to be more accurately and efficiently tracked in scene <b>102</b> as compared to using the images generated by one of these imaging systems alone. For example, as depicted, the movement of pedestrian <b>120</b> along path <b>149</b> may be tracked using the imaging data generated by imaging systems <b>140, 144,</b> and <b>148.</b> </div>
    </li> <li> <para-num num="[0025]"> </para-num> <div num="p0025" class="description-line">Additionally, the different illustrative embodiments also recognize and take into account that combining the images generated by imaging systems <b>140, 144,</b> and <b>148</b> may include combining the detections of objects in the different types of images. In other words, the images may be combined using sensor fusion.</div>
    </li> <li> <para-num num="[0026]"> </para-num> <div num="p0026" class="description-line">However, the different illustrative embodiments recognize and take into account that typically, detections of objects in images are made using features identified based on pixel values in the images. As a result, the sensor fusion of the images generated by imaging systems <b>140, 144,</b> and <b>148</b> may be affected by the different viewpoints of these imaging systems at the time the images were generated, the lighting in scene <b>102,</b> the modality of these imaging systems, and/or other suitable factors.</div>
    </li> <li> <para-num num="[0027]"> </para-num> <div num="p0027" class="description-line">Further, the different illustrative embodiments recognize and take into account that it may be desirable to have a system that performs sensor fusion by registering the viewpoints of the different types of imaging systems to a common model. The common model may be, for example, a two-dimensional map, a three-dimensional model of a scene, or some other suitable type of model. In particular, the different illustrative embodiments recognize and take into account that it may be desirable to have a system that registers the viewpoints of these different types of imaging systems to the common model without relying on the detections of objects in the images at the pixel level.</div>
    </li> <li> <para-num num="[0028]"> </para-num> <div num="p0028" class="description-line">Thus, the different illustrative embodiments provide a method and apparatus for processing images. In one illustrative embodiment, a sequence of images for a scene is received from an imaging system. An object is detected in the scene using the sequence of images. A viewpoint of the imaging system is registered to a model of the scene using a region in the model of the scene in which an expected behavior of the object is expected to occur.</div>
    </li> <li> <para-num num="[0029]"> </para-num> <div num="p0029" class="description-line">With reference now to <figref idrefs="f0002"> <b>Figure 2</b> </figref>, an illustration of a data processing system is depicted in accordance with an illustrative embodiment. Data processing system <b>200</b> is configured to generate and process sensor data <b>202.</b> In these illustrative examples, data processing system <b>200</b> includes number of sensor systems <b>204</b> and data processing module <b>206.</b> Number of sensor systems <b>204</b> is configured to generate sensor data <b>202,</b> while data processing module <b>206</b> is configured to process sensor data <b>202.</b> </div>
    </li> <li> <para-num num="[0030]"> </para-num> <div num="p0030" class="description-line">As used herein, a &#34;number of items&#34; means one or more items. In this manner, a &#34;number of sensor systems&#34; means one or more sensor systems. In these illustrative examples, number of sensor systems <b>204</b> may include first sensor system <b>208</b> and second sensor system <b>210.</b> In one illustrative example, first sensor system <b>208</b> takes the form of first imaging system <b>212,</b> and second sensor system <b>210</b> takes the form of second imaging system <b>214.</b> </div>
    </li> <li> <para-num num="[0031]"> </para-num> <div num="p0031" class="description-line">First imaging system <b>212</b> and second imaging system <b>214</b> generate sensor data <b>202</b> in the form of imaging data <b>216.</b> In these illustrative examples, first imaging system <b>212</b> and second imaging system <b>214</b> may generate imaging data <b>216</b> in one or more modalities.</div>
    </li> <li> <para-num num="[0032]"> </para-num> <div num="p0032" class="description-line">For example, each of first imaging system <b>212</b> and second imaging system <b>214</b> may be selected from at least one of an electro-optical (EO) imaging system, an infrared (IR) imaging system, a radar imaging system, a thermal imaging system, an ultrasound imaging system, a light detection and ranging (LIDAR) system, and some other suitable type of imaging system. In this manner, imaging data <b>216</b> generated by each of first imaging system <b>212</b> and second imaging system <b>214</b> may comprise images selected from at least one of electro-optical images, infrared images, radar images, thermal images, light detection and ranging images, and other suitable types of images. Electro-optical images may be, for example, visible light images.</div>
    </li> <li> <para-num num="[0033]"> </para-num> <div num="p0033" class="description-line">As used herein, the phrase &#34;at least one of&#34;, when used with a list of items, means different combinations of one or more of the listed items may be used and only one of each item in the list may be needed. For example, &#34;at least one of item A, item B, and item C&#34; may include, for example, without limitation, item A or item A and item B. This example also may include item A, item B, and item C, or item B and item C. In other examples, &#34;at least one of&#34; may be, for example, without limitation, two of item A, one of item B, and 10 of item C; four of item B and seven of item C; and other suitable combinations.</div>
    </li> <li> <para-num num="[0034]"> </para-num> <div num="p0034" class="description-line">In these illustrative examples, first imaging system <b>212</b> generates first sequence of images <b>218,</b> while second imaging system <b>214</b> generates second sequence of images <b>220.</b> As used herein, a &#34;sequence of images&#34; is two or more images generated in a consecutive order with respect to time. First sequence of images <b>218</b> and second sequence of images <b>220</b> may be generated for scene <b>222.</b> In some illustrative examples, each of first sequence of images <b>218</b> and second sequence of images <b>220</b> may be referred to as video of scene <b>222.</b> </div>
    </li> <li> <para-num num="[0035]"> </para-num> <div num="p0035" class="description-line">Scene <b>222</b> may be a physical area, such as, for example, without limitation, an area of a city, a neighborhood, an area over an ocean, an area in a forest, an area in a desert, a town, a geographical area, an area inside a manufacturing facility, a floor in a building, a section of highway, or some other suitable type of area. Scene <b>102</b> in <figref idrefs="f0001"> <b>Figure 1</b> </figref> is an example of one implementation for scene <b>222.</b> </div>
    </li> <li> <para-num num="[0036]"> </para-num> <div num="p0036" class="description-line">Objects <b>223</b> may be present in scene <b>222.</b> Object <b>225</b> is an example of one of objects <b>223</b> in scene <b>222.</b> Object <b>225</b> may take the form of, for example, without limitation, a person, a vehicle, a mobile structure, a package, and/or some other suitable type of object. A vehicle in scene <b>222</b> may take the form of, for example, without limitation, a car, a truck, an aircraft, a van, a tank, an unmanned aerial vehicle, a spaceship, a missile, a rocket, or some other suitable type of vehicle.</div>
    </li> <li> <para-num num="[0037]"> </para-num> <div num="p0037" class="description-line">In these depicted examples, first imaging system <b>212</b> generates first sequence of images <b>218</b> from viewpoint <b>227</b> of scene <b>222.</b> Second imaging system <b>214</b> generates second sequence of images <b>220</b> from viewpoint <b>229</b> of scene <b>222.</b> Viewpoint <b>227</b> and viewpoint <b>229</b> may change over time, depending on the implementation. For example, if first imaging system <b>212</b> is attached to a platform, such as an unmanned aerial vehicle (UAV), viewpoint <b>227</b> of first imaging system <b>212</b> may change as the unmanned aerial vehicle flies over scene <b>222.</b> </div>
    </li> <li> <para-num num="[0038]"> </para-num> <div num="p0038" class="description-line">In these illustrative examples, number of sensor systems <b>204</b> is configured to send sensor data <b>202</b> to data processing module <b>206</b> using number of communications links <b>224.</b> Number of communications links <b>224</b> may include at least one of, for example, a wired communications link, a wireless communications link, an optical communications link, and other suitable types of communications links.</div>
    </li> <li> <para-num num="[0039]"> </para-num> <div num="p0039" class="description-line">Data processing module <b>206</b> may be implemented using hardware, software, or a combination of both. In these illustrative examples, data processing module <b>206</b> may be implemented in computer system <b>226.</b> Computer system <b>226</b> may comprise a number of computers. When more than one computer is present in computer system <b>226,</b> these computers may be in communication with each other.</div>
    </li> <li> <para-num num="[0040]"> </para-num> <div num="p0040" class="description-line">In these illustrative examples, data processing module <b>206</b> is configured to process sensor data <b>202</b> received from number of sensor systems <b>204.</b> In particular, when more than one sensor system is present in number of sensor systems <b>204,</b> data processing module <b>206</b> may be configured to combine sensor data <b>202</b> generated by the different sensor systems to provide more accurate and complete data as compared to sensor data <b>202</b> generated by one of number of sensor systems <b>204.</b> In other words, data processing module <b>206</b> may perform sensor fusion. Data processing module <b>206</b> is described in more detail in <figref idrefs="f0003"> <b>Figure 3</b> </figref> below.</div>
    </li> <li> <para-num num="[0041]"> </para-num> <div num="p0041" class="description-line">With reference now to <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>,</b> an illustration of data processing module <b>206</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref> is depicted in accordance with an illustrative embodiment. Data processing module <b>206</b> may include feature detection module <b>302,</b> registration module <b>304,</b> fusion module <b>306,</b> and back-projection module <b>308.</b> </div>
    </li> <li> <para-num num="[0042]"> </para-num> <div num="p0042" class="description-line">Feature detection module <b>302</b> receives sensor data <b>202</b> from number of sensor systems <b>204</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> for processing. Feature detection module <b>302</b> processes sensor data <b>202</b> to detect features <b>310</b> in sensor data <b>202.</b> When sensor data <b>202</b> is imaging data <b>216,</b> features <b>310</b> detected in image data <b>216</b> may include at least a portion of objects <b>223</b> in scene <b>222</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref>. As used herein, &#34;at least a portion&#34; means one, some, or all.</div>
    </li> <li> <para-num num="[0043]"> </para-num> <div num="p0043" class="description-line">In one illustrative example, feature detection module <b>302</b> makes first number of detections <b>312</b> of objects <b>223</b> in scene <b>222</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref> using first sequence of images <b>218</b> and second number of detections <b>314</b> of objects <b>223</b> using second sequence of images <b>220.</b> First number of detections <b>312</b> and/or second number of detections <b>314</b> may include detections of one, some, or all of objects <b>223</b> in scene <b>222</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref>.</div>
    </li> <li> <para-num num="[0044]"> </para-num> <div num="p0044" class="description-line">Further, one or more of first number of detections <b>312</b> may be for the same object in objects <b>223</b> as one or more of second number of detections <b>314.</b> For example, both detection <b>316</b> from first sequence of images <b>218</b> and detection <b>318</b> from second sequence of images <b>220</b> may be detections of object <b>225</b> in objects <b>223</b> in scene <b>222</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref>. Of course, in other illustrative examples, detection <b>316</b> and detection <b>318</b> may be detections of different objects in objects <b>223.</b> </div>
    </li> <li> <para-num num="[0045]"> </para-num> <div num="p0045" class="description-line">Additionally, feature detection module <b>302</b> also groups first number of detections <b>312</b> and second number of detections <b>314</b> by type. For example, first number of detections <b>312</b> may include detections of first number of types <b>313.</b> Second number of detections <b>314</b> may include detections of second number of types <b>315.</b> A type in first number of types <b>313</b> and/or second number of types <b>315</b> may be selected from, for example, without limitation, one of a pedestrian type, a vehicle type, a structure type, or some other suitable type. In one illustrative example, detections of pedestrians are grouped together and detections of vehicles may be grouped together.</div>
    </li> <li> <para-num num="[0046]"> </para-num> <div num="p0046" class="description-line">In these illustrative examples, feature detection module <b>302</b> also may be configured to generate first number of tracks <b>320</b> using first sequence of images <b>218</b> and second number of tracks <b>322</b> using second sequence of images <b>220.</b> First number of tracks <b>320</b> may be generated to track one or more of objects <b>223</b> in scene <b>222</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref> over time in first sequence of images <b>218.</b> Second number of tracks <b>322</b> may be generated to track one or more of objects <b>223</b> in scene <b>222</b> over time in second sequence of images <b>220.</b> </div>
    </li> <li> <para-num num="[0047]"> </para-num> <div num="p0047" class="description-line">In one illustrative example, a track in first number of tracks <b>320</b> may be generated for object <b>225</b> when detection <b>316</b> of object <b>225</b> has been made in at least a selected number of images in first sequence of images <b>218.</b> In some cases, the track may be generated when detection <b>316</b> of object <b>225</b> has been made for at least a selected period of time.</div>
    </li> <li> <para-num num="[0048]"> </para-num> <div num="p0048" class="description-line">Feature detection module <b>302</b> sends first number of detections <b>312</b> and second number of detections <b>314</b> to registration module <b>304.</b> In these illustrative examples, registration module <b>304</b> is configured to use first number of detections <b>312</b> to register viewpoint <b>227</b> of first imaging system <b>212</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref> to model <b>324.</b> Further, registration module <b>304</b> is configured to use second number of detections <b>314</b> to register viewpoint <b>229</b> of second imaging system <b>214</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref> to model <b>324.</b> </div>
    </li> <li> <para-num num="[0049]"> </para-num> <div num="p0049" class="description-line">Registering a viewpoint, such as viewpoint <b>227</b> or viewpoint <b>229,</b> to model <b>324</b> means transforming a coordinate system for the viewpoint to coordinate system <b>331</b> for model <b>324.</b> This transformation may include, for example, rotating, translating, and/or performing some other operation to align the coordinate system for the viewpoint with coordinate system <b>331</b> for model <b>324.</b> </div>
    </li> <li> <para-num num="[0050]"> </para-num> <div num="p0050" class="description-line">In these illustrative examples, model <b>324</b> is a common model for number of sensor systems <b>204</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref>. Model <b>324</b> may take the form of, for example, a two-dimensional model, a three-dimensional model, or some other suitable type of model for scene <b>222</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> <b>.</b> In some illustrative examples, model <b>324</b> may take the form of a two-dimensional map of scene <b>222.</b> In this manner, coordinate system <b>331</b> may take the form of a two-dimensional coordinate system, a three-dimensional coordinate system, a geographic coordinate system, a Cartesian coordinate system, a polar coordinate system, and/or some other suitable type of coordinate system.</div>
    </li> <li> <para-num num="[0051]"> </para-num> <div num="p0051" class="description-line">In one illustrative example, registration module <b>304</b> registers viewpoint <b>227</b> of first imaging system <b>212</b> to model <b>324</b> using detection <b>316</b> of object <b>225</b> and number of regions <b>326</b> in model <b>324</b> in which expected behavior <b>328</b> of object <b>225</b> is expected to occur. For example, when object <b>225</b> is a vehicle, expected behavior <b>328</b> of object <b>225</b> may include at least one of traveling on a road, being parked in a parking lot, turning at an intersection, changing lanes in a road, and some other suitable type of behavior.</div>
    </li> <li> <para-num num="[0052]"> </para-num> <div num="p0052" class="description-line">These types of behaviors may be expected of object <b>225</b> and/or any object of the vehicle type. In this manner, when object <b>225</b> is a vehicle, number of regions <b>326</b> in model <b>324</b> may include, for example, any roads, intersections, parking lots, and/or other regions in model <b>324</b> in which expected behavior <b>328</b> of object <b>225</b> is expected to occur. In these illustrative examples, a region in number of regions <b>326</b> may be a continuous region, a discontinuous region, or some other suitable type of region.</div>
    </li> <li> <para-num num="[0053]"> </para-num> <div num="p0053" class="description-line">Registration module <b>304</b> uses detection <b>316</b> of object <b>225</b> and number of regions <b>326</b> in model <b>324</b> in which expected behavior <b>328</b> of object <b>225</b> is expected to occur to identify potential states <b>330</b> of first imaging system <b>212</b> with respect to model <b>324.</b> In these illustrative examples, a potential state in potential states <b>330</b> comprises at least one of a position and an orientation of first imaging system <b>212</b> with respect to coordinate system <b>331</b> for model <b>324.</b> </div>
    </li> <li> <para-num num="[0054]"> </para-num> <div num="p0054" class="description-line">Registration module <b>304</b> uses state estimation algorithm <b>333</b> to identify potential states <b>330</b> based on detection <b>316.</b> State estimation algorithm <b>333</b> may take the form of, for example, a particle filter. In particular, the particle filter may take the form of, for example, a contextual estimation filter (CEF). This contextual estimation filter may also be referred to as a condensation algorithm. With state estimation algorithm <b>333,</b> registration module <b>304</b> may be able to reduce the number of potential states <b>330</b> identified and generate estimated state <b>332</b> for first imaging system <b>212</b> when first number of detections <b>312</b> includes more than one detection.</div>
    </li> <li> <para-num num="[0055]"> </para-num> <div num="p0055" class="description-line">Registration module <b>304</b> uses estimated state <b>332</b> for first imaging system <b>212</b> to register viewpoint <b>227</b> of first imaging system <b>212</b> to model <b>324.</b> In these illustrative examples, registration module <b>304</b> registers viewpoint <b>229</b> of second imaging system <b>214</b> to model <b>324</b> in a manner similar to the manner in which viewpoint <b>227</b> of first imaging system <b>212</b> is registered to model <b>324.</b> </div>
    </li> <li> <para-num num="[0056]"> </para-num> <div num="p0056" class="description-line">Additionally, registration module <b>304</b> projects first number of detections <b>312</b> onto model <b>324</b> after viewpoint <b>227</b> of first imaging system <b>212</b> has been registered to model <b>324</b> to form first number of projections <b>334.</b> Registration module <b>304</b> also projects second number of detections <b>314</b> onto model <b>324</b> after viewpoint <b>229</b> of second imaging system <b>214</b> has been registered to model <b>324</b> to form second number of projections <b>336.</b> </div>
    </li> <li> <para-num num="[0057]"> </para-num> <div num="p0057" class="description-line">These projections may be performed using, for example, homography algorithm <b>347.</b> Homography algorithm <b>347</b> allows viewpoint <b>227</b> and viewpoint <b>229</b> to be transformed into coordinate system <b>331</b> for model <b>324.</b> In other words, homography algorithm <b>347</b> is used to align viewpoint <b>227</b> and/or viewpoint <b>229</b> to coordinate system <b>331</b> for model <b>324</b> when these viewpoints are projected onto model <b>324.</b> </div>
    </li> <li> <para-num num="[0058]"> </para-num> <div num="p0058" class="description-line">Fusion module <b>306</b> is configured to perform sensor fusion by combining first number of projections <b>334</b> and second number of projections <b>336</b> in model <b>324.</b> As one illustrative example, images in first sequence of images <b>218</b> and images in second sequence of images <b>220</b> may correspond to each other. For example, an image in first sequence of images <b>218</b> may have been generated at substantially the same time as an image in second sequence of images <b>220.</b> These two images may be referred to as corresponding images. Feature detection module <b>302</b> may make first number of detections <b>312</b> and second number of detections <b>314</b> in these two corresponding images.</div>
    </li> <li> <para-num num="[0059]"> </para-num> <div num="p0059" class="description-line">In this illustrative example, fusion module <b>306</b> identifies set of projection pairs <b>340</b> using first number of projections <b>334</b> and second number of projections <b>336</b> in model <b>324</b> for first number of detections <b>312</b> and second number of detections <b>314,</b> respectively. In particular, each projection pair in set of projection pairs <b>340</b> includes a projection from first number of projections <b>334</b> and a projection from second number of projections <b>336</b> having a closest distance between each other in model <b>324.</b> </div>
    </li> <li> <para-num num="[0060]"> </para-num> <div num="p0060" class="description-line">In other words, set of projection pairs <b>340</b> includes the pairs of projections from each of first number of projections <b>334</b> and second number of projections <b>336</b> being closest to each other. As used herein, a &#34;set of items&#34; means zero or more items. For example, a set may be an empty or null set. In other words, in some cases, fusion module <b>306</b> may not identify any projection pairs.</div>
    </li> <li> <para-num num="[0061]"> </para-num> <div num="p0061" class="description-line">For each projection pair identified in set of projection pairs <b>340,</b> fusion module <b>306</b> determines whether the distance between the two projections in model <b>324</b> is less than selected threshold <b>342.</b> If the distance between the two projections is not less than selected threshold <b>342,</b> fusion module <b>306</b> determines that these two projections are for detections of different objects in objects <b>223</b> in scene <b>222</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref> <b>.</b> These two projections are considered final projections for the two different objects.</div>
    </li> <li> <para-num num="[0062]"> </para-num> <div num="p0062" class="description-line">However, if the distance between the two projections is less than selected threshold <b>342,</b> fusion module <b>306</b> determines that these projections are for detections of the same object in objects <b>223</b> in scene <b>222</b> from <figref idrefs="f0002"> <b>Figure 2</b> </figref> <b>.</b> Thereafter, fusion module <b>306</b> averages these two projections to form a final projection for the particular object in model <b>324.</b> This averaging may be performed by, for example, identifying a centroid of the two projections in model <b>324.</b> </div>
    </li> <li> <para-num num="[0063]"> </para-num> <div num="p0063" class="description-line">In this manner, fusion module <b>306</b> combines first number of projections <b>334</b> and second number of projections <b>336</b> in model <b>324</b> to generate number of final projections <b>344</b> in model <b>324.</b> Final number of projections <b>344</b> in model <b>324</b> may then be used by back-projection module <b>308</b> to back-project number of final projections <b>344</b> into sensor data <b>202</b> as detections generated by feature detection module <b>302.</b> Final number of projections <b>344</b> are back-projected into the current images being processed by feature detection module <b>302.</b> </div>
    </li> <li> <para-num num="[0064]"> </para-num> <div num="p0064" class="description-line">In particular, back-projection module <b>308</b> uses inverse homography algorithm <b>346</b> to back-project number of final projections <b>344</b> into at least one of first sequence of images <b>218</b> and second sequence of images <b>220.</b> Inverse homography algorithm <b>346</b> may be, for example, the inverse of homography algorithm <b>347</b> used by registration module <b>304.</b> Inverse homography algorithm <b>346</b> allows number of final projections <b>344</b> to be transformed to the coordinate system for viewpoint <b>227</b> and/or viewpoint <b>229.</b> </div>
    </li> <li> <para-num num="[0065]"> </para-num> <div num="p0065" class="description-line">These back-projections of number of final projections <b>344</b> into at least one of first sequence of images <b>218</b> and second sequence of images <b>220</b> may be used by feature detection module <b>302.</b> In particular, feature detection module <b>302</b> may use these back-projections to improve the detection of features <b>310</b> in first sequence of images <b>218</b> and second sequence of images <b>220</b> over time.</div>
    </li> <li> <para-num num="[0066]"> </para-num> <div num="p0066" class="description-line">In one illustrative example, a final projection in number of final projections <b>344</b> for an object in objects <b>223</b> is formed based on a detection of the object in the current image from first sequence of images <b>218</b> being processed by feature detection module <b>302.</b> In other words, no detections for that object are made in the current image from second sequence of images <b>220</b> being processed by feature detection module <b>302.</b> </div>
    </li> <li> <para-num num="[0067]"> </para-num> <div num="p0067" class="description-line">However, this final projection may be back-projected into the next image in first sequence of images <b>218</b> and the next image in second sequence of images <b>220</b> processed by feature detection module <b>302.</b> In this manner, the detection of features <b>310</b> by feature detection module <b>302</b> in these next images may be improved.</div>
    </li> <li> <para-num num="[0068]"> </para-num> <div num="p0068" class="description-line">The illustrations of data processing system <b>200</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> and data processing module <b>206</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> and <figref idrefs="f0003"> <b>Figure 3</b> </figref> are not meant to imply physical or architectural limitations to the manner in which an illustrative embodiment may be implemented. Other components in addition to and/or in place of the ones illustrated may be used. Some components may be unnecessary. Also, the blocks are presented to illustrate some functional components. One or more of these blocks may be combined and/or divided into different blocks when implemented in an illustrative embodiment.</div>
    </li> <li> <para-num num="[0069]"> </para-num> <div num="p0069" class="description-line">With reference now to <figref idrefs="f0004"> <b>Figure 4</b> </figref> <b>,</b> an illustration of a map is depicted in accordance with an illustrative embodiment. In this illustrative example, map <b>400</b> is an example of one implementation for model <b>324</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> In particular, map <b>400</b> is a two-dimensional map of scene <b>401.</b> </div>
    </li> <li> <para-num num="[0070]"> </para-num> <div num="p0070" class="description-line">Viewpoint <b>402</b> of imaging system <b>404</b> is an example of one implementation of, for example, viewpoint <b>227</b> of first imaging system <b>212</b> and viewpoint <b>229</b> of second imaging system <b>214</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> <b>.</b> In one illustrative example, imaging system <b>404</b> may be a camera on an unmanned aerial vehicle located above scene <b>401.</b> Viewpoint <b>402</b> is the viewpoint of that camera looking down at scene <b>401.</b> </div>
    </li> <li> <para-num num="[0071]"> </para-num> <div num="p0071" class="description-line">Location <b>406</b> is the location with respect to viewpoint <b>402</b> of imaging system <b>404</b> at which a pedestrian in scene <b>401</b> has been detected. This detection may have been made using, for example, feature detection module <b>302</b> from <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0072]"> </para-num> <div num="p0072" class="description-line">Pedestrian likelihood distribution <b>408</b> indicates the region in map <b>400</b> in which an expected behavior of a pedestrian is expected to occur. For example, a pedestrian may be expected to walk along sidewalks in scene <b>401.</b> In this manner, pedestrian likelihood distribution <b>408</b> indicates the region in map <b>400</b> in which the pedestrian detected at location <b>406</b> with respect to viewpoint <b>402</b> is expected to be located in scene <b>401.</b> </div>
    </li> <li> <para-num num="[0073]"> </para-num> <div num="p0073" class="description-line">Registration module <b>304</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> may be configured to use location <b>406</b> and pedestrian likelihood distribution <b>408</b> to identify potential state distribution <b>410</b> for the imaging system. More specifically, potential state distribution <b>410</b> indicates the potential states for imaging system <b>404</b> based on location <b>406</b> and pedestrian likelihood distribution <b>408.</b> In this illustrative example, a potential state comprises a position for imaging system <b>404</b> above scene <b>401</b> with respect to the coordinate system of map <b>400.</b> In this manner, potential state distribution <b>410</b> indicates the region in map <b>400</b> in which imaging system <b>404</b> may be located.</div>
    </li> <li> <para-num num="[0074]"> </para-num> <div num="p0074" class="description-line">In this illustrative example, window <b>412</b> on map <b>400</b> indicates the actual location of viewpoint <b>402</b> with respect to scene <b>401</b> in map <b>400.</b> In other words, window <b>412</b> outlines the portion of scene <b>401</b> corresponding to the actual viewpoint of imaging system <b>404.</b> Further, position <b>414</b> is the actual position of imaging system <b>404</b> over scene <b>401.</b> </div>
    </li> <li> <para-num num="[0075]"> </para-num> <div num="p0075" class="description-line">With reference now to <figref idrefs="f0005"> <b>Figure 5</b> </figref> <b>,</b> an illustration of the estimated state distribution for an imaging system is depicted in accordance with an illustrative embodiment. In this illustrative example, estimated states <b>500</b> indicate the estimated possible positions of imaging system <b>404</b> over scene <b>401</b> from <figref idrefs="f0004"> <b>Figure 4</b> </figref> consistent with location <b>406</b> at which the pedestrian is detected with respect to viewpoint <b>402,</b> pedestrian likelihood distribution <b>408,</b> and potential state distribution <b>410</b> from <figref idrefs="f0004"> <b>Figure 4</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0076]"> </para-num> <div num="p0076" class="description-line">Estimated state <b>502</b> is an example of one of estimated states <b>500</b> that approximate the possible positions of imaging system <b>404.</b> Estimated state <b>502</b> comprises a position over scene <b>401</b> at which imaging system <b>404</b> may be located based on location <b>406</b> at which the pedestrian was detected with respect to viewpoint <b>402</b> of imaging system <b>404.</b> In this illustrative example, estimated states <b>500</b> are generated using state estimation algorithm <b>333</b> in registration module <b>304</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> More specifically, estimated states <b>500</b> are generated using state estimation algorithm <b>333</b> in the form of a condensation algorithm.</div>
    </li> <li> <para-num num="[0077]"> </para-num> <div num="p0077" class="description-line">With reference now to <figref idrefs="f0006"> <b>Figure 6</b> </figref> <b>,</b> an illustration of the estimated state distribution for an imaging system is depicted in accordance with an illustrative embodiment. In this illustrative example, estimated states <b>600</b> indicate the estimated possible positions for imaging system <b>404</b> when more than one pedestrian is detected in scene <b>401.</b> The pedestrian detected at location <b>406</b> with respect to viewpoint <b>402</b> is a first pedestrian detected. A second pedestrian may be detected at location <b>602</b> with respect to viewpoint <b>402,</b> and a third pedestrian may be detected at location <b>604</b> with respect to viewpoint <b>402.</b> </div>
    </li> <li> <para-num num="[0078]"> </para-num> <div num="p0078" class="description-line">When both the first pedestrian and the second pedestrian are detected, the total potential state distribution is the sum of potential state distribution <b>410</b> and potential state distribution <b>606.</b> Further, when the first pedestrian, the second pedestrian, and the third pedestrian are detected, the total potential state distribution is the sum of potential state distributions <b>410, 606,</b> and <b>608.</b> </div>
    </li> <li> <para-num num="[0079]"> </para-num> <div num="p0079" class="description-line">In this manner, as the number of detections of pedestrians in scene <b>401</b> increases, the total potential state distribution for imaging system <b>404</b> changes. In particular, as the number of detections of pedestrians in scene <b>401</b> increases and the distributions are summed, the densities for estimated states <b>600</b> change. The estimated state corresponding to the most likely state of imaging system <b>404</b> is the state with the maximum density in the total potential state distribution.</div>
    </li> <li> <para-num num="[0080]"> </para-num> <div num="p0080" class="description-line">Further, uncertainty in the most likely state identified for imaging system <b>404</b> decreases as the number of detections of pedestrians in scene <b>401</b> increases. As depicted, estimated states <b>600</b> include a smaller region of uncertainty as compared to estimated states <b>500</b> in <figref idrefs="f0005"> <b>Figure 5</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0081]"> </para-num> <div num="p0081" class="description-line">With reference now to <figref idrefs="f0007"> <b>Figure 7</b> </figref> <b>,</b> an illustration of a registration of a viewpoint of an imaging system to a map and the final state distribution is depicted in accordance with an illustrative embodiment. In this illustrative example, viewpoint <b>402</b> of imaging system <b>404</b> has been registered to map <b>400</b> of scene <b>401</b> using locations <b>406, 602,</b> and <b>604</b> of pedestrian detections with respect to viewpoint <b>402</b> from <figref idrefs="f0006"> <b>Figure 6</b> </figref> and potential state distribution <b>608</b> from <figref idrefs="f0006"> <b>Figure 6</b> </figref> <b>.</b> As depicted, viewpoint <b>402</b> is registered using estimated state <b>700</b> for imaging system <b>404.</b> </div>
    </li> <li> <para-num num="[0082]"> </para-num> <div num="p0082" class="description-line">Estimated state <b>700</b> is selected based on the highest density in estimated states <b>600.</b> In our invention, the total potential state distribution is determined by the sum of the potential state distributions due to multiple behavior detections. States which are consistent with the most number of behavior detections have the highest density. In this illustrative example, the state corresponding to the highest density is selected as estimated state <b>700</b> for imaging system <b>404.</b> </div>
    </li> <li> <para-num num="[0083]"> </para-num> <div num="p0083" class="description-line">With reference now to <figref idrefs="f0008"> <b>Figure 8</b> </figref> <b>,</b> an illustration of a registration of a viewpoint of an imaging system to a map is depicted in accordance with an illustrative embodiment. In this illustrative example, viewpoint <b>800</b> for an imaging system, such as, for example, first imaging system <b>212</b> or second imaging system <b>214</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> <b>,</b> has been registered to map <b>802</b> of scene <b>804.</b> </div>
    </li> <li> <para-num num="[0084]"> </para-num> <div num="p0084" class="description-line">In particular, viewpoint <b>800</b> is registered to map <b>802</b> based on detections <b>806.</b> In this depicted example, detections <b>806</b> are the detections of pedestrians in scene <b>804</b> with respect to viewpoint <b>800</b> of the imaging system. As illustrated, pedestrian likelihood distribution <b>808</b> indicates the region in map <b>802</b> in which an expected behavior of a pedestrian is expected to occur. Pedestrian likelihood distribution <b>808</b> indicates that pedestrians are expected to walk along sidewalks <b>810</b> in scene <b>804.</b> </div>
    </li> <li> <para-num num="[0085]"> </para-num> <div num="p0085" class="description-line">Registration module <b>304</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> may use pedestrian likelihood distribution <b>808</b> and detections <b>806</b> in viewpoint <b>800</b> of the imaging system to register viewpoint <b>800</b> to map <b>802.</b> As depicted, when viewpoint <b>800</b> is registered to map <b>802,</b> detections <b>806</b> may lie along pedestrian likelihood distribution <b>808.</b> As the number of detections <b>806</b> made increases, the accuracy with which viewpoint <b>800</b> may be registered to map <b>802</b> also increases.</div>
    </li> <li> <para-num num="[0086]"> </para-num> <div num="p0086" class="description-line">With reference now to <figref idrefs="f0009 f0010 f0011"> <b>Figures 9-11</b> </figref> <b>,</b> illustrations of the processing of imaging data are depicted in accordance with an illustrative embodiment. In <figref idrefs="f0009 f0010 f0011"> <b>Figures 9-11</b> </figref> <b>,</b> imaging data generated by two different types of imaging systems is processed and used to generate more accurate data as compared to using the imaging data generated by one imaging system.</div>
    </li> <li> <para-num num="[0087]"> </para-num> <div num="p0087" class="description-line">Turning now to <figref idrefs="f0009"> <b>Figure 9</b> </figref> <b>,</b> an illustration of imaging data generated by two different types of imaging systems is depicted in accordance with an illustrative embodiment. In this illustrative example, first video <b>900</b> is generated by an electro-optical imaging system. Second video <b>902</b> is generated by an infrared imaging system. Both first video <b>900</b> and second video <b>902</b> are generated for the same scene.</div>
    </li> <li> <para-num num="[0088]"> </para-num> <div num="p0088" class="description-line">Each of first video <b>900</b> and second video <b>902</b> comprises a sequence of images. Each of first video <b>900</b> and second video <b>902</b> are received at a data processing module, such as data processing module <b>206</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>,</b> as a continuous stream of images. First video <b>900</b> and second video <b>902</b> are processed by data processing module <b>206</b> as first video <b>900</b> and second video <b>902</b> are being received.</div>
    </li> <li> <para-num num="[0089]"> </para-num> <div num="p0089" class="description-line">For example, feature detection module <b>302</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> generates first tracks <b>904</b> using first video <b>900</b> and second tracks <b>906</b> using second video <b>902.</b> First tracks <b>904</b> and second tracks <b>906</b> are generated for pedestrians detected in scene <b>903</b> by feature detection module <b>302.</b> </div>
    </li> <li> <para-num num="[0090]"> </para-num> <div num="p0090" class="description-line">With reference now to <figref idrefs="f0010"> <b>Figure 10</b> </figref> <b>,</b> an illustration of sensor fusion is depicted in accordance with an illustrative embodiment. In this illustrative example, registration module <b>304</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> has registered a viewpoint of the electro-optical imaging system that generated first video <b>900</b> in <figref idrefs="f0009"> <b>Figure 9</b> </figref> to map <b>1000.</b> Map <b>1000</b> is an example one implementation for model <b>324</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> Further, registration module <b>304</b> has also registered a viewpoint of the infrared imaging system that generates second video <b>902</b> in <figref idrefs="f0009"> <b>Figure 9</b> </figref> to map <b>1000.</b> </div>
    </li> <li> <para-num num="[0091]"> </para-num> <div num="p0091" class="description-line">Based on the registrations of these two viewpoints to map <b>1000,</b> registration module <b>304</b> projects first tracks <b>904</b> in <figref idrefs="f0009"> <b>Figure 9</b> </figref> onto map <b>1000</b> to form first projections <b>1002.</b> Further, registration module <b>304</b> projects second tracks <b>906</b> in <figref idrefs="f0009"> <b>Figure 9</b> </figref> onto map <b>1000</b> to form second projections <b>1004.</b> In this illustrative example, at least a portion of second projections <b>1004</b> and at least a portion of first projections <b>1002</b> are for the same pedestrians in scene <b>903.</b> Further, in some cases, one or more pedestrians represented by first projections <b>1002</b> may not be represented by any of second projections <b>1004.</b> Similarly, one or more pedestrians represented by second projections <b>1004</b> may not be represented by any of first projections <b>1002.</b> </div>
    </li> <li> <para-num num="[0092]"> </para-num> <div num="p0092" class="description-line">Fusion module <b>306</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> is configured to perform sensor fusion <b>1005</b> to form final projections <b>1006.</b> When sensor fusion <b>1005</b> is performed, each of final projections <b>1006</b> may represent a different pedestrian in scene <b>903.</b> Sensor fusion <b>1005</b> is performed such that pedestrians in scene <b>903</b> may be tracked more accurately using both first video <b>900</b> and second video <b>902</b> in <figref idrefs="f0009"> <b>Figure 9</b> </figref> as compared to using only one of first video <b>900</b> and second video <b>902.</b> </div>
    </li> <li> <para-num num="[0093]"> </para-num> <div num="p0093" class="description-line">With reference now to <figref idrefs="f0011"> <b>Figure 11</b> </figref> <b>,</b> an illustration of back-projection of tracks onto video is depicted in accordance with an illustrative embodiment. In this illustrative example, final projections <b>1006</b> from <figref idrefs="f0010"> <b>Figure 10</b> </figref> have been back-projected onto first video <b>900</b> generated by the electro-optical imaging system.</div>
    </li> <li> <para-num num="[0094]"> </para-num> <div num="p0094" class="description-line">In particular, final projections <b>1006</b> are back-projected onto first video <b>900</b> at a later point in time for first video <b>900</b> as compared to when first tracks <b>904</b> in <figref idrefs="f0009"> <b>Figure 9</b> </figref> were generated. In other words, final projections are back-projected onto images in first video <b>900</b> generated at a later point in time than the images of first video <b>900</b> depicted in <figref idrefs="f0009"> <b>Figure 9</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0095]"> </para-num> <div num="p0095" class="description-line">Feature detection module <b>302</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> uses these back-projections to generate tracks <b>1100</b> for pedestrians in scene <b>903.</b> Tracks <b>1100</b> may be more accurate tracks for pedestrians in scene <b>903</b> as compared to first tracks <b>904</b> generated in <figref idrefs="f0009"> <b>Figure 9</b> </figref> <b>.</b> Further, tracks <b>1100</b> may be used by registration module <b>304</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> to more accurately register the viewpoint of the electro-optical imaging system to map <b>1000</b> in <figref idrefs="f0010"> <b>Figure 10</b> </figref> <b>.</b> In this manner, tracks <b>1100</b> may be more accurately projected onto map <b>1000</b> as sensor fusion <b>1005</b> is performed for the new images received in first video <b>900.</b> </div>
    </li> <li> <para-num num="[0096]"> </para-num> <div num="p0096" class="description-line">The illustrations of the processing of imaging data in <figref idrefs="f0009 f0010 f0011"> <b>Figures 9-11</b> </figref> are not meant to imply limitations to the manner in which an illustrative embodiment may be implemented. For example, in other illustrative examples, other types of video may also be used. For example, sensor fusion <b>1005</b> may be performed using video generated by a radar imaging system in addition to first video <b>900</b> and second video <b>902</b> in <figref idrefs="f0009"> <b>Figure 9</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0097]"> </para-num> <div num="p0097" class="description-line">With reference now to <figref idrefs="f0012"> <b>Figure 12</b> </figref> <b>,</b> an illustration of a flowchart of a process for processing images is depicted in accordance with an illustrative embodiment. The process illustrated in <figref idrefs="f0012"> <b>Figure 12</b> </figref> may be implemented using data processing module <b>206</b> in <figref idrefs="f0002"> <b>Figures 2</b> </figref> and <figref idrefs="f0003"> <b>3</b> </figref> <b>.</b> In particular, this process may be implemented using feature detection module <b>302</b> and registration module <b>304</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0098]"> </para-num> <div num="p0098" class="description-line">The process begins by receiving a sequence of images for a scene received from an imaging system (operation <b>1200).</b> In operation <b>1200,</b> this sequence of images may take the form of video. The viewpoint of the imaging system from which the sequence of images is generated may change. For example, the imaging system may be a video camera mounted to the bottom of an aircraft. As the aircraft flies over the scene, the viewpoint of the imaging system changes.</div>
    </li> <li> <para-num num="[0099]"> </para-num> <div num="p0099" class="description-line">The process then detects a number of objects in the scene using the sequence of images (operation <b>1202).</b> For example, the number of objects may include pedestrians, vehicles, and/or other suitable types of objects. The process generates a number of tracks for the number of objects (operation <b>1204).</b> In operation <b>1204,</b> these tracks may track the movement of the number of objects in the scene over time in the sequence of images.</div>
    </li> <li> <para-num num="[0100]"> </para-num> <div num="p0100" class="description-line">Thereafter, the process registers the viewpoint of the imaging system to a model of the scene using a number of regions in the model of the scene in which a number of expected behaviors of the number of objects is observed to occur (operation <b>1206).</b> In operation <b>1206,</b> the model may be, for example, a two-dimensional map of the scene for which the sequence of images was generated. The number of objects detected may be, for example, vehicles. Vehicles are expected to travel on roads. The tracks generated for the vehicles, as well as any roads on the map of the scene, may be used to register the viewpoint of the imaging system to the map of the scene. In these illustrative examples, operation <b>1206</b> may be performed using state estimation algorithm <b>333</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0101]"> </para-num> <div num="p0101" class="description-line">Next, the process projects the number of tracks for the number of objects onto the model of the scene to form a number of projections (operation <b>1208),</b> with the process terminating thereafter. In particular, operation <b>1208</b> is performed based on the registration of the viewpoint of the imaging system to the model in operation <b>1206.</b> </div>
    </li> <li> <para-num num="[0102]"> </para-num> <div num="p0102" class="description-line">With reference now to <figref idrefs="f0013"> <b>Figure 13</b> </figref> <b>,</b> an illustration of a flowchart of a process for performing sensor fusion is depicted in accordance with an illustrative embodiment. The process illustrated in <figref idrefs="f0013"> <b>Figure 13</b> </figref> may be implemented using data processing module <b>206</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> and <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> In particular, this process may be implemented using fusion module <b>306</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0103]"> </para-num> <div num="p0103" class="description-line">The process begins by identifying a first number of projections and a second number of projections of a first number of tracks and a second number of tracks, respectively, onto a model of a scene (operation <b>1300).</b> The first number of projections and the second number of projections may have been formed using the process illustrated in <figref idrefs="f0012"> <b>Figure 12</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0104]"> </para-num> <div num="p0104" class="description-line">In particular, the first number of projections may have been formed by projecting a first number of tracks generated using imaging data for the scene from a first type of imaging system onto the model of the scene. The second number of projections may have been formed by projecting a second number of tracks generated using imaging data for the scene from a second type of imaging system onto the model of the scene. The process illustrated in <figref idrefs="f0012"> <b>Figure 12</b> </figref> may be used to process the imaging data received from the first type of imaging system and the imaging data from the second type of imaging system.</div>
    </li> <li> <para-num num="[0105]"> </para-num> <div num="p0105" class="description-line">The process then identifies a set of projection pairs using the first number of projections and the second number of projections (operation <b>1302).</b> Each projection pair in the set of projection pairs include a projection from the first number of projections and a projection from the second number of projections that are closest to each other with respect to a coordinate system for the model.</div>
    </li> <li> <para-num num="[0106]"> </para-num> <div num="p0106" class="description-line">In some cases, the set of projection pairs may be an empty set. For example, if at least one projection from the first number of projections is not within a selected distance from a projection in the second number of projections, the set of projection pairs may be an empty set.</div>
    </li> <li> <para-num num="[0107]"> </para-num> <div num="p0107" class="description-line">Next, the process determines whether the set of projection pairs is an empty set (operation <b>1304).</b> If the set is not an empty set, the process selects an unprocessed projection pair (operation <b>1306).</b> Thereafter, the process determines whether a distance between the projections in the selected projection pair is less than a selected threshold (operation <b>1308).</b> When the distance between the projections in the selected projection pair is less than the selected threshold, the two projections may be considered to be projections for the same object. In other words, the projections may be for tracks of the same object.</div>
    </li> <li> <para-num num="[0108]"> </para-num> <div num="p0108" class="description-line">In operation <b>1308,</b> if the distance between the projections in the selected projection pair is less than a selected threshold, the process identifies a centroid of the two projections as a final projection for an object (operation <b>1310).</b> Next, the process adds the final projection to a group of final projections (operation <b>1312).</b> </div>
    </li> <li> <para-num num="[0109]"> </para-num> <div num="p0109" class="description-line">The process then determines whether any additional unprocessed projection pairs are present in the set of projection pairs (operation <b>1314).</b> If additional unprocessed projection pairs are present in the set of projection pairs, the process returns to operation <b>1306</b> as described above. Otherwise, if additional unprocessed projection pairs are not present in the set of projection pairs, the process adds any projections remaining in the first number of projections and the second number of projections not included in the set of projection pairs to the group of final projections (operation <b>1316),</b> with the process terminating thereafter.</div>
    </li> <li> <para-num num="[0110]"> </para-num> <div num="p0110" class="description-line">With reference again to operation <b>1308,</b> if the distance between the projections in the selected projection pair is not less than the selected threshold, the process adds these two projections to the group of final projections (operation <b>1318).</b> The process then proceeds to operation <b>1314</b> as described above. Further, with reference again to operation <b>1304,</b> if the set of projection pairs is an empty set, the process proceeds to operation <b>1316</b> as described above.</div>
    </li> <li> <para-num num="[0111]"> </para-num> <div num="p0111" class="description-line">In this illustrative example, the group of final projections is the result of sensor fusion of the imaging data generated by the first type of imaging system and the imaging data generated by the second type of imaging system. The group of final projections may more accurately track the objects in the scene as compared to the first number of projections or the second number of projections.</div>
    </li> <li> <para-num num="[0112]"> </para-num> <div num="p0112" class="description-line">With reference now to <figref idrefs="f0014"> <b>Figure 14</b> </figref> <b>,</b> an illustration of a flowchart of a process for using sensor fusion to improve tracking the movement of objects in a scene is depicted in accordance with an illustrative embodiment. The process illustrated in <figref idrefs="f0014"> <b>Figure 14</b> </figref> may be implemented using, for example, data processing module <b>206</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> and <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> In particular, this process may be implemented using feature detection module <b>302,</b> registration module <b>304,</b> fusion module <b>306,</b> and back-projection module <b>308</b> in <figref idrefs="f0003"> <b>Figure 3</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0113]"> </para-num> <div num="p0113" class="description-line">The process begins by receiving a first video for a scene from a first type of imaging system and a second video for the scene from a second type of imaging system (operation <b>1400).</b> In operation <b>1400,</b> the first video and the second video for the scene are received in substantially real-time in this illustrative example.</div>
    </li> <li> <para-num num="[0114]"> </para-num> <div num="p0114" class="description-line">The process generates first tracks for objects in the scene detected in the first video and second tracks for objects in the scene detected in the second video (operation <b>1402).</b> The first tracks and the second tracks may be for the same and/or different objects in the scene. Next, the process registers a viewpoint of the first type of imaging system to a model of the scene using the first tracks and a viewpoint of the second type of imaging system to the model of the scene using the second tracks (operation <b>1404).</b> This registration may be performed using the process illustrated in <figref idrefs="f0012"> <b>Figure 12</b> </figref> <b>.</b> In particular, operation <b>1404</b> may be performed using operation <b>1206</b> in <figref idrefs="f0012"> <b>Figure 12</b> </figref> <b>.</b> </div>
    </li> <li> <para-num num="[0115]"> </para-num> <div num="p0115" class="description-line">The process then projects the first tracks onto the model to form first projections and project second tracks onto the model to form second projections (operation <b>1406).</b> These projections track the movement of the objects in the scene with respect to the model of the scene.</div>
    </li> <li> <para-num num="[0116]"> </para-num> <div num="p0116" class="description-line">Thereafter, the process performs sensor fusion to form final projections tracking the movement of the objects with respect to the model of the scene (operation <b>1408).</b> Operation <b>1408</b> may be performed using the process described in <figref idrefs="f0013"> <b>Figure 13</b> </figref> <b>.</b> The process then back-projects the final projections onto the first video and the second video (operation <b>1410).</b> </div>
    </li> <li> <para-num num="[0117]"> </para-num> <div num="p0117" class="description-line">The process uses these back-projections to update the first tracks generated using the first video and the second tracks generated using the second video (operation <b>1412).</b> In operation <b>1412,</b> updating the first tracks and the second tracks may include updating a position of the tracks with respect to the first video and the second video, adding additional tracks, removing tracks, and/or performing other suitable operations. In these illustrative examples, the process then returns to operation <b>1404</b> using the updated first tracks and the updated second tracks to register the viewpoints of the imaging systems to the models.</div>
    </li> <li> <para-num num="[0118]"> </para-num> <div num="p0118" class="description-line">In this manner, the sensor fusion may be used to improve the accuracy with which objects in the scene are tracked in the first video and the second video for the scene. Further, the final projections formed by the sensor fusion may be used to improve the registration of the viewpoints of the imaging systems to the model of the scene.</div>
    </li> <li> <para-num num="[0119]"> </para-num> <div num="p0119" class="description-line">The flowcharts and block diagrams in the different depicted embodiments illustrate the architecture, functionality, and operation of some possible implementations of apparatus and methods in an illustrative embodiment. In this regard, each block in the flowcharts or block diagrams may represent a module, segment, function, and/or a portion of an operation or step. For example, one or more of the blocks may be implemented as program code, in hardware, or a combination of the program code and hardware. When implemented in hardware, the hardware may, for example, take the form of integrated circuits that are manufactured or configured to perform one or more operations in the flowcharts or block diagrams.</div>
    </li> <li> <para-num num="[0120]"> </para-num> <div num="p0120" class="description-line">In some alternative implementations of an illustrative embodiment, the function or functions noted in the block may occur out of the order noted in the figures. For example, in some cases, two blocks shown in succession may be executed substantially concurrently, or the blocks may sometimes be performed in the reverse order, depending upon the functionality involved. Also, other blocks may be added in addition to the illustrated blocks in a flowchart or block diagram.</div>
    </li> <li> <para-num num="[0121]"> </para-num> <div num="p0121" class="description-line">In these different illustrative embodiments, one method for implementing state estimation algorithm <b>333</b> from <figref idrefs="f0003"> <b>Figure 3</b> </figref> may be in the form of a condensation algorithm, otherwise known as a particle filter. This condensation algorithm is used to identify the state of an imaging system, such as first imaging system <b>212</b> or second imaging system <b>214</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> <b>.</b> The state space, <i>X<sup>t</sup>,</i> for registration of an imaging system may be defined using position and orientation of the imaging system at a given point in time, <i>t</i>.</div>
    </li> <li> <para-num num="[0122]"> </para-num> <div num="p0122" class="description-line">The relationship between the state of the imaging system and the observation of the state of the imaging system may be simplified as follows: <maths id="math0001" num="(1)"> <math display="block"> <msup> <mi>Z</mi> <mi>t</mi> </msup> <mo>=</mo> <mi>f</mi> <mfenced> <msup> <mi>X</mi> <mi>t</mi> </msup> </mfenced> <mo>=</mo> <msup> <mi>X</mi> <mi>t</mi> </msup> <mo>+</mo> <msup> <mi>n</mi> <mi>t</mi> </msup> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/6d/e7/cd/a7fe4db3d4e469/imgb0001.png"><img id="ib0001" file="imgb0001.tif" wi="153" he="12" img-content="math" img-format="tif" width="612" height="48" alt="Figure imgb0001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/6d/e7/cd/a7fe4db3d4e469/imgb0001.png"/></a></div> </maths> <br/>
where <i>Z<sup>t</sup> </i> is the observation of the state of the imaging system at time, <i>t</i>, and <i>n<sup>t</sup> </i> is the noise at time, <i>t</i>.</div>
    </li> <li> <para-num num="[0123]"> </para-num> <div num="p0123" class="description-line">The condensation algorithm is based on factored sampling but is extended to apply iteratively to successive images in a sequence. At each time-step, the process is a self-contained iteration of factored sampling. The output of an iteration will be a weighted, time stamped sample set, denoted <maths id="math0002" num=""> <math display="inline"> <mfenced open="{" close="}" separators=""> <msubsup> <mi>s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>,</mo> <mi>n</mi> <mo>=</mo> <mn>1</mn> <mo></mo> <mi>N</mi> </mfenced> <mn>.</mn> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/98/da/2f/4676d47931b5fc/imgb0002.png"><img id="ib0002" file="imgb0002.tif" wi="34" he="12" img-content="math" img-format="tif" inline="yes" width="136" height="48" alt="Figure imgb0002" class="patent-full-image" src="https://patentimages.storage.googleapis.com/98/da/2f/4676d47931b5fc/imgb0002.png"/></a></div> </maths> with weights <maths id="math0003" num=""> <math display="inline"> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>,</mo> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/be/02/c8/0ab4a133e6f845/imgb0003.png"><img id="ib0003" file="imgb0003.tif" wi="12" he="12" img-content="math" img-format="tif" inline="yes" width="48" height="48" alt="Figure imgb0003" class="patent-full-image" src="https://patentimages.storage.googleapis.com/be/02/c8/0ab4a133e6f845/imgb0003.png"/></a></div> </maths> representing approximately the conditional state-density <i>pxtZt</i> at time, <i>t,</i> where the sample set is the set of particles, <i>n</i> is an index, and <i>N</i> is the total number of samples or particles.</div>
    </li> <li> <para-num num="[0124]"> </para-num> <div num="p0124" class="description-line">In particular, the condensation algorithm updates a set of particles, <maths id="math0004" num=""> <math display="inline"> <mfenced open="{" close="}" separators=""> <msubsup> <mi>s</mi> <mrow> <mi>t</mi> <mo>-</mo> <mn>1</mn> </mrow> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>,</mo> <mi>n</mi> <mo>=</mo> <mn>1</mn> <mo></mo> <mi>N</mi> </mfenced> <mo>,</mo> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/be/33/e3/9984da6ce76d5d/imgb0004.png"><img id="ib0004" file="imgb0004.tif" wi="41" he="14" img-content="math" img-format="tif" inline="yes" width="164" height="56" alt="Figure imgb0004" class="patent-full-image" src="https://patentimages.storage.googleapis.com/be/33/e3/9984da6ce76d5d/imgb0004.png"/></a></div> </maths> <br/>
and their weights, <maths id="math0005" num=""> <math display="inline"> <mfenced open="{" close="}" separators=""> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>,</mo> <mi>n</mi> <mo>=</mo> <mn>1</mn> <mo></mo> <mi>N</mi> </mfenced> <mo>,</mo> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/f7/ed/e3/d7cbb99d3204f6/imgb0005.png"><img id="ib0005" file="imgb0005.tif" wi="35" he="13" img-content="math" img-format="tif" inline="yes" width="140" height="52" alt="Figure imgb0005" class="patent-full-image" src="https://patentimages.storage.googleapis.com/f7/ed/e3/d7cbb99d3204f6/imgb0005.png"/></a></div> </maths> from which the posterior mean of the state of the imaging system may be computed. The posterior mean is an estimate of the state of the imaging system given the set of observation and may be computed as follows: <maths id="math0006" num="(2)"> <math display="block"> <msub> <mover> <mi>x</mi> <mo>^</mo> </mover> <mi>t</mi> </msub> <mo>=</mo> <mi>E</mi> <mfenced open="[" close="]" separators=""> <mi>x</mi> <mrow> <mo>|</mo> <mi>z</mi> </mrow> </mfenced> <mo>=</mo> <mstyle displaystyle="false"> <munderover> <mo></mo> <mrow> <mi>n</mi> <mo>=</mo> <mn>1</mn> </mrow> <mi>N</mi> </munderover> </mstyle> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo></mo> <msubsup> <mi>s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/0e/27/9f/52f8c00e3d39d4/imgb0006.png"><img id="ib0006" file="imgb0006.tif" wi="151" he="14" img-content="math" img-format="tif" width="604" height="56" alt="Figure imgb0006" class="patent-full-image" src="https://patentimages.storage.googleapis.com/0e/27/9f/52f8c00e3d39d4/imgb0006.png"/></a></div> </maths> <br/>
where <i>x<sub>t</sub> </i> is the posterior mean of the state at time, t; and <i>E</i>[<i>x</i>|<i>z</i>] is the estimate of the state, x, of the imaging system given the observation, z.</div>
    </li> <li> <para-num num="[0125]"> </para-num> <div num="p0125" class="description-line">The condensation algorithm is an iterative process. From the &#34;old&#34; sample set, <maths id="math0007" num=""> <math display="inline"> <mfenced open="{" close="}" separators=""> <msubsup> <mi>s</mi> <mrow> <mi>t</mi> <mo>-</mo> <mn>1</mn> </mrow> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>,</mo> <msubsup> <mi></mi> <mrow> <mi>t</mi> <mo>-</mo> <mn>1</mn> </mrow> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>,</mo> <msubsup> <mi>c</mi> <mrow> <mi>t</mi> <mo>-</mo> <mn>1</mn> </mrow> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>,</mo> <mi>n</mi> <mo>=</mo> <mn>1</mn> <mo></mo> <mo>,</mo> <mi>N</mi> </mfenced> <mo>,</mo> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/d3/5d/71/079584b9285c09/imgb0007.png"><img id="ib0007" file="imgb0007.tif" wi="56" he="14" img-content="math" img-format="tif" inline="yes" width="224" height="56" alt="Figure imgb0007" class="patent-full-image" src="https://patentimages.storage.googleapis.com/d3/5d/71/079584b9285c09/imgb0007.png"/></a></div> </maths> at time <i>t-1,</i> a &#34;new&#34; sample set, <maths id="math0008" num=""> <math display="inline"> <mfenced open="{" close="}" separators=""> <msubsup> <mi>s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo></mo> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo></mo> <msubsup> <mi>c</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </mfenced> <mo>,</mo> <mi>n</mi> <mo>=</mo> <mn>1</mn> <mo></mo> <mo>,</mo> <mi>N</mi> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/fd/6a/5e/4ba8a8b395d089/imgb0008.png"><img id="ib0008" file="imgb0008.tif" wi="55" he="14" img-content="math" img-format="tif" inline="yes" width="220" height="56" alt="Figure imgb0008" class="patent-full-image" src="https://patentimages.storage.googleapis.com/fd/6a/5e/4ba8a8b395d089/imgb0008.png"/></a></div> </maths> , is constructed for time, <i>t.</i> In this illustrative example, <maths id="math0009" num=""> <math display="inline"> <msubsup> <mi>c</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/fb/64/91/371d5dd3c3ae5e/imgb0009.png"><img id="ib0009" file="imgb0009.tif" wi="10" he="9" img-content="math" img-format="tif" inline="yes" width="40" height="36" alt="Figure imgb0009" class="patent-full-image" src="https://patentimages.storage.googleapis.com/fb/64/91/371d5dd3c3ae5e/imgb0009.png"/></a></div> </maths> are the cumulative weights.</div>
    </li> <li> <para-num num="[0126]"> </para-num> <div num="p0126" class="description-line">The <i>n<sup>th</sup> </i> of <i>N</i> new samples are constructed by first selecting a sample, <maths id="math0010" num=""> <math display="inline"> <msubsup> <mi mathvariant="italic">s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mn>.</mn> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/0b/03/db/f8212d6c67320b/imgb0010.png"><img id="ib0010" file="imgb0010.tif" wi="12" he="10" img-content="math" img-format="tif" inline="yes" width="48" height="40" alt="Figure imgb0010" class="patent-full-image" src="https://patentimages.storage.googleapis.com/0b/03/db/f8212d6c67320b/imgb0010.png"/></a></div> </maths> The sample is selected as follows:
</div> </li> </ul> <ol> <li>1) generating a random number <i>r</i>  [0,1], uniformly distributed;</li> <li>2) finding, by binary subdivision, the smallest <i>j</i> for which <maths id="math0011" num=""> <math display="inline"> <msubsup> <mi>c</mi> <mrow> <mi>t</mi> <mo>-</mo> <mn>1</mn> </mrow> <mfenced> <mi>j</mi> </mfenced> </msubsup> <mo></mo> <mi>r</mi> <mo>;</mo> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/44/88/0b/c406a57a75f011/imgb0011.png"><img id="ib0011" file="imgb0011.tif" wi="19" he="10" img-content="math" img-format="tif" inline="yes" width="76" height="40" alt="Figure imgb0011" class="patent-full-image" src="https://patentimages.storage.googleapis.com/44/88/0b/c406a57a75f011/imgb0011.png"/></a></div> </maths> and</li> <li>3) setting <maths id="math0012" num=""> <math display="inline"> <msubsup> <mi mathvariant="italic">s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>=</mo> <msubsup> <mi mathvariant="italic">s</mi> <mrow> <mi>t</mi> <mo>-</mo> <mn>1</mn> </mrow> <mfenced> <mi>j</mi> </mfenced> </msubsup> <mn>.</mn> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/30/32/b7/c3c087a12aa526/imgb0012.png"><img id="ib0012" file="imgb0012.tif" wi="25" he="9" img-content="math" img-format="tif" inline="yes" width="100" height="36" alt="Figure imgb0012" class="patent-full-image" src="https://patentimages.storage.googleapis.com/30/32/b7/c3c087a12aa526/imgb0012.png"/></a></div> </maths> </li> </ol>
    <li> <para-num num="[0127]"> </para-num> <div num="p0127" class="description-line">Then, predictions are made by sampling from <maths id="math0013" num=""> <math display="inline"> <mi>p</mi> <mo></mo> <mfenced separators=""> <msub> <mi>x</mi> <mi>t</mi> </msub> <mrow> <mo>|</mo> <msub> <mi>x</mi> <mrow> <mi>t</mi> <mo>-</mo> <mn>1</mn> </mrow> </msub> <mo>=</mo> <msubsup> <mi mathvariant="italic">s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </mrow> </mfenced> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/6e/79/cc/ba03d530e78ba6/imgb0013.png"><img id="ib0013" file="imgb0013.tif" wi="36" he="12" img-content="math" img-format="tif" inline="yes" width="144" height="48" alt="Figure imgb0013" class="patent-full-image" src="https://patentimages.storage.googleapis.com/6e/79/cc/ba03d530e78ba6/imgb0013.png"/></a></div> </maths> to choose each <maths id="math0014" num=""> <math display="inline"> <msubsup> <mi>s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mn>.</mn> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/37/0c/62/17ea914808272f/imgb0014.png"><img id="ib0014" file="imgb0014.tif" wi="12" he="12" img-content="math" img-format="tif" inline="yes" width="48" height="48" alt="Figure imgb0014" class="patent-full-image" src="https://patentimages.storage.googleapis.com/37/0c/62/17ea914808272f/imgb0014.png"/></a></div> </maths> The new position in terms of the observations, <i>z<sub>t</sub>,</i> is measured and weighted as follows in terms of a modified data likelihood function: <maths id="math0015" num="3"> <math display="block"> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>=</mo> <mi>p</mi> <mfenced separators=""> <msub> <mi>z</mi> <mi>t</mi> </msub> <mrow> <mo>|</mo> <msub> <mi>x</mi> <mi>t</mi> </msub> <mo>=</mo> <msubsup> <mi>s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </mrow> </mfenced> <mo>,</mo> <mi>where</mi> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/94/b8/44/8d4b654cb62186/imgb0015.png"><img id="ib0015" file="imgb0015.tif" wi="140" he="12" img-content="math" img-format="tif" width="560" height="48" alt="Figure imgb0015" class="patent-full-image" src="https://patentimages.storage.googleapis.com/94/b8/44/8d4b654cb62186/imgb0015.png"/></a></div> </maths> <maths id="math0016" num="(4)"> <math display="block"> <mi>P</mi> <mfenced separators=""> <mi>z</mi> <mrow> <mo>|</mo> <mi>x</mi> </mrow> </mfenced> <mo>=</mo> <msub> <mi>P</mi> <mi>a</mi> </msub> <mfenced separators=""> <mi>z</mi> <mrow> <mo>|</mo> <mi>x</mi> </mrow> </mfenced> <mo></mo> <msub> <mi>P</mi> <mi>b</mi> </msub> <mfenced separators=""> <mi>z</mi> <mrow> <mo>|</mo> <mi>x</mi> </mrow> </mfenced> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/e2/bc/f4/dd613231e1774a/imgb0016.png"><img id="ib0016" file="imgb0016.tif" wi="140" he="9" img-content="math" img-format="tif" width="560" height="36" alt="Figure imgb0016" class="patent-full-image" src="https://patentimages.storage.googleapis.com/e2/bc/f4/dd613231e1774a/imgb0016.png"/></a></div> </maths> <maths id="math0017" num="(5)"> <math display="block"> <msub> <mi>P</mi> <mi>a</mi> </msub> <mfenced separators=""> <mi>z</mi> <mrow> <mo>|</mo> <mi>x</mi> </mrow> </mfenced> <mo></mo> <mi mathvariant="italic">exp</mi> <mfenced> <msubsup> <mrow> <mo></mo> <mi>z</mi> <mo>-</mo> <mi>x</mi> <mo></mo> </mrow> <msup> <mi mathvariant="normal"></mi> <mrow> <mo>-</mo> <mn>1</mn> </mrow> </msup> <mn>2</mn> </msubsup> </mfenced> <mo>,</mo> <mi>and</mi> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/fb/4a/28/2a3ff2dcfdc8bd/imgb0017.png"><img id="ib0017" file="imgb0017.tif" wi="140" he="9" img-content="math" img-format="tif" width="560" height="36" alt="Figure imgb0017" class="patent-full-image" src="https://patentimages.storage.googleapis.com/fb/4a/28/2a3ff2dcfdc8bd/imgb0017.png"/></a></div> </maths> <maths id="math0018" num="(6)"> <math display="block"> <msub> <mi>P</mi> <mrow> <mi>b</mi> <mo>,</mo> <mi>s</mi> </mrow> </msub> <mfenced separators=""> <mi>z</mi> <mrow> <mo>|</mo> <mi>x</mi> </mrow> </mfenced> <mo>=</mo> <mrow> <mo>{</mo> <mtable> <mtr> <mtd columnalign="left"> <mi></mi> </mtd> <mtd> <mi mathvariant="italic">if x</mi> <mo></mo> <mn>0</mn> </mtd> </mtr> <mtr> <mtd columnalign="left"> <mn>1</mn> <mo>-</mo> <mi>a</mi> </mtd> <mtd> <mi mathvariant="italic">if x</mi> <mo></mo> <mn>0</mn> </mtd> </mtr> </mtable> </mrow> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/7b/ea/e0/5e6f5b1cec88ee/imgb0018.png"><img id="ib0018" file="imgb0018.tif" wi="140" he="14" img-content="math" img-format="tif" width="560" height="56" alt="Figure imgb0018" class="patent-full-image" src="https://patentimages.storage.googleapis.com/7b/ea/e0/5e6f5b1cec88ee/imgb0018.png"/></a></div> </maths> <br/>
where the set <i>O</i> is the set of points in the scene in which, according to a priori geospatial data, expected behaviors and expected detections of objects is most likely to occur. For example, if vehicles are being detected, the set <i>O</i> may include the points in the scene that correspond to roads. In this illustrative example, the constant, , may be set to a value between about 0.5 and about 1.</div>
    </li> <li> <para-num num="[0128]"> </para-num> <div num="p0128" class="description-line">In this example, <i>P</i>(<i>z</i>|<i>x</i>) is the data likelihood function that describes the probability of an observation, z, being made given the current state, x, and incorporates the expected behaviors of objects with respect to the scene. This function is also referred to as a data likelihood density or data likelihood density function. The data likelihood function is categorized into two functions, also referred to as densities.</div>
    </li> <li> <para-num num="[0129]"> </para-num> <div num="p0129" class="description-line">The first function, expressed in equation (5) is a function of the distance from the current state capturing the noise of the imaging system. In other words, the first function takes into account noise of the imaging system. The second function, expressed in equation (6), determines whether a detection of the object in the scene is at a location in the region in the model of the scene in which an expected behavior of the object is expected to occur. In other words, the second function determines whether the observation is located in a high likelihood geospatial region.</div>
    </li> <li> <para-num num="[0130]"> </para-num> <div num="p0130" class="description-line">Next, the results are normalized such that: <maths id="math0019" num="(7)"> <math display="block"> <mstyle displaystyle="false"> <mstyle displaystyle="false"> <munder> <mo></mo> <mi>n</mi> </munder> </mstyle> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </mstyle> <mo>=</mo> <mn>1.</mn> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/74/d1/90/e5f626e4aed7ba/imgb0019.png"><img id="ib0019" file="imgb0019.tif" wi="125" he="9" img-content="math" img-format="tif" width="500" height="36" alt="Figure imgb0019" class="patent-full-image" src="https://patentimages.storage.googleapis.com/74/d1/90/e5f626e4aed7ba/imgb0019.png"/></a></div> </maths> <br/>
The results are stored with cumulative probability as <maths id="math0020" num=""> <math display="inline"> <mfenced separators=""> <msubsup> <mi>s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo></mo> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo></mo> <msubsup> <mi>c</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </mfenced> <mo>,</mo> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/4c/a4/a5/19476216c83877/imgb0020.png"><img id="ib0020" file="imgb0020.tif" wi="30" he="9" img-content="math" img-format="tif" inline="yes" width="120" height="36" alt="Figure imgb0020" class="patent-full-image" src="https://patentimages.storage.googleapis.com/4c/a4/a5/19476216c83877/imgb0020.png"/></a></div> </maths>where <maths id="math0021" num="(8)"> <math display="block"> <msubsup> <mi>c</mi> <mi>t</mi> <mfenced> <mn>0</mn> </mfenced> </msubsup> <mo>=</mo> <mn>0</mn> <mo>,</mo> <mspace width="1em"> </mspace> <mi>and</mi> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/9c/86/94/d548d7a2771098/imgb0021.png"><img id="ib0021" file="imgb0021.tif" wi="148" he="9" img-content="math" img-format="tif" width="592" height="36" alt="Figure imgb0021" class="patent-full-image" src="https://patentimages.storage.googleapis.com/9c/86/94/d548d7a2771098/imgb0021.png"/></a></div> </maths> <maths id="math0022" num="(9)"> <math display="block"> <msubsup> <mi>c</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo>=</mo> <msubsup> <mi>c</mi> <mi>t</mi> <mfenced separators=""> <mi>n</mi> <mo>-</mo> <mn>1</mn> </mfenced> </msubsup> <mo>+</mo> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mspace width="1em"> </mspace> <mfenced separators=""> <mi>n</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo></mo> <mo>,</mo> <mi>N</mi> </mfenced> <mn>.</mn> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/d4/99/e6/87fb20af07fc38/imgb0022.png"><img id="ib0022" file="imgb0022.tif" wi="148" he="10" img-content="math" img-format="tif" width="592" height="40" alt="Figure imgb0022" class="patent-full-image" src="https://patentimages.storage.googleapis.com/d4/99/e6/87fb20af07fc38/imgb0022.png"/></a></div> </maths> </div>
    </li> <li> <para-num num="[0131]"> </para-num> <div num="p0131" class="description-line">Once the N samples have been constructed, moments of the tracked position at time, t, may be estimated as follows: <maths id="math0023" num="(10)"> <math display="block"> <mi></mi> <mfenced open="[" close="]" separators=""> <mi>f</mi> <mfenced> <msub> <mi>x</mi> <mi>t</mi> </msub> </mfenced> </mfenced> <mo>=</mo> <mstyle displaystyle="false"> <munderover> <mo></mo> <mrow> <mi>n</mi> <mo>=</mo> <mn>1</mn> </mrow> <mi>N</mi> </munderover> </mstyle> <msubsup> <mi></mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> <mo></mo> <mi>f</mi> <mfenced> <msubsup> <mi>s</mi> <mi>t</mi> <mfenced> <mi>n</mi> </mfenced> </msubsup> </mfenced> <mo>,</mo> </math> <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/e4/d1/e5/3de7116a284663/imgb0023.png"><img id="ib0023" file="imgb0023.tif" wi="137" he="12" img-content="math" img-format="tif" width="548" height="48" alt="Figure imgb0023" class="patent-full-image" src="https://patentimages.storage.googleapis.com/e4/d1/e5/3de7116a284663/imgb0023.png"/></a></div> </maths> <br/>
such that a mean position may be obtained using f(x) = x. In this manner, the condensation algorithm takes into account the probability of an observation, z, being made given the current state, x, to estimate the state of the imaging system.</div>
    </li> <li> <para-num num="[0132]"> </para-num> <div num="p0132" class="description-line">Turning now to <figref idrefs="f0015"> <b>Figure 15</b> </figref> <b>,</b> an illustration of a data processing system is depicted in accordance with an illustrative embodiment. In this illustrative example, data processing system <b>1500</b> may be used to implement one or more computers in computer system <b>226</b> in <figref idrefs="f0002"> <b>Figure 2</b> </figref> <b>.</b> Data processing system <b>1500</b> includes communications fabric <b>1502,</b> which provides communications between processor unit <b>1504,</b> memory <b>1506,</b> persistent storage <b>1508,</b> communications unit <b>1510,</b> input/output (I/O) unit <b>1512,</b> and display <b>1514.</b> </div>
    </li> <li> <para-num num="[0133]"> </para-num> <div num="p0133" class="description-line">Processor unit <b>1504</b> serves to execute instructions for software that may be loaded into memory <b>1506.</b> Processor unit <b>1504</b> may be a number of processors, a multi-processor core, or some other type of processor, depending on the particular implementation. A number, as used herein with reference to an item, means one or more items. Further, processor unit <b>1504</b> may be implemented using a number of heterogeneous processor systems in which a main processor is present with secondary processors on a single chip. As another illustrative example, processor unit <b>1504</b> may be a symmetric multi-processor system containing multiple processors of the same type.</div>
    </li> <li> <para-num num="[0134]"> </para-num> <div num="p0134" class="description-line">Memory <b>1506</b> and persistent storage <b>1508</b> are examples of storage devices <b>1516.</b> A storage device is any piece of hardware that is capable of storing information, such as, for example, without limitation, data, program code in functional form, and/or other suitable information either on a temporary basis and/or a permanent basis. Storage devices <b>1516</b> may also be referred to as computer readable storage devices in these examples. Memory <b>1506,</b> in these examples, may be, for example, a random access memory or any other suitable volatile or non-volatile storage device. Persistent storage <b>1508</b> may take various forms, depending on the particular implementation.</div>
    </li> <li> <para-num num="[0135]"> </para-num> <div num="p0135" class="description-line">For example, persistent storage <b>1508</b> may contain one or more components or devices. For example, persistent storage <b>1508</b> may be a hard drive, a flash memory, a rewritable optical disk, a rewritable magnetic tape, or some combination of the above. The media used by persistent storage <b>1508</b> also may be removable. For example, a removable hard drive may be used for persistent storage <b>1508.</b> </div>
    </li> <li> <para-num num="[0136]"> </para-num> <div num="p0136" class="description-line">Communications unit <b>1510,</b> in these examples, provides for communications with other data processing systems or devices. In these examples, communications unit <b>1510</b> is a network interface card. Communications unit <b>1510</b> may provide communications through the use of either or both physical and wireless communications links.</div>
    </li> <li> <para-num num="[0137]"> </para-num> <div num="p0137" class="description-line">Input/output unit <b>1512</b> allows for input and output of data with other devices that may be connected to data processing system <b>1500.</b> For example, input/output unit <b>1512</b> may provide a connection for user input through a keyboard, a mouse, and/or some other suitable input device. Further, input/output unit <b>1512</b> may send output to a printer. Display <b>1514</b> provides a mechanism to display information to a user.</div>
    </li> <li> <para-num num="[0138]"> </para-num> <div num="p0138" class="description-line">Instructions for the operating system, applications, and/or programs may be located in storage devices <b>1516,</b> which are in communication with processor unit <b>1504</b> through communications fabric <b>1502.</b> In these illustrative examples, the instructions are in a functional form on persistent storage <b>1508.</b> These instructions may be loaded into memory <b>1506</b> for execution by processor unit <b>1504.</b> The processes of the different embodiments may be performed by processor unit <b>1504</b> using computer-implemented instructions, which may be located in a memory, such as memory <b>1506.</b> </div>
    </li> <li> <para-num num="[0139]"> </para-num> <div num="p0139" class="description-line">These instructions are referred to as program code, computer usable program code, or computer readable program code that may be read and executed by a processor in processor unit <b>1504.</b> The program code in the different embodiments may be embodied on different physical or computer readable storage media, such as memory <b>1506</b> or persistent storage <b>1508.</b> </div>
    </li> <li> <para-num num="[0140]"> </para-num> <div num="p0140" class="description-line">Program code <b>1518</b> is located in a functional form on computer readable media <b>1520</b> that is selectively removable and may be loaded onto or transferred to data processing system <b>1500</b> for execution by processor unit <b>1504.</b> Program code <b>1518</b> and computer readable media <b>1520</b> form computer program product <b>1522</b> in these examples. In one example, computer readable media <b>1520</b> may be computer readable storage media <b>1524</b> or computer readable signal media <b>1526.</b> Computer readable storage media <b>1524</b> may include, for example, an optical or magnetic disk that is inserted or placed into a drive or other device that is part of persistent storage <b>1508</b> for transfer onto a storage device, such as a hard drive, that is part of persistent storage <b>1508.</b> </div>
    </li> <li> <para-num num="[0141]"> </para-num> <div num="p0141" class="description-line">Computer readable storage media <b>1524</b> also may take the form of a persistent storage, such as a hard drive, a thumb drive, or a flash memory, that is connected to data processing system <b>1500.</b> In some instances, computer readable storage media <b>1524</b> may not be removable from data processing system <b>1500.</b> In these examples, computer readable storage media <b>1524</b> is a physical or tangible storage device used to store program code <b>1518</b> rather than a medium that propagates or transmits program code <b>1518.</b> Computer readable storage media <b>1524</b> is also referred to as a computer readable tangible storage device or a computer readable physical storage device. In other words, computer readable storage media <b>1524</b> is a media that can be touched by a person.</div>
    </li> <li> <para-num num="[0142]"> </para-num> <div num="p0142" class="description-line">Alternatively, program code <b>1518</b> may be transferred to data processing system <b>1500</b> using computer readable signal media <b>1526.</b> Computer readable signal media <b>1526</b> may be, for example, a propagated data signal containing program code <b>1518.</b> For example, computer readable signal media <b>1526</b> may be an electromagnetic signal, an optical signal, and/or any other suitable type of signal. These signals may be transmitted over communications links, such as wireless communications links, optical fiber cable, coaxial cable, a wire, and/or any other suitable type of communications link. In other words, the communications link and/or the connection may be physical or wireless in the illustrative examples.</div>
    </li> <li> <para-num num="[0143]"> </para-num> <div num="p0143" class="description-line">In some illustrative embodiments, program code <b>1518</b> may be downloaded over a network to persistent storage <b>1508</b> from another device or data processing system through computer readable signal media <b>1526</b> for use within data processing system <b>1500.</b> For instance, program code stored in a computer readable storage medium in a server data processing system may be downloaded over a network from the server to data processing system <b>1500.</b> The data processing system providing program code <b>1518</b> may be a server computer, a client computer, or some other device capable of storing and transmitting program code <b>1518.</b> </div>
    </li> <li> <para-num num="[0144]"> </para-num> <div num="p0144" class="description-line">The different components illustrated for data processing system <b>1500</b> are not meant to provide architectural limitations to the manner in which different embodiments may be implemented. The different illustrative embodiments may be implemented in a data processing system including components in addition to or in place of those illustrated for data processing system <b>1500.</b> Other components shown in <figref idrefs="f0015"> <b>Figure 15</b> </figref> can be varied from the illustrative examples shown. The different embodiments may be implemented using any hardware device or system capable of running program code. As one example, the data processing system may include organic components integrated with inorganic components and/or may be comprised entirely of organic components excluding a human being. For example, a storage device may be comprised of an organic semiconductor.</div>
    </li> <li> <para-num num="[0145]"> </para-num> <div num="p0145" class="description-line">In another illustrative example, processor unit <b>1504</b> may take the form of a hardware unit that has circuits that are manufactured or configured for a particular use. This type of hardware may perform operations without needing program code to be loaded into a memory from a storage device to be configured to perform the operations.</div>
    </li> <li> <para-num num="[0146]"> </para-num> <div num="p0146" class="description-line">For example, when processor unit <b>1504</b> takes the form of a hardware unit, processor unit <b>1504</b> may be a circuit system, an application specific integrated circuit (ASIC), a programmable logic device, or some other suitable type of hardware configured to perform a number of operations. With a programmable logic device, the device is configured to perform the number of operations. The device may be reconfigured at a later time or may be permanently configured to perform the number of operations. Examples of programmable logic devices include, for example, a programmable logic array, a field programmable logic array, a field programmable gate array, and other suitable hardware devices. With this type of implementation, program code <b>1518</b> may be omitted, because the processes for the different embodiments are implemented in a hardware unit.</div>
    </li> <li> <para-num num="[0147]"> </para-num> <div num="p0147" class="description-line">In still another illustrative example, processor unit <b>1504</b> may be implemented using a combination of processors found in computers and hardware units. Processor unit <b>1504</b> may have a number of hardware units and a number of processors that are configured to run program code <b>1518.</b> With this depicted example, some of the processes may be implemented in the number of hardware units, while other processes may be implemented in the number of processors.</div>
    </li> <li> <para-num num="[0148]"> </para-num> <div num="p0148" class="description-line">In another example, a bus system may be used to implement communications fabric 1502 and may be comprised of one or more buses, such as a system bus or an input/output bus. Of course, the bus system may be implemented using any suitable type of architecture that provides for a transfer of data between different components or devices attached to the bus system.</div>
    </li> <li> <para-num num="[0149]"> </para-num> <div num="p0149" class="description-line">Additionally, a communications unit may include a number of devices that transmit data, receive data, or transmit and receive data. A communications unit may be, for example, a modem or a network adapter, two network adapters, or some combination thereof. Further, a memory may be, for example, memory <b>1506,</b> or a cache, such as found in an interface and memory controller hub that may be present in communications fabric <b>1502.</b> </div>
    </li> <li> <para-num num="[0150]"> </para-num> <div num="p0150" class="description-line">In the figures and the text, a method is disclosed for processing images, the method comprising: receiving a sequence of images 218 for a scene 102, 222 from an imaging system 212; detecting an object 225 in the scene 102, 222 using the sequence of images 218; and registering a viewpoint 227 of the imaging system 212 to a model of the scene 102, 222 using a region in the model of the scene 102, 222 in which an expected behavior of the object 225 is expected to occur. In one variant, the method further includes: projecting a track for the object 225 onto the model of the scene 102, 222 based on a registration of the viewpoint 227 of the imaging system 212 to the model. In yet another variant, the method includes wherein registering the viewpoint 227 of the imaging system 212 to the model of the scene 102, 222 using the region in the model of the scene 102, 222 in which the expected behavior of the object 225 is expected to occur comprises: estimating a state of the imaging system 212 based on a probability of the state of the imaging system 212 given an identification of the object 225 in the sequence of images 218 of the scene 102, 222.</div>
    </li> <li> <para-num num="[0151]"> </para-num> <div num="p0151" class="description-line">In yet another variant, the method includes wherein the state of the imaging system 212 includes at least one of a position and an orientation of the imaging system 212 with respect to a coordinate system for the model of the scene 102, 222. In yet another variant, the method includes wherein estimating the state of the imaging system 212 based on the probability of the state of the imaging system 212 given the identification of the object in the sequence of images 218 of the scene 102, 222 includes: estimating the state of the imaging system 212 based on the probability of the state of the imaging system (212) given the identification of the object 225 in the sequence of images 218 of the scene 102, 222 using a particle filter.</div>
    </li> <li> <para-num num="[0152]"> </para-num> <div num="p0152" class="description-line">In one alternative, the method includes wherein the expected behavior 328 is expected to occur in the region in the model of the scene 102, 222 for any object 225 of a same type as the object 225. In yet another alternative, the method includes wherein the imaging system 212 is a first imaging system 212, the sequence of images 218 is a first sequence of images 218, the object 225 is a first object, and the viewpoint 227 is a first viewpoint, and further comprising: receiving a second sequence of images 220 for a scene from a second imaging system 214; detecting a second object in the scene 102, 222 using the second sequence of images 220, wherein the second object is the same type as the first object; and registering a second viewpoint 229 of the second imaging system 214 to the model of the scene 102, 222 using the region in the scene 102, 222 in which the expected behavior for the second object is expected to occur.</div>
    </li> <li> <para-num num="[0153]"> </para-num> <div num="p0153" class="description-line">In still another variant, the method further includes: projecting a first track for the first object onto the model of the scene 102, 222 to form a first projection based on a registration of the first viewpoint 227 of the first imaging system 212 to the model of the scene 102, 222; and projecting a second track for the first object onto the model of the scene 102, 222 to form a second projection based on a registration of the second viewpoint 229 of the second imaging system 214 to the model of the scene 102, 222. In yet another variant, the method includes wherein the first projection and the second projection form a projection pair 340 and further comprising: determining whether a distance between the first projection and the second projection with respect to a coordinate system 331 for the model 324 is less than a selected threshold 342; and identifying a centroid of the first projection and the second projection as a final projection when the distance between the first projection and the second projection with respect to the coordinate system 331 for the model is less than the selected threshold 342.</div>
    </li> <li> <para-num num="[0154]"> </para-num> <div num="p0154" class="description-line">In yet another variant, the method of includes wherein estimating the state of the imaging system 212 based on the probability of the state of the imaging system 212 given the identification of the object in the sequence of images 218 of the scene 102, 222 comprises: estimating the state of the imaging system 212 using a condensation algorithm comprising a first function and a second function, wherein the first function takes into account noise of the imaging system 212 and the second function determines whether a detection of the object 225 in the scene 102, 222 is at a location in the region in the model of the scene 102, 222 in which the expected behavior 328 of the object 225 is expected to occur, and wherein the first function and the second function form a data likelihood function. In yet another variant, the method includes wherein the imaging system 212 is selected from one of an electro-optical imaging system, an infrared imaging system, a radar imaging system, a thermal imaging system, and an ultrasound imaging system.</div>
    </li> <li> <para-num num="[0155]"> </para-num> <div num="p0155" class="description-line">In yet another aspect, an apparatus is disclosed including a computer system configured to receive a sequence of images 218, 220 for a scene 102, 222 from an imaging system 212, 214; detect an object 225 in the scene 102, 222 using the sequence of images 218, 220; and register a viewpoint 227, 229 of the imaging system 212, 214 to a model of the scene 102, 222 using a region in the model of the scene 102, 222 in which an expected behavior 328 of the object 225 is expected to occur. In one variant, the apparatus includes wherein the computer system is further configured to project a track for the object onto the model of the scene 102, 222 based on a registration of the viewpoint 227, 229 of the imaging system 212, 214 to the model.</div>
    </li> <li> <para-num num="[0156]"> </para-num> <div num="p0156" class="description-line">In another variant, the apparatus includes wherein in being configured to register the viewpoint 227, 229 of the imaging system 212, 214 to the model of the scene 102, 222 using the region in the model of the scene 102, 222 in which the expected behavior 328 of the object 225 is expected to occur, the computer system is configured to estimate a state 333 of the imaging system 212, 214 based on a probability of the state of the imaging system 212, 214 given an identification of the object in the sequence of images 218, 220 of the scene 102, 222 given.</div>
    </li> <li> <para-num num="[0157]"> </para-num> <div num="p0157" class="description-line">In yet another variant, the apparatus includes wherein the state of the imaging system 212, 214 includes at least one of a position and an orientation of the imaging system 212, 214 with respect to a coordinate system 331 for the model of the scene 102, 222. In still another variant, the apparatus includes, wherein in being configured to estimate the state of the imaging system 212, 214 based on the probability of the state of the imaging system 212, 214 given the identification of the object in the sequence of images 218, 220 of the scene 102, 222, the computer system is configured to estimate the state 332 of the imaging system 212, 214 based on the probability of the state of the imaging system 212, 214 given the identification of the object 225 in the sequence of images 218, 220 of the scene 102, 222 using a particle filter.</div>
    </li> <li> <para-num num="[0158]"> </para-num> <div num="p0158" class="description-line">In one alternative, the apparatus includes wherein the expected behavior 328 is expected to occur in the region in the model of the scene 102,222 for any object 225 of a same type as the object 225. In still another alternative, the apparatus includes wherein the imaging system 212, 214 is a first imaging system 212, the sequence of images 218, 220 is a first sequence of images 218, the object 225 is a first object, and the viewpoint 227, 229 is a first viewpoint 227, and wherein the computer system is further configured to receive a second sequence of images 220 for the scene 102, 222 from a second imaging system 214; and detect a second object in the scene 102, 222 using the second sequence of images 220, wherein the second object is a same type as the first object; and register a second viewpoint of the second imaging system 214 to the model of the scene 102, 222 using the region in the scene 102, 222 in which the expected behavior 328 for the second object is expected to occur. In one variant, the apparatus includes wherein the computer system is further configured to project a first track for the first object onto the model of the scene to form a first projection based on a registration of the first viewpoint 227 of the first imaging system 212 to the model of the scene 102, 222; and project a second track for the first object onto the model of the scene 102, 222 to form a second projection based on a registration of the second viewpoint 229 of the second imaging system 214 to the model of the scene 102, 222. In yet another variant, the apparatus includes wherein the first projection and the second projection form a projection pair 340 and wherein the computer system is configured to determine whether a distance between the first projection and the second projection with respect to a coordinate system 331 for the model is less than a selected threshold 342; and identify a centroid of the first projection and the second projection as a final projection when the distance between the first projection and the second projection with respect to the coordinate system for the model is less than the selected threshold 342.</div>
    </li> <li> <para-num num="[0159]"> </para-num> <div num="p0159" class="description-line">Thus, the different illustrative embodiments provide a method and apparatus for processing images. In one illustrative embodiment, a sequence of images for a scene is received from an imaging system. An object is detected in the scene using the sequence of images. A viewpoint of the imaging system is registered to a model of the scene using a region in the model of the scene in which an expected behavior of the object is expected to occur.</div>
    </li> <li> <para-num num="[0160]"> </para-num> <div num="p0160" class="description-line">The description of the different illustrative embodiments has been presented for purposes of illustration and description and is not intended to be exhaustive or limited to the embodiments in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. Further, different illustrative embodiments may provide different advantages as compared to other illustrative embodiments. The embodiment or embodiments selected are chosen and described in order to best explain the principles of the embodiments, the practical application, and to enable others of ordinary skill in the art to understand the disclosure for various embodiments with various modifications as are suited to the particular use contemplated.</div>
  </li>
  </div></div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">15</span>)</h2>
    
    <div itemprop="content" html><ol mxw-id="PCLM51495389" lang="EN" load-source="patent-office" class="claims">
    
    <li class="claim"> <div id="c-en-0001" num="0001" class="claim">
      <div class="claim-text">A method for processing images, the method comprising:
<div class="claim-text">receiving a sequence of images (218) for a scene (102, 222) from an imaging system (212);</div>
<div class="claim-text">detecting an object (225) in the scene (102, 222) using the sequence of images (218); and</div>
<div class="claim-text">registering a viewpoint (227) of the imaging system (212) to a model of the scene (102, 222) using a region in the model of the scene (102, 222) in which an expected behavior of the object (225) is expected to occur.</div> </div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0002" num="0002" class="claim">
      <div class="claim-text">The method of claim 1 further comprising:
<div class="claim-text">projecting a track for the object (225) onto the model of the scene (102, 222) based on a registration of the viewpoint (227) of the imaging system (212) to the model.</div> </div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0003" num="0003" class="claim">
      <div class="claim-text">The method of any of claims 1 or 2, wherein registering the viewpoint (227) of the imaging system (212) to the model of the scene (102, 222) using the region in the model of the scene (102, 222) in which the expected behavior of the object (225) is expected to occur comprises:
<div class="claim-text">estimating a state of the imaging system (212) based on a probability of the state of the imaging system (212) given an identification of the object (225) in the sequence of images (218) of the scene (102, 222).</div> </div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0004" num="0004" class="claim">
      <div class="claim-text">The method of any of claims 3, wherein the state of the imaging system (212) comprises at least one of a position and an orientation of the imaging system (212) with respect to a coordinate system for the model of the scene (102, 222).</div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0005" num="0005" class="claim">
      <div class="claim-text">The method of claim 3, wherein estimating the state of the imaging system (212) based on the probability of the state of the imaging system (212) given the identification of the object in the sequence of images (218) of the scene comprises:
<div class="claim-text">estimating the state of the imaging system (212) based on the probability of the state of the imaging system (212) given the identification of the object (225) in the sequence of images (218) of the scene (102, 222) using a particle filter.</div> </div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0006" num="0006" class="claim">
      <div class="claim-text">The method of any of claims 1-5, wherein the expected behavior is expected to occur in the region in the model of the scene (102, 222) for any object (225) of a same type as the object (225).</div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0007" num="0007" class="claim">
      <div class="claim-text">The method of any of claims 1-6, wherein the imaging system (212) is a first imaging system (212), the sequence of images (218) is a first sequence of images (218), the object (225) is a first object, and the viewpoint (227) is a first viewpoint, and further comprising:
<div class="claim-text">receiving a second sequence of images (220) for a scene from a second imaging system (214);</div>
<div class="claim-text">detecting a second object in the scene (102, 222) using the second sequence of images (220), wherein the second object is the same type as the first object; and</div>
<div class="claim-text">registering a second viewpoint (229) of the second imaging system (214) to the model of the scene (102, 222) using the region in the scene (102, 222) in which the expected behavior (328) for the second object is expected to occur.</div> </div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0008" num="0008" class="claim">
      <div class="claim-text">The method of claim 7 further comprising:
<div class="claim-text">projecting a first track for the first object onto the model of the scene (102, 222) to form a first projection based on a registration of the first viewpoint (227) of the first imaging system (212) to the model of the scene (102, 222); and</div>
<div class="claim-text">projecting a second track for the first object onto the model of the scene (102, 222) to form a second projection based on a registration of the second viewpoint (229) of the second imaging system (214) to the model of the scene (102, 222).</div> </div>
    </div>
    </li> <li class="claim"> <div id="c-en-0009" num="0009" class="claim">
      <div class="claim-text">An apparatus comprising:
<div class="claim-text">a computer system configured to receive a sequence of images (218, 220) for a scene (102, 222) from an imaging system (212, 214); detect an object (225) in the scene (102, 222) using the sequence of images (218, 220); and register a viewpoint (227, 229) of the imaging system (212, 214) to a model of the scene (102, 222) using a region in the model of the scene (102, 222) in which an expected behavior (328) of the object (225) is expected to occur.</div> </div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0010" num="0010" class="claim">
      <div class="claim-text">The apparatus of claim 9, wherein the computer system is further configured to project a track for the object onto the model of the scene (102, 222) based on a registration of the viewpoint (227, 229) of the imaging system (212, 214) to the model.</div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0011" num="0011" class="claim">
      <div class="claim-text">The apparatus of claim 9, wherein in being configured to register the viewpoint (227, 229) of the imaging system (212, 214) to the model of the scene (102, 222) using the region in the model of the scene (102, 222) in which the expected behavior (328) of the object (225) is expected to occur, the computer system is configured to estimate a state (333) of the imaging system (212, 214) based on a probability of the state of the imaging system (212, 214) given an identification of the object in the sequence of images (218, 220) of the scene (102, 222) given.</div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0012" num="0012" class="claim">
      <div class="claim-text">The apparatus of claim 11, wherein the state of the imaging system (212, 214) comprises at least one of a position and an orientation of the imaging system (212, 214) with respect to a coordinate system (331) for the model of the scene (102, 222).</div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0013" num="0013" class="claim">
      <div class="claim-text">The apparatus of claim 11, wherein in being configured to estimate the state of the imaging system (212, 214) based on the probability of the state of the imaging system (212, 214) given the identification of the object in the sequence of images (218, 220) of the scene (102, 222), the computer system is configured to estimate the state (332) of the imaging system (212, 214) based on the probability of the state of the imaging system (212, 214) given the identification of the object (225) in the sequence of images (218, 220) of the scene (102, 222) using a particle filter.</div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0014" num="0014" class="claim">
      <div class="claim-text">The apparatus of any of claims 9-13, wherein the expected behavior (328) is expected to occur in the region in the model of the scene (102, 222) for any object (225) of a same type as the object (225).</div>
    </div>
    </li> <li class="claim-dependent"> <div id="c-en-0015" num="0015" class="claim">
      <div class="claim-text">The apparatus of any of claims 9-14, wherein the imaging system (212, 214) is a first imaging system (212), the sequence of images (218, 220) is a first sequence of images (218), the object (225) is a first object, and the viewpoint (227, 229) is a first viewpoint (227), and wherein the computer system is further configured to receive a second sequence of images (220) for the scene (102, 222) from a second imaging system (214); and detect a second object in the scene (102, 222) using the second sequence of images (220), wherein the second object is a same type as the first object; and register a second viewpoint of the second imaging system (214) to the model of the scene (102, 222) using the region in the scene (102, 222) in which the expected behavior (328) for the second object is expected to occur.</div>
    </div>
  </li> </ol>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
        <span itemprop="applicationNumber">EP12186437.5A</span>
        <span itemprop="priorityDate">2011-09-29</span>
        <span itemprop="filingDate">2012-09-27</span>
        <span itemprop="title">Method and apparatus for processing images 
       </span>
        <span itemprop="ifiStatus">Pending</span>
        
        <a href="/patent/EP2575079A3/en">
            <span itemprop="representativePublication">EP2575079A3</span>
            (<span itemprop="primaryLanguage">en</span>)
        </a>
    </section>

    <h2>Priority Applications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="priorityApps" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US13/249,064</span>
                   
                   <a href="/patent/US8891820B2/en">
                        <span itemprop="representativePublication">US8891820B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2011-09-29</td>
                <td itemprop="filingDate">2011-09-29</td>
                <td itemprop="title">Multi-modal sensor fusion 
       </td>
              </tr>
           </tbody>
       </table>

    

    

    

    <h2>Publications (2)</h2>
        <table>
            <thead>
                <tr>
                    <th>Publication Number</th>
                    <th>Publication Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="pubs" itemscope repeat>
                <td>
                   <span itemprop="publicationNumber">EP2575079A2</span>
                   
                   <span itemprop="thisPatent">true</span>
                   <a href="/patent/EP2575079A2/en">EP2575079A2
                       (<span itemprop="primaryLanguage">en</span>)
                   </a>
                </td>
                <td itemprop="publicationDate">2013-04-03</td>
              </tr><tr itemprop="pubs" itemscope repeat>
                <td>
                   <span itemprop="publicationNumber">EP2575079A3</span>
                   
                   <a href="/patent/EP2575079A3/en">EP2575079A3
                       (<span itemprop="primaryLanguage">en</span>)
                   </a>
                </td>
                <td itemprop="publicationDate">2014-12-24</td>
              </tr>
           </tbody>
        </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=47351378</h2>

    <h2>Family Applications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Title</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="applications" itemscope repeat>
                <td>
                    <span itemprop="applicationNumber">EP12186437.5A</span>
                    <span itemprop="ifiStatus">Pending</span>
                    
                    <a href="/patent/EP2575079A3/en">
                        <span itemprop="representativePublication">EP2575079A3</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                </td>
                <td itemprop="priorityDate">2011-09-29</td>
                <td itemprop="filingDate">2012-09-27</td>
                <td itemprop="title">Method and apparatus for processing images 
       </td>
              </tr>
           </tbody>
        </table>

    

    

    <h2>Country Status (2)</h2>
      <table>
        <thead>
          <tr>
            <th>Country</th>
            <th>Link</th>
          </tr>
        </thead>
        <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
            <td>
              <span itemprop="countryCode">US</span>
                (<span itemprop="num">1</span>)
              
            </td>
            <td>
              <a href="/patent/US8891820B2/en">
                <span itemprop="representativePublication">US8891820B2</span>
                  (<span itemprop="primaryLanguage">en</span>)
              </a>
            </td>
          </tr><tr itemprop="countryStatus" itemscope repeat>
            <td>
              <span itemprop="countryCode">EP</span>
                (<span itemprop="num">1</span>)
              <meta itemprop="thisCountry" content="true">
            </td>
            <td>
              <a href="/patent/EP2575079A3/en">
                <span itemprop="representativePublication">EP2575079A3</span>
                  (<span itemprop="primaryLanguage">en</span>)
              </a>
            </td>
          </tr>
      </tbody>
    </table>

    <h2>Cited By (5)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/GB2511863A/en">
              <span itemprop="publicationNumber">GB2511863A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2013-03-15</td>
          <td itemprop="publicationDate">2014-09-17</td>
          <td><span itemprop="assigneeOriginal">Infrared Integrated Syst Ltd</span></td>
          <td itemprop="title">Apparatus and method for multispectral imaging 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/EP3107039A1/en">
              <span itemprop="publicationNumber">EP3107039A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-06-18</td>
          <td itemprop="publicationDate">2016-12-21</td>
          <td><span itemprop="assigneeOriginal">The Boeing Company</span></td>
          <td itemprop="title">Method and apparatus for tracking targets 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9715639B2/en">
              <span itemprop="publicationNumber">US9715639B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-06-18</td>
          <td itemprop="publicationDate">2017-07-25</td>
          <td><span itemprop="assigneeOriginal">The Boeing Company</span></td>
          <td itemprop="title">Method and apparatus for detecting targets 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/EP3231187A4/en">
              <span itemprop="publicationNumber">EP3231187A4</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-12-13</td>
          <td itemprop="publicationDate">2018-06-27</td>
          <td><span itemprop="assigneeOriginal">Fox Sports Productions, Inc.</span></td>
          <td itemprop="title">Systems and methods for displaying thermographic characteristics within a broadcast 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/GB2572795A/en">
              <span itemprop="publicationNumber">GB2572795A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2018-04-11</td>
          <td itemprop="publicationDate">2019-10-16</td>
          <td><span itemprop="assigneeOriginal">Nokia Technologies Oy</span></td>
          <td itemprop="title">Camera registration 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Families Citing this family (7)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20170249491A1/en">
              <span itemprop="publicationNumber">US20170249491A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2011-08-30</td>
          <td itemprop="publicationDate">2017-08-31</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Methods and arrangements for identifying objects 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2015120913A1/en">
              <span itemprop="publicationNumber">WO2015120913A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-02-17</td>
          <td itemprop="publicationDate">2015-08-20</td>
          <td><span itemprop="assigneeOriginal">Metaio Gmbh</span></td>
          <td itemprop="title">Method and device for detecting a touch between a first object and a second object 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9547935B2/en">
              <span itemprop="publicationNumber">US9547935B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-02-24</td>
          <td itemprop="publicationDate">2017-01-17</td>
          <td><span itemprop="assigneeOriginal">Vricon Systems Ab</span></td>
          <td itemprop="title">Method and a system for building a three-dimensional model from satellite images 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9928592B2/en">
              <span itemprop="publicationNumber">US9928592B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2016-03-14</td>
          <td itemprop="publicationDate">2018-03-27</td>
          <td><span itemprop="assigneeOriginal">Sensors Unlimited, Inc.</span></td>
          <td itemprop="title">Image-based signal detection for object metrology 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US10007971B2/en">
              <span itemprop="publicationNumber">US10007971B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2016-03-14</td>
          <td itemprop="publicationDate">2018-06-26</td>
          <td><span itemprop="assigneeOriginal">Sensors Unlimited, Inc.</span></td>
          <td itemprop="title">Systems and methods for user machine interaction for image-based metrology 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/JP6239047B1/en">
              <span itemprop="publicationNumber">JP6239047B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-06-17</td>
          <td itemprop="publicationDate">2017-11-29</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Object recognition integration apparatus and object recognition integration method 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US10410055B2/en">
              <span itemprop="publicationNumber">US10410055B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-10-05</td>
          <td itemprop="publicationDate">2019-09-10</td>
          <td><span itemprop="assigneeOriginal">TuSimple</span></td>
          <td itemprop="title">System and method for aerial video traffic analysis 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Family Cites Families (9)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6072496A/en">
              <span itemprop="publicationNumber">US6072496A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1998-06-08</td>
          <td itemprop="publicationDate">2000-06-06</td>
          <td><span itemprop="assigneeOriginal">Microsoft Corporation</span></td>
          <td itemprop="title">Method and system for capturing and representing 3D geometry, color and shading of facial expressions and other animated objects 
       </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20030218674A1/en">
              <span itemprop="publicationNumber">US20030218674A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2002-05-24</td>
          <td itemprop="publicationDate">2003-11-27</td>
          <td><span itemprop="assigneeOriginal">Sarnoff Corporation</span></td>
          <td itemprop="title">Method and apparatus for video georegistration 
       </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9363487B2/en">
              <span itemprop="publicationNumber">US9363487B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2005-09-08</td>
          <td itemprop="publicationDate">2016-06-07</td>
          <td><span itemprop="assigneeOriginal">Avigilon Fortress Corporation</span></td>
          <td itemprop="title">Scanning camera-based video surveillance system 
       </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9251585B2/en">
              <span itemprop="publicationNumber">US9251585B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2007-07-12</td>
          <td itemprop="publicationDate">2016-02-02</td>
          <td><span itemprop="assigneeOriginal">Siemens Aktiengesellschaft</span></td>
          <td itemprop="title">Coregistration and analysis of multi-modal images obtained in different geometries 
       </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8098888B1/en">
              <span itemprop="publicationNumber">US8098888B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-01-28</td>
          <td itemprop="publicationDate">2012-01-17</td>
          <td><span itemprop="assigneeOriginal">Videomining Corporation</span></td>
          <td itemprop="title">Method and system for automatic analysis of the trip of people in a retail space using multiple cameras 
       </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8401276B1/en">
              <span itemprop="publicationNumber">US8401276B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-05-20</td>
          <td itemprop="publicationDate">2013-03-19</td>
          <td><span itemprop="assigneeOriginal">University Of Southern California</span></td>
          <td itemprop="title">3-D reconstruction and registration 
       </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8384534B2/en">
              <span itemprop="publicationNumber">US8384534B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2010-01-14</td>
          <td itemprop="publicationDate">2013-02-26</td>
          <td><span itemprop="assigneeOriginal">Toyota Motor Engineering &amp; Manufacturing North America, Inc.</span></td>
          <td itemprop="title">Combining driver and environment sensing for vehicular safety systems 
       </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/IL204089A/en">
              <span itemprop="publicationNumber">IL204089A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2010-02-21</td>
          <td itemprop="publicationDate">2014-06-30</td>
          <td><span itemprop="assigneeOriginal">Elbit Systems Ltd</span></td>
          <td itemprop="title">Method and system for detection and tracking employing multi-view multi-spectral imaging 
     </td>
        </tr><tr itemprop="backwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9746988B2/en">
              <span itemprop="publicationNumber">US9746988B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2011-05-23</td>
          <td itemprop="publicationDate">2017-08-29</td>
          <td><span itemprop="assigneeOriginal">The Boeing Company</span></td>
          <td itemprop="title">Multi-sensor surveillance system with a common operating picture 
       </td>
        </tr>
      </tbody>
    </table>

    
    <ul>
      
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2011</span>
        <ul>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2011-09-29</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US13/249,064</span>
            <a href="/patent/US8891820B2/en"><span itemprop="documentId">patent/US8891820B2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
          </li>
          
        </ul>
      </li>
      
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2012</span>
        <ul>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2012-09-27</span>
            <span itemprop="countryCode">EP</span>
            <span itemprop="applicationNumber">EP12186437.5A</span>
            <a href="/patent/EP2575079A3/en"><span itemprop="documentId">patent/EP2575079A3/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Pending</span>
            
            <span itemprop="thisApp" content="true" bool></span>
            
          </li>
          
        </ul>
      </li>
      
    </ul>
    

    </section>

  

  <section>
    <h2>Non-Patent Citations (1)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">None</span>
            
            
          </td>
        </tr>
      </tbody>
    </table>
  </section>

  <h2>Cited By (6)</h2>
  <table>
    <caption>* Cited by examiner,  Cited by third party</caption>
    <thead>
      <tr>
        <th>Publication number</th>
        <th>Priority date</th>
        <th>Publication date</th>
        <th>Assignee</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/GB2511863A/en">
            <span itemprop="publicationNumber">GB2511863A</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2013-03-15</td>
        <td itemprop="publicationDate">2014-09-17</td>
        <td><span itemprop="assigneeOriginal">Infrared Integrated Syst Ltd</span></td>
        <td itemprop="title">Apparatus and method for multispectral imaging 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/EP3231187A4/en">
            <span itemprop="publicationNumber">EP3231187A4</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2014-12-13</td>
        <td itemprop="publicationDate">2018-06-27</td>
        <td><span itemprop="assigneeOriginal">Fox Sports Productions, Inc.</span></td>
        <td itemprop="title">Systems and methods for displaying thermographic characteristics within a broadcast 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/EP3107039A1/en">
            <span itemprop="publicationNumber">EP3107039A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2015-06-18</td>
        <td itemprop="publicationDate">2016-12-21</td>
        <td><span itemprop="assigneeOriginal">The Boeing Company</span></td>
        <td itemprop="title">Method and apparatus for tracking targets 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/US9715639B2/en">
            <span itemprop="publicationNumber">US9715639B2</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          
          
        </td>
        <td itemprop="priorityDate">2015-06-18</td>
        <td itemprop="publicationDate">2017-07-25</td>
        <td><span itemprop="assigneeOriginal">The Boeing Company</span></td>
        <td itemprop="title">Method and apparatus for detecting targets 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/US9727785B2/en">
            <span itemprop="publicationNumber">US9727785B2</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          
          
        </td>
        <td itemprop="priorityDate">2015-06-18</td>
        <td itemprop="publicationDate">2017-08-08</td>
        <td><span itemprop="assigneeOriginal">The Boeing Company</span></td>
        <td itemprop="title">Method and apparatus for tracking targets 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/GB2572795A/en">
            <span itemprop="publicationNumber">GB2572795A</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2018-04-11</td>
        <td itemprop="publicationDate">2019-10-16</td>
        <td><span itemprop="assigneeOriginal">Nokia Technologies Oy</span></td>
        <td itemprop="title">Camera registration 
       </td>
      </tr>
    </tbody>
  </table>

  <section>
    <h2>Also Published As</h2>
    <table>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Publication date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/EP2575079A3/en">
              <span itemprop="publicationNumber">EP2575079A3</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2014-12-24</td>
        </tr><tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20130083959A1/en">
              <span itemprop="publicationNumber">US20130083959A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2013-04-04</td>
        </tr><tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8891820B2/en">
              <span itemprop="publicationNumber">US8891820B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2014-11-18</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="17481366721858458409">
              <a href="/scholar/17481366721858458409"><span itemprop="scholarAuthors">Wang et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2007">2007</time>
            
          </td>
          <td itemprop="title">Simultaneous localization, mapping and moving object tracking</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="4194396260688539376">
              <a href="/scholar/4194396260688539376"><span itemprop="scholarAuthors">Geiger et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2013">2013</time>
            
          </td>
          <td itemprop="title">3d traffic scene understanding from movable platforms</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="13892323861103254096">
              <a href="/scholar/13892323861103254096"><span itemprop="scholarAuthors">Zhang et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2014">2014</time>
            
          </td>
          <td itemprop="title">LOAM: Lidar Odometry and Mapping in Real-time.</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="739419258585031332">
              <a href="/scholar/739419258585031332"><span itemprop="scholarAuthors">Hillel et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2014">2014</time>
            
          </td>
          <td itemprop="title">Recent progress in road and lane detection: a survey</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="15536977796882410972">
              <a href="/scholar/15536977796882410972"><span itemprop="scholarAuthors">Danescu et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2011">2011</time>
            
          </td>
          <td itemprop="title">Modeling and tracking the driving environment with a particle-based occupancy grid</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="4909253061523927413">
              <a href="/scholar/4909253061523927413"><span itemprop="scholarAuthors">Kitani et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2012">2012</time>
            
          </td>
          <td itemprop="title">Activity forecasting</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/CN104035071B/en">
                <span itemprop="publicationNumber">CN104035071B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2016-11-23">2016-11-23</time>
            
            
          </td>
          <td itemprop="title">Merge radar/video camera object data and the method and apparatus of LiDAR scanning element 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US7929730B2/en">
                <span itemprop="publicationNumber">US7929730B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2011-04-19">2011-04-19</time>
            
            
          </td>
          <td itemprop="title">Method and system for object detection and tracking 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="14844172770641591568">
              <a href="/scholar/14844172770641591568"><span itemprop="scholarAuthors">Kooij et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2014">2014</time>
            
          </td>
          <td itemprop="title">Context-based pedestrian path prediction</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="15802995347996195679">
              <a href="/scholar/15802995347996195679"><span itemprop="scholarAuthors">Kumar et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2013">2013</time>
            
          </td>
          <td itemprop="title">An automated algorithm for extracting road edges from terrestrial mobile LiDAR data</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="6020623860903843127">
              <a href="/scholar/6020623860903843127"><span itemprop="scholarAuthors">Pendleton et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2017">2017</time>
            
          </td>
          <td itemprop="title">Perception, planning, control, and coordination for autonomous vehicles</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="18159608726822091237">
              <a href="/scholar/18159608726822091237"><span itemprop="scholarAuthors">Ess et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2009">2009</time>
            
          </td>
          <td itemprop="title">Moving obstacle detection in highly dynamic scenes</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="14755172622672260091">
              <a href="/scholar/14755172622672260091"><span itemprop="scholarAuthors">Zhang et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2017">2017</time>
            
          </td>
          <td itemprop="title">Low-drift and real-time lidar odometry and mapping</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="8193072240574136765">
              <a href="/scholar/8193072240574136765"><span itemprop="scholarAuthors">Laugier et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2011">2011</time>
            
          </td>
          <td itemprop="title">Probabilistic analysis of dynamic scenes and collision risks assessment to improve driving safety</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20120281907A1/en">
                <span itemprop="publicationNumber">US20120281907A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2012-11-08">2012-11-08</time>
            
            
          </td>
          <td itemprop="title">Real-time 3d point cloud obstacle discriminator apparatus and associated methodology for training a classifier via bootstrapping 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="7928038489779377624">
              <a href="/scholar/7928038489779377624"><span itemprop="scholarAuthors">Hata et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2014">2014</time>
            
          </td>
          <td itemprop="title">Robust curb detection and vehicle localization in urban environments</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="155964749680033681">
              <a href="/scholar/155964749680033681"><span itemprop="scholarAuthors">Kammel et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2008">2008</time>
            
          </td>
          <td itemprop="title">Lidar-based lane marker detection and mapping</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US9858816B2/en">
                <span itemprop="publicationNumber">US9858816B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2018-01-02">2018-01-02</time>
            
            
          </td>
          <td itemprop="title">Determining parking space occupancy using a 3D representation 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/DE102015201951A1/en">
                <span itemprop="publicationNumber">DE102015201951A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2015-08-27">2015-08-27</time>
            
            
          </td>
          <td itemprop="title">System and method for mapping, locating and correcting a spatial position 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20180023960A1/en">
                <span itemprop="publicationNumber">US20180023960A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2018-01-25">2018-01-25</time>
            
            
          </td>
          <td itemprop="title">Distributing a crowdsourced sparse map for autonomous vehicle navigation 
     </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="5288153210993232002">
              <a href="/scholar/5288153210993232002"><span itemprop="scholarAuthors">Botterill et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2011">2011</time>
            
          </td>
          <td itemprop="title">Bagofwordsdriven, singlecamera simultaneous localization and mapping</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="7898189145055142583">
              <a href="/scholar/7898189145055142583"><span itemprop="scholarAuthors">Hata et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2015">2015</time>
            
          </td>
          <td itemprop="title">Feature detection for vehicle localization in urban environments using a multilayer LIDAR</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="4993679902350781690">
              <a href="/scholar/4993679902350781690"><span itemprop="scholarAuthors">Alcantarilla et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2018">2018</time>
            
          </td>
          <td itemprop="title">Street-view change detection with deconvolutional networks</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="4617104328123596200">
              <a href="/scholar/4617104328123596200"><span itemprop="scholarAuthors">Schmitt et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2016">2016</time>
            
          </td>
          <td itemprop="title">Data fusion and remote sensing: An ever-growing relationship</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="14232023917278847154">
              <a href="/scholar/14232023917278847154"><span itemprop="scholarAuthors">Guo et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2012">2012</time>
            
          </td>
          <td itemprop="title">Robust road detection and tracking in challenging scenarios based on Markov random fields with unsupervised learning</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2013-04-03">2013-04-03</time></td>
          <td itemprop="code">AK</td>
          <td itemprop="title">Designated contracting states:</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Kind code of ref document</strong>:
              <span itemprop="value">A2</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Designated state(s)</strong>:
              <span itemprop="value">AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2013-04-03">2013-04-03</time></td>
          <td itemprop="code">17P</td>
          <td itemprop="title">Request for examination filed</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Effective date</strong>:
              <span itemprop="value">20120927</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2013-04-03">2013-04-03</time></td>
          <td itemprop="code">AX</td>
          <td itemprop="title">Request for extension of the european patent to</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Extension  state</strong>:
              <span itemprop="value">BA ME</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2014-12-24">2014-12-24</time></td>
          <td itemprop="code">AK</td>
          <td itemprop="title">Designated contracting states:</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Kind code of ref document</strong>:
              <span itemprop="value">A3</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Designated state(s)</strong>:
              <span itemprop="value">AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2014-12-24">2014-12-24</time></td>
          <td itemprop="code">AX</td>
          <td itemprop="title">Request for extension of the european patent to</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Extension  state</strong>:
              <span itemprop="value">BA ME</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2014-12-24">2014-12-24</time></td>
          <td itemprop="code">RIC1</td>
          <td itemprop="title">Classification (correction)</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Ipc</strong>:
              <span itemprop="value">G06T   7/20        20060101ALI20141117BHEP</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Ipc</strong>:
              <span itemprop="value">G06T   7/00        20060101ALI20141117BHEP</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Ipc</strong>:
              <span itemprop="value">G06K   9/00        20060101AFI20141117BHEP</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2017-04-26">2017-04-26</time></td>
          <td itemprop="code">17Q</td>
          <td itemprop="title">First examination report</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Effective date</strong>:
              <span itemprop="value">20170327</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>
</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script async="" defer="" src="//www.google.com/insights/consumersurveys/async_survey?site=cxkjf7ipxgbnnjy6k35ezcvbbe"></script>
  </body>
</html>
