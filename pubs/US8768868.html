<!doctype html>
<html lang="en">
  <head>
    <title>US8768868B1 - Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
        - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US8768868B1/en">
    <meta name="description" content="
     Described is a system for multi-class classifier threshold-offset estimation for visual object recognition. The system receives an input image with input features for classifying. A pair-wise classifier is trained for each pair of a plurality of object classes. A set of classification responses is generated, and a multi-class receiver-operating-characteristics (ROC) curve is computed for a set of threshold-offsets. An objective function of classification performance is computed from the ROC curve and optimized using particle swarm optimization (PSO) to generate a set of optimized threshold-offsets. The optimized threshold-offsets are then applied to the classification responses. The resulting classification responses are compared to a predetermined value to classify each input feature as belonging to one object class or another. The tuning of the threshold-offsets with (PSO) improves classification performance in a visual object recognition system. 
   
   ">
    
    <meta name="DC.type" content="patent">
    
    <meta name="DC.title" content="Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
       ">
    
    <meta name="DC.date" content="2012-04-05" scheme="dateSubmitted">
    
    <meta name="DC.description" content="
     Described is a system for multi-class classifier threshold-offset estimation for visual object recognition. The system receives an input image with input features for classifying. A pair-wise classifier is trained for each pair of a plurality of object classes. A set of classification responses is generated, and a multi-class receiver-operating-characteristics (ROC) curve is computed for a set of threshold-offsets. An objective function of classification performance is computed from the ROC curve and optimized using particle swarm optimization (PSO) to generate a set of optimized threshold-offsets. The optimized threshold-offsets are then applied to the classification responses. The resulting classification responses are compared to a predetermined value to classify each input feature as belonging to one object class or another. The tuning of the threshold-offsets with (PSO) improves classification performance in a visual object recognition system. 
   
   ">
    
    <meta name="citation_patent_application_number" content="US:13/440,881">
    
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/47/37/2d/eff41f25c458bc/US8768868.pdf">
    
    <meta name="citation_patent_number" content="US:8768868">
    
    <meta name="DC.date" content="2014-07-01" scheme="issue">
    
    <meta name="DC.contributor" content="Shinko Y. Cheng" scheme="inventor">
    
    <meta name="DC.contributor" content="Yang Chen" scheme="inventor">
    
    <meta name="DC.contributor" content="Deepak Khosla" scheme="inventor">
    
    <meta name="DC.contributor" content="Kyungnam Kim" scheme="inventor">
    
    <meta name="DC.contributor" content="HRL Laboratories LLC" scheme="assignee">
    
    <meta name="DC.relation" content="US:7912246" scheme="references">
    
    <meta name="DC.relation" content="US:20100141787:A1" scheme="references">
    
    <meta name="citation_reference" content="Dollar, P., Wojek, C., Schiele, B., Perona, P., Pedestrian detection: A benchmark, In Computer Vision and Pattern Recognition, 2009, all pages." scheme="references">
    
    <meta name="citation_reference" content="Duda, R.O., Hart, P.E., Stork, D.E., Pattern Classification, John Wiley & Sons, Chichester, 2001, Chapter 5.2.2." scheme="references">
    
    <meta name="citation_reference" content="Ellis, A., Ferryman, J.M., PET 2010 and PETS2009 evaluation of results using individual ground truthed single views, In IEEE International Conference on Advanced Video and Signal Based Surveillace (AVSS), pp. 135-142, 2010." scheme="references">
    
    <meta name="citation_reference" content="Everingham, M., Good, L.V., Williams, C.K.I., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge, International Journal of Computer Vision, 88, 303-336, 2010." scheme="references">
    
    <meta name="citation_reference" content="Hastie, T., Tibshirani, R., Friedman, J., The Elements of statistical Learning. Data Mining, Inference, and Predition, 2nd edn., Springer Series in Statistics, 2009, p. 658." scheme="references">
    
    <meta name="citation_reference" content="Kasturi, R., Goldof, D., Soundararajan, P., Manohar, V., Garofolo, J., Bowers, R., Boonstra, M., Korzhova, V., Zhang, J., Framework for performance evaluation of face, text, and vehicle tetction and tracking in video: Data, metrics and protocol, IEEE Transactions on Pattern Analysis and Machine Intelligence, 31, 319-336, 2009." scheme="references">
    
    <meta name="citation_reference" content="Kennedy, J.; Eberhart, R.; Neural Networks, 1995, &#34;Particle Swarm Optimization,&#34; Proceedings., IEEE International Conference, Nov./Dec. 1995, 1942-1948 vol. 4." scheme="references">
    
    <meta name="citation_reference" content="Oh, S., Perera, A., Cuntoor, N., Chen, C.C., Lee, J.T., Mukherjee, S., Aggarwal, J., Lee, H., Davis, L., Swears, E., Wang, X., Ji, Q., Reddy, K., Shah, M., Vodrick, C., Pirsiavash, H., Ramanan, D., Yuen, J., Torralba, A., Song, B., Fong, A., Roy-Chowdhury, A., Desai, M., A large-scale benchmark dataset for event recognition in surveillance video, In IEEE Computer Vision and Pattern Recognition, 2011, all pages." scheme="references">
    
    <meta name="citation_reference" content="Wu, T.F., Lin, C.J., Weng, R.C., Pobability estimates for multi-class classification by pairwise coupling, Journal of Machine Learning Research 5, 975-1005, 2004." scheme="references">
    
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <style>
      body { transition: none; }
    </style>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-27188110-4', 'auto');

      version = 'patent-search.search_20191120_RC00';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.profilePicture = "https:\/\/lh4.googleusercontent.com\/-jksfid8w7L8\/AAAAAAAAAAI\/AAAAAAAAAAA\/4nKKEmF_j5w\/s32-c-mo\/p.png?sourceid=navclient";

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.html">
    
  </head>
  <body unresolved>
    
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.js"></script>
    
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US8768868B1 - Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
        - Google Patents</h1>
  <span itemprop="title">Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
       </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/47/37/2d/eff41f25c458bc/US8768868.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US8768868B1</dd>
    <meta itemprop="numberWithoutCodes" content="8768868">
    <meta itemprop="kindCode" content="B1">
    <meta itemprop="publicationDescription" content="Patent ( no pre-grant publication)">
    
    <span>US8768868B1</span>
    
    <span>US13/440,881</span>
    
    <span>US201213440881A</span>
    
    <span>US8768868B1</span>
    
    <span>US 8768868 B1</span>
    
    <span>US8768868 B1</span>
    
    <span>US 8768868B1</span>
    
    <span>  </span>
    
    <span> </span>
    
    <span> </span>
    
    <span>US 201213440881 A</span>
    
    <span>US201213440881 A</span>
    
    <span>US 201213440881A</span>
    
    <span>US 8768868 B1</span>
    
    <span>US8768868 B1</span>
    
    <span>US 8768868B1</span>
    

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    
    <dd itemprop="priorArtKeywords" repeat>set</dd>
    <dd itemprop="priorArtKeywords" repeat>class</dd>
    <dd itemprop="priorArtKeywords" repeat>threshold</dd>
    <dd itemprop="priorArtKeywords" repeat>auc</dd>
    <dd itemprop="priorArtKeywords" repeat>multi</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2012-04-05">2012-04-05</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Active</span>, expires <time itemprop="expiration" datetime="2032-12-20">2032-12-20</time>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US13/440,881</dd>

  

  

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>Shinko Y. Cheng</dd>
  <dd itemprop="inventor" repeat>Yang Chen</dd>
  <dd itemprop="inventor" repeat>Deepak Khosla</dd>
  <dd itemprop="inventor" repeat>Kyungnam Kim</dd>
  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    HRL Laboratories LLC
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>HRL Laboratories LLC</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2012-04-05">2012-04-05</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2012-04-05">2012-04-05</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2014-07-01">2014-07-01</time></dd>

  

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2012-04-05">2012-04-05</time>
    <span itemprop="title">Application filed by HRL Laboratories LLC</span>
    <span itemprop="type">filed</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    <span itemprop="assigneeSearch">HRL Laboratories LLC</span>
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2012-04-05">2012-04-05</time>
    <span itemprop="title">Priority to US13/440,881</span>
    <span itemprop="type">priority</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US8768868B1/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2012-04-05">2012-04-05</time>
    <span itemprop="title">Assigned to HRL LABORATORIES, LLC</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">HRL LABORATORIES, LLC</span>
    
    
    <span itemprop="description" repeat>ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS).</span>
    
    <span itemprop="description" repeat>Assignors: CHEN, YANG, Cheng, Shinko Y., KHOSLA, DEEPAK, KIM, KYUNGNAM</span>
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2014-07-01">2014-07-01</time>
    <span itemprop="title">Application granted</span>
    <span itemprop="type">granted</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2014-07-01">2014-07-01</time>
    <span itemprop="title">Publication of US8768868B1</span>
    <span itemprop="type">publication</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US8768868B1/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2014-12-23">2014-12-23</time>
    <span itemprop="title">Assigned to DARPA</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">DARPA</span>
    
    
    <span itemprop="description" repeat>CONFIRMATORY LICENSE (SEE DOCUMENT FOR DETAILS).</span>
    
    <span itemprop="description" repeat>Assignors: HRL LABORATORIES, LLC</span>
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2019-12-14">2019-12-14</time>
    <span itemprop="title">Application status is Active</span>
    <span itemprop="type">legal-status</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2032-12-20">2032-12-20</time>
    <span itemprop="title">Adjusted expiration</span>
    <span itemprop="type">legal-status</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  

  <h2>Links</h2>

  <ul>
    
          <li itemprop="links" itemscope repeat>
            <meta itemprop="id" content="usptoLink">
            <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PALL&s1=8768868.PN." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
          </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=8768868" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="http://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=8768868B1&amp;KC=B1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="globalDossierLink">
          <a href="http://globaldossier.uspto.gov/#/result/patent/US/8768868/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
        </li>
      

      

      

      

      <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="stackexchangeLink">
          <a href="https://patents.stackexchange.com/questions/tagged/US8768868" itemprop="url"><span itemprop="text">Discuss</span></a>
        </li>
      
  </ul>

  
  <ul itemprop="concept" itemscope>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000002245</span>
      <span itemprop="name">particles</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="sections" repeat>title</span>
      
      <span itemprop="count">18</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000007</span>
      <span itemprop="name">visual effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="sections" repeat>title</span>
      
      <span itemprop="count">18</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005457</span>
      <span itemprop="name">optimization</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="sections" repeat>title</span>
      
      <span itemprop="count">11</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004044</span>
      <span itemprop="name">response</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">48</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004590</span>
      <span itemprop="name">computer program</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">17</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000015654</span>
      <span itemprop="name">memory</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">8</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000002609</span>
      <span itemprop="name">media</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">6</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003860</span>
      <span itemprop="name">storage</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">5</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000011159</span>
      <span itemprop="name">matrix materials</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">4</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000670</span>
      <span itemprop="name">limiting</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000000047</span>
      <span itemprop="name">products</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003287</span>
      <span itemprop="name">optical</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000035945</span>
      <span itemprop="name">sensitivity</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000035533</span>
      <span itemprop="name">AUC</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003935</span>
      <span itemprop="name">attention</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004422</span>
      <span itemprop="name">calculation algorithm</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001413</span>
      <span itemprop="name">cellular</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004891</span>
      <span itemprop="name">communication</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005225</span>
      <span itemprop="name">electronics</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002068</span>
      <span itemprop="name">genetic</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007689</span>
      <span itemprop="name">inspection</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006011</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000036961</span>
      <span itemprop="name">partial</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002093</span>
      <span itemprop="name">peripheral</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010010</span>
      <span itemprop="name">raising</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001131</span>
      <span itemprop="name">transforming</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
  </ul>
  

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/01/43/7e/244bb3048c372d/US08768868-20140701-D00000.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/03/72/23/27eb83616112db/US08768868-20140701-D00000.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="object recognition system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="698">
              <meta itemprop="top" content="120">
              <meta itemprop="right" content="801">
              <meta itemprop="bottom" content="177">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="multi-class classifier">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="846">
              <meta itemprop="top" content="969">
              <meta itemprop="right" content="947">
              <meta itemprop="bottom" content="1030">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="112">
            <meta itemprop="label" content="U.S.C. Section">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1766">
              <meta itemprop="top" content="946">
              <meta itemprop="right" content="1880">
              <meta itemprop="bottom" content="1003">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="114">
            <meta itemprop="label" content="particular object class">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="2072">
              <meta itemprop="top" content="945">
              <meta itemprop="right" content="2167">
              <meta itemprop="bottom" content="1002">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="116">
            <meta itemprop="label" content="output y">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="2497">
              <meta itemprop="top" content="1071">
              <meta itemprop="right" content="2601">
              <meta itemprop="bottom" content="1128">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/2d/97/c4/b645d7958c5bc7/US08768868-20140701-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/fa/89/97/e5165ff11fe133/US08768868-20140701-D00001.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/fd/fb/bd/112af1f6715e35/US08768868-20140701-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/8f/57/11/1566169ff26b71/US08768868-20140701-D00002.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="202">
            <meta itemprop="label" content="C">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="793">
              <meta itemprop="top" content="1680">
              <meta itemprop="right" content="849">
              <meta itemprop="bottom" content="1781">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="204">
            <meta itemprop="label" content="background class B">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="841">
              <meta itemprop="top" content="457">
              <meta itemprop="right" content="895">
              <meta itemprop="bottom" content="556">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="208">
            <meta itemprop="label" content="t">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1383">
              <meta itemprop="top" content="914">
              <meta itemprop="right" content="1450">
              <meta itemprop="bottom" content="1011">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/76/1d/6e/09ec539dbb4c66/US08768868-20140701-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/06/b1/08/e10d2f30a7be40/US08768868-20140701-D00003.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/e5/c5/e9/011c97501815de/US08768868-20140701-D00004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/1a/9d/57/28c38932bfe16d/US08768868-20140701-D00004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="402">
            <meta itemprop="label" content="axis">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="486">
              <meta itemprop="top" content="1753">
              <meta itemprop="right" content="546">
              <meta itemprop="bottom" content="1847">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/3e/d8/0c/b066b072aef845/US08768868-20140701-D00005.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/d7/9c/f7/e2e661d88f71cf/US08768868-20140701-D00005.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="500">
            <meta itemprop="label" content="Curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="287">
              <meta itemprop="top" content="1755">
              <meta itemprop="right" content="339">
              <meta itemprop="bottom" content="1849">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="502">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="352">
              <meta itemprop="top" content="1767">
              <meta itemprop="right" content="405">
              <meta itemprop="bottom" content="1853">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="502">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1138">
              <meta itemprop="top" content="429">
              <meta itemprop="right" content="1198">
              <meta itemprop="bottom" content="523">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="504">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="417">
              <meta itemprop="top" content="1763">
              <meta itemprop="right" content="467">
              <meta itemprop="bottom" content="1852">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="5">
            <meta itemprop="id" content="504">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="898">
              <meta itemprop="top" content="407">
              <meta itemprop="right" content="974">
              <meta itemprop="bottom" content="537">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/bc/8c/5e/52a158b190a294/US08768868-20140701-D00006.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/5a/4c/5e/08db810e035c80/US08768868-20140701-D00006.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="600">
            <meta itemprop="label" content="Curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="316">
              <meta itemprop="top" content="1744">
              <meta itemprop="right" content="371">
              <meta itemprop="bottom" content="1831">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="600">
            <meta itemprop="label" content="Curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="676">
              <meta itemprop="top" content="474">
              <meta itemprop="right" content="729">
              <meta itemprop="bottom" content="559">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="602">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="377">
              <meta itemprop="top" content="1753">
              <meta itemprop="right" content="429">
              <meta itemprop="bottom" content="1820">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="602">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="828">
              <meta itemprop="top" content="446">
              <meta itemprop="right" content="880">
              <meta itemprop="bottom" content="532">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="6">
            <meta itemprop="id" content="604">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="445">
              <meta itemprop="top" content="1752">
              <meta itemprop="right" content="493">
              <meta itemprop="bottom" content="1832">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/03/78/1b/20a42d66e79d6b/US08768868-20140701-D00007.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/90/3f/c2/75d532886f80e4/US08768868-20140701-D00007.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/11/3e/86/5a958428cf8d13/US08768868-20140701-D00008.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/66/69/06/dde54d4eb35974/US08768868-20140701-D00008.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="800">
            <meta itemprop="label" content="Curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="321">
              <meta itemprop="top" content="1716">
              <meta itemprop="right" content="373">
              <meta itemprop="bottom" content="1810">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="800">
            <meta itemprop="label" content="Curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="448">
              <meta itemprop="top" content="379">
              <meta itemprop="right" content="495">
              <meta itemprop="bottom" content="458">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="802">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="378">
              <meta itemprop="top" content="1732">
              <meta itemprop="right" content="433">
              <meta itemprop="bottom" content="1806">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="802">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1005">
              <meta itemprop="top" content="355">
              <meta itemprop="right" content="1055">
              <meta itemprop="bottom" content="428">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="804">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="446">
              <meta itemprop="top" content="1731">
              <meta itemprop="right" content="494">
              <meta itemprop="bottom" content="1801">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="8">
            <meta itemprop="id" content="804">
            <meta itemprop="label" content="curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="770">
              <meta itemprop="top" content="430">
              <meta itemprop="right" content="821">
              <meta itemprop="bottom" content="513">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/3f/7b/38/e4952695bbf3db/US08768868-20140701-D00009.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/6d/63/a2/07ece9a45859fb/US08768868-20140701-D00009.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/ee/d5/fb/a8938f6f7c2eab/US08768868-20140701-D00010.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/4c/1b/cd/ac3c9ed3a80d83/US08768868-20140701-D00010.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="1002">
            <meta itemprop="label" content="ROC curve">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="925">
              <meta itemprop="top" content="515">
              <meta itemprop="right" content="978">
              <meta itemprop="bottom" content="623">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="10">
            <meta itemprop="id" content="104">
            <meta itemprop="label" content="multi-class classifier">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="346">
              <meta itemprop="top" content="554">
              <meta itemprop="right" content="430">
              <meta itemprop="bottom" content="638">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/4e/de/16/bb3bb4a5be7e3d/US08768868-20140701-D00011.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/24/c5/2b/f9fc58bae7ed80/US08768868-20140701-D00011.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1100">
            <meta itemprop="label" content="data processing system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="255">
              <meta itemprop="top" content="1207">
              <meta itemprop="right" content="318">
              <meta itemprop="bottom" content="1336">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1102">
            <meta itemprop="label" content="input">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="690">
              <meta itemprop="top" content="1685">
              <meta itemprop="right" content="753">
              <meta itemprop="bottom" content="1814">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1104">
            <meta itemprop="label" content="output">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="464">
              <meta itemprop="top" content="357">
              <meta itemprop="right" content="525">
              <meta itemprop="bottom" content="472">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1106">
            <meta itemprop="label" content="processor">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="772">
              <meta itemprop="top" content="355">
              <meta itemprop="right" content="830">
              <meta itemprop="bottom" content="486">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="11">
            <meta itemprop="id" content="1108">
            <meta itemprop="label" content="memory">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1170">
              <meta itemprop="top" content="355">
              <meta itemprop="right" content="1232">
              <meta itemprop="bottom" content="470">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/c7/ec/ec/c3b99b3afd8704/US08768868-20140701-D00012.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/d2/f2/f8/7ae72eee72ce97/US08768868-20140701-D00012.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1200">
            <meta itemprop="label" content="floppy disk">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="430">
              <meta itemprop="top" content="241">
              <meta itemprop="right" content="492">
              <meta itemprop="bottom" content="380">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="12">
            <meta itemprop="id" content="1202">
            <meta itemprop="label" content="optical disk">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="829">
              <meta itemprop="top" content="469">
              <meta itemprop="right" content="886">
              <meta itemprop="bottom" content="595">
            </span>
          </li>
        </ul>
      </li>
      </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    
    <ul>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06N</span>&mdash;<span itemprop="Description">COMPUTER SYSTEMS BASED ON SPECIFIC COMPUTATIONAL MODELS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06N5/00</span>&mdash;<span itemprop="Description">Computer systems using knowledge-based models</span>
            <meta itemprop="Leaf" content="true">
            
            <meta itemprop="FirstCode" content="true">
          </li>
          </ul>
      </li>
      </ul>
  </section>

  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA134955115" lang="EN" load-source="patent-office">
    <div num="p-0001" class="abstract">Described is a system for multi-class classifier threshold-offset estimation for visual object recognition. The system receives an input image with input features for classifying. A pair-wise classifier is trained for each pair of a plurality of object classes. A set of classification responses is generated, and a multi-class receiver-operating-characteristics (ROC) curve is computed for a set of threshold-offsets. An objective function of classification performance is computed from the ROC curve and optimized using particle swarm optimization (PSO) to generate a set of optimized threshold-offsets. The optimized threshold-offsets are then applied to the classification responses. The resulting classification responses are compared to a predetermined value to classify each input feature as belonging to one object class or another. The tuning of the threshold-offsets with (PSO) improves classification performance in a visual object recognition system.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><div mxw-id="PDES69860389" lang="EN" load-source="patent-office" class="description">
    
    <heading>GOVERNMENT LICENSE RIGHTS</heading>
    <p num="p-0002">This invention was made with government support under U.S. Government Contract Number HR0011-10-C-0033 DARPA Neovision2. The government has certain rights in the invention.</p>
    
    
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="p-0003">(1) Field of Invention</p>
    <p num="p-0004">The present invention relates to a system for improving the performance of a multi-class classifier in a visual object detection system and, more particularly, to a system for improving the performance of a multi-class classifier in a visual object detection system using particle swarm optimization to estimate threshold-offset.</p>
    <p num="p-0005">(2) Description of Related Art</p>
    <p num="p-0006">Multi-class classification involves assigning one of several class labels to an input object. Typical approaches to multi-class visual object recognition utilize the precision-recall curve to depict recognition performance. The Precision-Recall curve is a widely used tool to evaluate the performance of scoring functions in discriminating between two populations. The use of the Precision-Recall curve stems from focusing on the problem of image retrieval as opposed to surveillance. The separate domains of image retrieval and surveillance consider different types of errors as more or less tolerable. For instance, the number of images of the same target that appears before a surveillance object recognition system is more numerous and, as a partial result, false-positive rates of whole percentage points are not as tolerable as they are in image retrieval.</p>
    <p num="p-0007">Multi-class visual object recognition for surveillance has been an active research problem, but much of the progress has been made on tracking and the 2-class problem, as opposed to the multi-class problem. For the multi-class problem, the community appears waiting for the results to emerge from the image retrieval research. Because of this and because multi-class visual object recognition has defined different types of errors as tolerable, the issue of tuning the multi-class classification to suit the surveillance problem has not been investigated in depth. Thus, a continuing need exists for a solution to the problem of multi-class visual object recognition for surveillance.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="p-0008">The present invention relates to a system for multi-class classifier threshold-offset estimation. The system comprises one or more processors and a memory having instructions such that when the instructions are executed, the one or more processors perform operations of first receiving an input image comprising a set of input features. A classifier is then trained for each pair of a plurality of object classes M. A set of classification responses r is generated based on the set of input features. A multi-class receiver-operating-characteristics (ROC) curve is computed for a set of threshold-offsets x. Next an objective function of classification performance f(x) is computed from the ROC curve. The objective function of classification performance f(x) is then optimized through particle swarm optimization to generate a set of optimized threshold-offsets x. The set of optimized threshold-offsets x is applied to the set of classification responses r to generate a set of classification responses r. Each classification response in the set of classification responses r is compared to a predetermined value to classify the set of input features as belonging to an object class.</p>
    <p num="p-0009">In another aspect, the set of classification responses r is a set of M(M1)/2 classification responses, where r=[r<sub>12 </sub>r<sub>13 </sub>r<sub>14 </sub>. . . r<sub>1m </sub>r<sub>23 </sub>r<sub>24 </sub>. . . r<sub>2m</sub>, r<sub>34 </sub>. . . r<sub>(m-1)m</sub>], and each subscript denotes an object class.</p>
    <p num="p-0010">In another aspect, r=r+x, where x=(t<sub>12</sub>, t<sub>13</sub>, t<sub>14</sub>, . . . , t<sub>1M</sub>, . . . ), and where t denotes a threshold-offset.</p>
    <p num="p-0011">In another aspect, a vote designating the set of input features as belonging to one object class of each pair of the plurality of object classes M or the other is generated to generate a set of votes. The set of votes is collected to determine which object class of the plurality of object classes M received a majority of the set of votes. The set of input features is classified as belonging to the object class receiving the majority of the set of votes.</p>
    <p num="p-0012">In another aspect, an area under the ROC curve (AUC) is extracted to determine a true-positive (TP) rate for a given false-positive rate; and the objective function is defined as:
<br/>
<i>f</i> <sub>1</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
<br/>
wherein each subscript denotes an object class.
</p>
    <p num="p-0013">In another aspect, an area under the ROC curve (AUC) is extracted to determine a true-positive (TP) rate for a given false-positive rate; and the objective function is defined as:
<br/>
<i>f</i> <sub>2</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
<br/>
wherein each subscript denotes an object class and * denotes multiplication.
</p>
    <p num="p-0014">In another aspect, an area under the ROC curve (AUC) is extracted to determine a true-positive (TP) rate for a given false-positive rate; and the objective function is defined as:
<br/>
<i>f</i> <sub>3</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
<br/>
wherein each subscript denotes an object class.
</p>
    <p num="p-0015">In another aspect, an area under the ROC curve (AUC) is extracted to determine a true-positive (TP) rate for a given false-positive rate; and the objective function is defined as:
<br/>
<i>f</i> <sub>4</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
<br/>
wherein each subscript denotes an object class and * denotes multiplication.
</p>
    <p num="p-0016">As can be appreciated by one in the art, the present invention also comprises a method for causing a processor to perform the operations described herein.</p>
    <p num="p-0017">As can be appreciated by one in the art, the present invention also comprises a computer program product comprising computer-readable instruction means stored on a non-transitory computer-readable medium that are executable by a computer having a processor for causing the processor to perform the operations described herein.</p>
    
    
    <description-of-drawings>
      <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <p num="p-0018">The objects, features and advantages of the present invention will be apparent from the following detailed descriptions of the various aspects of the invention in conjunction with reference to the following drawings, where:</p>
      <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram depicting the application of learned threshold-offset using particle swarm optimization (PSO) in multi-class feature classification according to the present invention;</p>
      <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a diagram illustrating the application of a series of scalar thresholds to binary classifier responses according to the present invention;</p>
      <p num="p-0021"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a confusion matrix calculated after applying the threshold-offset to all binary classifier responses according to the present invention;</p>
      <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a graph depicting a multi-class receiver-operator-characteristics (ROC) curve according to the present invention;</p>
      <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a graph depicting ROC curves for three object classes prior to PSO according to the present invention;</p>
      <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a graph depicting ROC curves for three object classes after tuning with PSO according to the present invention;</p>
      <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a table showing area under the curve (AUC) changes from threshold-offset tuning with PSO according to the present invention;</p>
      <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a graph depicting ROC curves for three object classes after tuning with PSO;</p>
      <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a table showing true-positive (TP) rate changes from threshold-offset tuning with PSO according to the present invention;</p>
      <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a flow diagram depicting a method of multi-class classifier threshold-offset estimation with PSO according to the present invention;</p>
      <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 11</figref> is an illustration of a data processing system according to the present invention; and</p>
      <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 12</figref> is an illustration of a computer program product according to the present invention.</p>
    </description-of-drawings>
    
    
    <heading>DETAILED DESCRIPTION</heading>
    <p num="p-0031">The present invention relates to a system for improving the performance of a multi-class classifier in a visual object detection system and, more particularly, to a system for improving the performance of a multi-class classifier in a visual object detection system using particle swarm optimization (PSO) to estimate threshold-offset. The following description is presented to enable one of ordinary skill in the art to make and use the invention and to incorporate it in the context of particular applications. Various modifications, as well as a variety of uses, in different applications will be readily apparent to those skilled in the art, and the general principles defined herein may be applied to a wide range of embodiments. Thus, the present invention is not intended to be limited to the embodiments presented, but is to be accorded with the widest scope consistent with the principles and novel features disclosed herein.</p>
    <p num="p-0032">In the following detailed description, numerous specific details are set forth in order to provide a more thorough understanding of the present invention. However, it will be apparent to one skilled in the art that the present invention may be practiced without necessarily being limited to these specific details. In other instances, well-known structures and devices are shown in block diagram form, rather than in detail, in order to avoid obscuring the present invention.</p>
    <p num="p-0033">The reader&#39;s attention is directed to all papers and documents which are filed concurrently with this specification and which are open to public inspection with this specification, and the contents of all such papers and documents are incorporated herein by reference. All the features disclosed in this specification, (including any accompanying claims, abstract, and drawings) may be replaced by alternative features serving the same, equivalent or similar purpose, unless expressly stated otherwise. Thus, unless expressly stated otherwise, each feature disclosed is one example only of a generic series of equivalent or similar features.</p>
    <p num="p-0034">Furthermore, any element in a claim that does not explicitly state means for performing a specified function, or step for performing a specific function, is not to be interpreted as a means or step clause as specified in 35 U.S.C. Section 112, Paragraph 6. In particular, the use of step of or act of in the claims herein is not intended to invoke the provisions of 35 U.S.C. 112, Paragraph 6.</p>
    <p num="p-0035">Please note, if used, the labels left, right, front, back, top, bottom, forward, reverse, clockwise and counter-clockwise have been used for convenience purposes only and are not intended to imply any particular fixed direction. Instead, they are used to reflect relative locations and/or directions between various portions of an object. As such, as the present invention is changed, the above labels may change their orientation.</p>
    <p num="p-0036">(1) Principal Aspects</p>
    <p num="p-0037">The present invention has three principal aspects. The first is a system for multi-class classifier threshold-offset estimation. The system is typically in the form of a computer system, computer component, or computer network operating software or in the form of a hard-coded instruction set. This system may take a variety of forms with a variety of hardware devices and may include computer networks, handheld computing devices, cellular networks, satellite networks, and other communication devices. As can be appreciated by one skilled in the art, this system may be incorporated into a wide variety of devices that provide different functionalities. The second principal aspect is a method for multi-class classifier threshold-offset estimation, typically in the form of software, operated using a data processing system (computer or computer network). The third principal aspect is a computer program product. The computer program product generally represents computer-readable instruction means (instructions) stored on a non-transitory computer-readable medium such as an optical storage device, e.g., a compact disc (CD) or digital versatile disc (DVD), or a magnetic storage device such as a floppy disk or magnetic tape. Other, non-limiting examples of computer-readable media include hard disks, read-only memory (ROM), and flash-type memories.</p>
    <p num="p-0038">The term instruction means as used with respect to this invention generally indicates a set of operations to be performed on a computer, and may represent pieces of a whole program or individual, separable, software modules. Non-limiting examples of instruction means include computer program code (source or object code) and hard-coded electronics (i.e. computer operations coded into a computer chip). The instruction means may be stored in the memory of a computer or on a non-transitory computer-readable medium such as a floppy disk, a CD-ROM, and a flash drive.</p>
    <p num="p-0039">(2) Specific Details</p>
    <p num="p-0040">The present invention describes a method to tune the threshold-offsets of pair-wise multi-class classifiers to maximize classification performance using Particle Swarm Optimization (PSO). The method consists of a post-processing step used to improve the performance of a multi-class classifier in a visual object detection system which locates real objects in images. The present invention improves performance on transforming images of objects-of-interest to images with marked locations of objectives-of-interest.</p>
    <p num="p-0041">A well-established method of constructing a multi-class classifier, which is also utilized in the present invention, is from training a classifier for each pair of classes among M object classes (e.g., vehicle, pedestrian). With this method, a total of M(M1)/2 classifiers are trained and applied to a test sample. Then, each pair-wise classifier generates a vote for a class, and a classification is determined by collecting all the votes and selecting the class with the majority vote. The immediate output from constructing a multi-class classifier from pair-wise classifiers is an optimal division only between two classes for each pair-wise classifier with a threshold of zero, disregarding the presence of any other classes.</p>
    <p num="p-0042">The challenge lies in optimally selecting the threshold for each of the pair-wise classifiers to achieve the best possible classification performance. Such a situation may occur if one does not wish to operate at equal false-alarm and miss rates. In visual object detection, a false alarm, or false-positive, is an indication that an object is present in an image when it is not. A miss, or false-negative, is the absence of an indication of an object in an image when it is, in fact, present in the image. In some cases, it is more desirable to tune the classifier such that the classifier performs at a minimally tolerable false-positive (i.e., object absent, signal present) rate. For instance, it may be desirable to bias the threshold towards some classes that have a more balanced (i.e., equal in value) true-positive (i.e., object present, signal present) rate for all non-background-classes.</p>
    <p num="p-0043">A receiver-operating-characteristic (ROC) curve is a graphical plot of the sensitivity for a binary (2-class) classifier system as its discrimination threshold is varied. Sensitivity refers to the true-positive rate versus false-positive rate. In order to traverse the multi-class ROC surface, multiple thresholds need to be tuned in order to obtain the thresholds that achieve the desired operating points. The invention described herein solves this problem by tuning the threshold-offsets with PSO.</p>
    <p num="p-0044">PSO is a relatively simple optimization method that has its roots in artificial life in general, and to bird flocking and swarming theory in particular. Conceptually, it includes aspects of genetic algorithms and evolutionary programming. A population of potential solutions is maintained as the positions of a set of particles in a solution space, where each dimension represents one solution component. Each particle is assigned a velocity vector and the particles then cooperatively explore the solution space in search of an objective function optima. Each particle keeps track of its coordinates in a multi-dimensional space, keeping track of the current position x<sub>i</sub>, and the best solution (p<sub>i</sub>) it has observed so far. A global best position variable (p<sub>g</sub>) stores the best location among all particles. The velocity of each particle is then changed towards p<sub>i </sub>and p<sub>g </sub>in a dynamical way according to:
<br/>
<i>v</i> <sub>i</sub>(<i>t+</i>1)=<i>wv</i> <sub>i</sub>(<i>t</i>)+<i>c</i> <sub>i</sub><sub>1</sub> <i>[p</i> <sub>i</sub>(<i>t</i>)<i>x</i> <sub>i</sub>(<i>t</i>)]+<i>c</i> <sub>2</sub><sub>2</sub> <i>p</i> <sub>g</sub>(<i>t</i>)<i>x</i> <sub>i</sub>(<i>t</i>)x<sub>i</sub>(<i>t+</i>1)=<i>x</i> <sub>i</sub>(<i>t</i>)+<i>v</i> <sub>i</sub>(<i>t+</i>1)
<br/>
where x<sub>i</sub>(t) and v<sub>i</sub>(t) are the position and velocity vectors at time t of the i-th particle, and c<sub>1 </sub>and c<sub>2 </sub>are parameters that weight the influence of their respective terms in the velocity update equation, w is a decay constant which allows the swarm to converge to a solution more quickly, <sub>1 </sub>and <sub>2 </sub>are random numbers between 0 and 1 that introduce a degree of random exploration, and x is a parameter that controls the convergence properties of the swarm.
</p>
    <p num="p-0045">An advantage of utilizing PSO is the ability to avoid computing complex derivatives in order to optimize the objective function. PSO allows a larger space of possible objective functions to choose from. As described in further detail below, the present invention is used to optimize objective functions that utilize the geometric or arithmetic mean of the areas under the ROC (AUC) of each class or that of the true-positive (TP) rate given a particular false-positive rate.</p>
    <p num="p-0046">As described above, a well-established method of constructing a multi-class classifier is by training a classifier for each pair of classes among M classes. With this method, a total of M(M1)/2 classifiers are trained and applied to a test sample. Each pair-wise classifier then generates a vote for a class, and a classification is determined by collecting all the votes and selecting the class with the majority vote. <figref idrefs="DRAWINGS">FIG. 1</figref> depicts the relative location of where the learned threshold-offset of the present invention is applied in a multi-class visual object recognition system <b>100</b>. In the present invention, an input image (or image patch) <b>102</b> is received. A pair-wise multi-class classifier <b>104</b> first generates M(M1)/2 responses r <b>106</b>, where r=[r<sub>12 </sub>r<sub>13 </sub>r<sub>14 </sub>. . . r<sub>1m </sub>r<sub>23 </sub>r<sub>24 </sub>. . . r<sub>2m </sub>r<sub>34 </sub>. . . r<sub>(m-1)m</sub>]. In the process of voting, each response casts a vote for one of the two classes (e.g., background class versus non-background class). A vote is cast by comparing the response to a predetermined value, such as zero. As a non-limiting example, if the response is equal to or greater than zero, it is one class; if less than zero, the other class. The class with the most votes determines which class the input features are predicted to belong. Depending on the thresholds chosen, the outcomes may be biased towards classifying input to a certain class, such as the background class. Often, a bias may raise the true-positive rate for one class at a cost of lowering the true-positive rate for another only slightly, thereby also raising the overall average true-positive rate across classes.</p>
    <p num="p-0047">In the present invention, r=r+x, where x=(t<sub>12</sub>,t<sub>13</sub>,t<sub>14</sub>, . . . , t<sub>1M</sub>, . . . ) is the set of threshold-offsets. As shown in <figref idrefs="DRAWINGS">FIG. 1</figref>, PSO is used to tune the set of threshold-offsets x <b>108</b> to optimize an objective function of classification performance, which is described in further detail below. The set of threshold-offsets x is applied <b>110</b> to the responses r <b>106</b> to obtain r <b>112</b>. Finally, a majority vote <b>114</b> is performed based on the responses to determine which class the input features are predicted to belong. The output y <b>116</b> represents the class prediction for each input feature.</p>
    <p num="p-0048">Depending on the problem, the objective function can be defined as:
<br/>
<i>f</i> <sub>1</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . (1)
<br/>
<i>f</i> <sub>2</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . (2)
<br/>
<i>f</i> <sub>3</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . (3)
<br/>
<i>f</i> <sub>4</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,(4)
<br/>
where AUC denotes the area under the ROC curve, and TP denotes the true-positive rate. Objectives (1) and (2) are functions of the areas under the ROC curve (i.e., true-positives vs. false-positives curve), while objectives (3) and (4) are functions of the true-positive rate for a given false-positive rate. The subscript denotes the class. The objectives using the sum over the classes (objectives (1) and (3)) result in maximizing the average performance for each class. The objectives using the products (objectives (2) and (4)) favor that all factors be equally high. The first set of objectives (objectives (1) and (2)), using the AUC, tunes the thresholds to obtain the best classifiers over all operating points. The second set of objectives (objectives (3) and (4)), using the TP, obtains the best classifiers for a given operating point.
</p>
    <p num="p-0049">An example of an algorithm for finding x that maximizes f<sub>k</sub>(x) is summarized below:</p>
    <p num="h-0006">Require: Number of classes M</p>
    <p num="h-0007">Require: Set of r=M(M1)/2 classification responses (r<sub>12</sub>,r<sub>13</sub>,r<sub>14</sub>, . . . , r<sub>1M</sub>, . . . )</p>
    <p num="h-0008">Require: c1,c2,w PSO damping factors. typ: (1,1,0.8)</p>
    <p num="h-0009">Require: Number of iterations N</p>
    <p num="h-0010">Require: Number of particles P</p>
    <p num="h-0011">Require: Range of thresholds to search over X. typ: X=10</p>
    <p num="h-0012">Require: Objective function f(x)</p>
    <p num="p-0050">
      <tables id="TABLE-US-00001" num="00001">
        <tgroup align="left" colsep="0" rowsep="0" cols="2">
            <colspec colname="1" colwidth="49pt" align="center"> </colspec>
            <colspec colname="2" colwidth="168pt" align="left"> </colspec>
            </tgroup> <row>
                <entry namest="1" nameend="2" align="center" rowsep="1"> </entry>
              </row> <row>
                <entry>1: </entry>
                <entry>dim = M(M-1)/2</entry>
              </row> <row>
                <entry>2:</entry>
                <entry>v = zeros(dim, l)</entry>
              </row> <row>
                <entry>3: </entry>
                <entry>x = rand(dim, P) * 2-1) * X</entry>
              </row> <row>
                <entry>4: </entry>
                <entry>1 = x</entry>
              </row> <row>
                <entry>5: </entry>
                <entry>gconf = -inf</entry>
              </row> <row>
                <entry>6: </entry>
                <entry>lconf = -inf(dim, 1)</entry>
              </row> <row>
                <entry>7: </entry>
                <entry>for n = 1:N</entry>
              </row> <row>
                <entry>8:</entry>
                <entry>for i = 1:P</entry>
              </row> <row>
                <entry>9:</entry>
                <entry>xconf(i) = f(x(:, i))</entry>
              </row> <row>
                <entry>10:</entry>
                <entry>if(lcongf(i) &lt; xconf(i))</entry>
              </row> <row>
                <entry>11:</entry>
                <entry>1conf(i) = xconf(i)</entry>
              </row> <row>
                <entry>12:</entry>
                <entry>1(:, i) = x(:, i)</entry>
              </row> <row>
                <entry>13:</entry>
                <entry>end</entry>
              </row> <row>
                <entry>14:</entry>
                <entry>end</entry>
              </row> <row>
                <entry>15:</entry>
                <entry>for i = 1:P</entry>
              </row> <row>
                <entry>16:</entry>
                <entry>if(gconf(i) &lt; lconf(i))</entry>
              </row> <row>
                <entry>17:</entry>
                <entry>gconf(i) = max(gconf(i), 1conf(i))</entry>
              </row> <row>
                <entry>18:</entry>
                <entry>g(:, i) = 1(:, i)</entry>
              </row> <row>
                <entry>19:</entry>
                <entry>end</entry>
              </row> <row>
                <entry>20:</entry>
                <entry>end</entry>
              </row> <row>
                <entry>21:</entry>
                <entry> </entry>
              </row> <row>
                <entry>22:</entry>
                <entry>r1 = rand(0, c1)</entry>
              </row> <row>
                <entry>23:</entry>
                <entry>r2 = rand(0, c2)</entry>
              </row> <row>
                <entry>24:</entry>
                <entry>v = w * v + r1 * (1-x) + r2 * (repmat(g,[1 P])-x)</entry>
              </row> <row>
                <entry>25:</entry>
                <entry>x = x + v</entry>
              </row> <row>
                <entry>26:</entry>
                <entry>end</entry>
              </row> <row>
                <entry>27: </entry>
                <entry>return g</entry>
              </row> <row>
                <entry namest="1" nameend="2" align="center" rowsep="1"> </entry>
              </row> <table frame="none" colsep="0" rowsep="0" class="description-table">
          <thead>
              
            </thead>
            <tbody valign="top">
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </tbody>
          
        </table>
      </tables>
    </p>
    <p num="p-0051">To compute the multi-class ROC curve for a given threshold offset x, first the threshold-offset for all classifier responses is applied. Then, a series of scalar thresholds t are applied to the binary classifiers that pertain to the background class to compute a confusion matrix. A confusion matrix contains information about actual and predicted classifications done by a classification system. To generate a series of confusion matrices for the case of two positive classes, C<sub>1 </sub> <b>200</b> and C<sub>2 </sub> <b>202</b>, and a background class B <b>204</b>, a threshold t is applied on responses t<sub>1B </sub> <b>206</b> and t<sub>2B </sub> <b>208</b> as illustrated in <figref idrefs="DRAWINGS">FIG. 2</figref>.</p>
    <p num="p-0052"> <figref idrefs="DRAWINGS">FIG. 3</figref> depicts a confusion matrix calculated after applying the threshold-offset to all binary classifier responses and the threshold to the component binary-classifiers involving the background class. From here, the diagonal entries for classes c<sub>1 </sub>and c<sub>2</sub>, P(C<sub>1</sub>|C<sub>1</sub>) <b>302</b> and P(c<sub>2</sub>|c<sub>2</sub>) <b>304</b>, are the true-positive rates and 1-P(B|B) <b>306</b> is the false-positive, or false alarm rate (FAR). A series of thresholds will result in a series of true-positive rate and false-positive rate tuples (i.e., ordered list of elements) needed to plot the multi-class ROC. <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates an abstract depiction of the multi-class ROC curve, where the x-axis <b>400</b> represents the false-positive rate, or FAR, while the y-axis <b>402</b> represents the true-positive rate, or probability of detection PD(c). Each curve represents the true-positive and false-positive trade-off for a particular class. For instance, curve PD(C1) <b>404</b> represents the true-positive and false-positive trade-off for class c<sub>1</sub>, while curve PD(C2) <b>406</b> represents the true-positive and false-positive trade-off for class c<sub>2</sub>. Finally, the AUC, or the true-positive rate for a given false-positive rate, is extracted from the curve. The AUC is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.</p>
    <p num="p-0053">An example output from an unoptimized multi-class ROC for a multi-class classifier is shown in <figref idrefs="DRAWINGS">FIG. 5</figref>. Curve <b>500</b> represents objects detected as vehicle class, curve <b>502</b> represents objects detected as pedestrian class, and curve <b>504</b> represents objects detected as bike class. <figref idrefs="DRAWINGS">FIG. 6</figref> depicts the resulting multi-class ROC after applying the PSO threshold-offset tuning routine with objective function (2). Curve <b>600</b> represents objects detected as vehicle class, curve <b>602</b> represents objects detected as pedestrian class, and curve <b>604</b> represents objects detected as bike class. The geometric mean (product) of the AUCs is used as the objective function for this instance and the tuning procedure raised the value from 0.6294 to 0.7209. As shown in the table depicted in <figref idrefs="DRAWINGS">FIG. 7</figref>, the result of tuning lowered the AUC for the vehicle class by 0.3020, but it raised the AUC for the bike class by 0.2037 and the pedestrian class by 0.3378, which combined is more than the amount lost for the vehicle class.</p>
    <p num="p-0054"> <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates the resulting multi-class ROC after applying the PSO threshold-offset tuning routine with objective (4). Curve <b>800</b> represents objects detected as vehicle class, curve <b>802</b> represents objects detected as pedestrian class, and curve <b>804</b> represents objects detected as bike class. The geometric mean (product) of the true-positive rates at 10% false alarm rate is used as the objective function for this instance. The tuning procedure raised the mean value from 0.1604 to 0.2420. As shown in the table depicted in <figref idrefs="DRAWINGS">FIG. 9</figref>, the cost of losing 23% true-positive rate (TPR) in the vehicle class is offset by a more than 18% increase in TPR for both pedestrian and bike classes.</p>
    <p num="p-0055"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a flow diagram detailing the major steps involved in threshold-offset estimation with PSO for multi-class classification, which expands on what is depicted in <figref idrefs="DRAWINGS">FIG. 1</figref>. First, the system receives an input image consisting of input features <b>102</b>. A classifier is trained for each pair of a plurality of object classes <b>104</b>. Then, a set of classification responses r is generated based on the input features <b>106</b>. A ROC curve is computed for a set of threshold-offsets x <b>1000</b>, as described above. The system next computes an objective function f(x) from components of the ROC curve <b>1002</b>. The objective function f(x) is optimized using PSO to generate a set of optimized threshold-offsets x <b>1008</b>. The set of optimized threshold-offsets x is then applied to the classification responses r to generate a set of classification responses r <b>110</b> and <b>112</b>. Finally, each classification response in the set of classification responses r is compared to a predetermined value (e.g., zero) to classify the input features as belonging to a particular object class <b>114</b>, as described in detail above.</p>
    <p num="p-0056"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates a block diagram depicting components of a data processing system <b>1100</b> (e.g., computer) incorporating the operations of the method described above and throughout the specification. The method utilizes a data processing system <b>1100</b> for storing computer executable instructions (or instruction means) for causing a processor to carry out the operations of the above described method. The data processing system <b>1100</b> comprises an input <b>1102</b> for receiving information from a user. Information received may include input from devices such as cameras, scanners, keypads, keyboards, microphone, other peripherals such as storage devices, other programs, etc. The input <b>1102</b> may include multiple ports. An output <b>1104</b> is connected with a processor <b>1106</b> (or processors) for providing information for transmission to other data processing systems, to storage devices, to display devices such as monitors, to generating information necessary for delivery, and to other mechanisms for presentation in user-usable forms. The input <b>1102</b> and the output <b>1104</b> are both coupled with the processor <b>1106</b>, which may be a general-purpose computer processor or a specialized processor designed specifically for use with the present invention. The processor <b>1106</b> is coupled with a memory <b>1108</b> to permit storage of data and software to be manipulated by commands to the processor <b>1106</b>. The memory <b>1108</b> includes instructions such that when the instructions are executed, the processor <b>1108</b> (or processors) performs operations described above and throughout the specification.</p>
    <p num="p-0057">An illustrative diagram of a computer program product embodying the present invention is depicted in <figref idrefs="DRAWINGS">FIG. 12</figref>. As a non-limiting example, the computer program product is depicted as either a floppy disk <b>1200</b> or an optical disk <b>1202</b>. However, as mentioned previously, the computer program product generally represents computer readable code (i.e., instruction means or instructions) stored on any compatible non-transitory computer readable medium.</p>
    <p num="p-0058">The invention described herein is applicable to systems for visual object recognition of multiple classes. Non-limiting examples of applications include automatic target recognition and surveillance systems. However, as can be appreciated by one skilled in the art, the invention is applicable to all multi-class classification systems that utilize a pair-wise classifier approach.</p>
    
  </div>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">24</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM61421689" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement>
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A system for multi-class classifier threshold-offset estimation for visual object recognition, the system comprising:
<div class="claim-text">one or more processors and a memory having instructions such that when the instructions are executed, the one or more processors perform operations of:</div>
<div class="claim-text">receiving an input image comprising a set of input features;</div>
<div class="claim-text">training a classifier for each pair of a plurality of object classes M;</div>
<div class="claim-text">generating a set of classification responses r based on the set of input features;</div>
<div class="claim-text">computing a multi-class receiver-operating-characteristics (ROC) curve for a set of threshold-offsets x;</div>
<div class="claim-text">computing an objective function of classification performance f(x) from the ROC curve;</div>
<div class="claim-text">optimizing the objective function of classification performance f(x) through particle swarm optimization to generate a set of optimized threshold-offsets x;</div>
<div class="claim-text">applying the set of optimized threshold-offsets x to the set of classification responses r to generate a set of classification responses r; and</div>
<div class="claim-text">comparing each classification response in the set of classification responses r to a predetermined value to classify the set of input features as belonging to an object class.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The system for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the set of classification responses r is a set of M(M1)/2 classification responses, where r=[r<sub>12 </sub>r<sub>13 </sub>r<sub>14 </sub>. . . r<sub>1m </sub>r<sub>23 </sub>r<sub>24 </sub>. . . r<sub>2m </sub>r<sub>34 </sub>. . . r<sub>(m-1)m</sub>], and each subscript denotes an object class.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The system for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein r=r+x, where x=(t<sub>12</sub>, t<sub>13</sub>, t<sub>14</sub>, . . . , t<sub>1M</sub>, . . . ), and where t denotes a threshold-offset.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The system for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the system further performs operation of:
<div class="claim-text">generating a vote designating the set of input features as belonging to one object class of each pair of the plurality of object classes M or the other to generate a set of votes;</div>
<div class="claim-text">collecting the set of votes to determine which object class of the plurality of object classes M received a majority of the set of votes;</div>
<div class="claim-text">classifying the set of input features as belonging to the object class receiving the majority of the set of votes.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The system for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the system further performs operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>1</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
</div>
</div>
</div>
      <div class="claim-text">wherein each subscript denotes an object class.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The system for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the system further performs operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>2</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class and * denotes multiplication.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The system for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the system further performs operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>3</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The system for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the system further performs operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>4</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class and * denotes multiplication.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. A computer-implemented method for multi-class classifier threshold-offset estimation for visual object recognition, comprising an act of:
<div class="claim-text">causing a data processor to execute instructions stored on a memory such that upon execution, the data processor performs operations of:
<div class="claim-text">receiving an input image comprising a set of input features;</div>
<div class="claim-text">training a classifier for each pair of a plurality of object classes M;</div>
<div class="claim-text">generating a set of classification responses r based on the set of input features;</div>
<div class="claim-text">computing a multi-class receiver-operating-characteristics (ROC) curve for a set of threshold-offsets x;</div>
<div class="claim-text">computing an objective function of classification performance f(x) from the ROC curve;</div>
<div class="claim-text">optimizing the objective function of classification performance f(x) through particle swarm optimization to generate a set of optimized threshold-offsets x;</div>
<div class="claim-text">applying the set of optimized threshold-offsets x to the set of classification responses r to generate a set of classification responses r; and</div>
<div class="claim-text">comparing each classification response in the set of classification responses r to a predetermined value to classify the set of input features as belonging to an object class.</div>
</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the set of classification responses r is a set of M(M1)/2 classification responses, where r=[r<sub>12 </sub>r<sub>13 </sub>r<sub>14 </sub>. . . r<sub>1m </sub>r<sub>23 </sub>r<sub>24 </sub>r<sub>2m </sub>r<sub>34 </sub>. . . r<sub>(m-1)m</sub>], and each subscript denotes an object class.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein r=r+x, where x=(t<sub>12</sub>, t<sub>13</sub>, t<sub>14</sub>, . . . , t<sub>1M</sub>, . . . ), and where t denotes a threshold-offset.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The method for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising an act of:
<div class="claim-text">generating a vote designating the set of input features as belonging to one object class of each pair of the plurality of object classes M or the other to generate a set of votes;</div>
<div class="claim-text">collecting the set of votes to determine which object class of the plurality of object classes M received a majority of the set of votes;</div>
<div class="claim-text">classifying the set of input features as belonging to the object class receiving the majority of the set of votes.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The method for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising acts of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>1</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The method for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising acts of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>2</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class and * denotes multiplication.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The method for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising acts of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>3</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The method for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00012">claim 12</claim-ref>, further comprising acts of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>4</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class and * denotes multiplication.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. A computer program product for multi-class classifier threshold-offset estimation for visual object recognition, the computer program product comprising: computer-readable instruction means stored on a non-transitory computer-readable medium that are executable by a computer having a processor for causing the processor to perform operations of:
<div class="claim-text">receiving an input image comprising a set of input features;</div>
<div class="claim-text">training a classifier for each pair of a plurality of object classes M;</div>
<div class="claim-text">generating a set of classification responses r based on the set of input features;</div>
<div class="claim-text">computing a multi-class receiver-operating-characteristics (ROC) curve for a set of threshold-offsets x;</div>
<div class="claim-text">computing an objective function of classification performance f(x) from the ROC curve;</div>
<div class="claim-text">optimizing the objective function of classification performance f(x) through particle swarm optimization to generate a set of optimized threshold-offsets x;</div>
<div class="claim-text">applying the set of optimized threshold-offsets x to the set of classification responses r to generate a set of classification responses r; and</div>
<div class="claim-text">comparing each classification response in the set of classification responses r to a predetermined value to classify the set of input features as belonging to an object class.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The computer program product for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the set of classification responses r is a set of M(M1)/2 classification responses, where r=[r<sub>12 </sub>r<sub>13 </sub>r<sub>14 </sub>. . . r<sub>1m </sub>r<sub>23 </sub>r<sub>24 </sub>. . . r<sub>2m </sub>r<sub>34 </sub>. . . r<sub>(m-1)m</sub>], and each subscript denotes an object class.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The computer program product for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein r=r+x, where x=(t<sub>12</sub>, r<sub>13</sub>, t<sub>14</sub>, . . . t<sub>1M</sub>, . . . ), and where t denotes a threshold-offset.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The computer program product for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising instruction means for causing the processor to perform an operation of:
<div class="claim-text">generating a vote designating the set of input features as belonging to one object class of each pair of the plurality of object classes M or the other to generate a set of votes;</div>
<div class="claim-text">collecting the set of votes to determine which object class of the plurality of object classes M received a majority of the set of votes;</div>
<div class="claim-text">classifying the set of input features as belonging to the object class receiving the majority of the set of votes.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The computer program product for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00020">claim 20</claim-ref>, further comprising instruction means for causing the processor to perform operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>1</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The computer program product for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00020">claim 20</claim-ref>, further comprising instruction means for causing the processor to perform operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>2</sub>(<i>x</i>)=<i>AUC</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>AUC</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class and * denotes multiplication.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. The computer program product for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00020">claim 20</claim-ref>, further comprising instruction means for causing the processor to perform operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>3</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))+<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))+ . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. The computer program product for multi-class classifier threshold-offset estimation as set forth in <claim-ref idref="CLM-00020">claim 20</claim-ref>, further comprising instruction means for causing the processor to perform operations of:
<div class="claim-text">extracting an area under the ROC curve (AUC) to determine a true-positive (TP) rate for a given false-positive rate; and</div>
<div class="claim-text">defining the objective function as:
<div class="claim-text"> <br/> <i>f</i> <sub>4</sub>(<i>x</i>)=<i>TP</i> <sub>1</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>2</sub>(<i>r</i>(<i>x</i>))*<i>TP</i> <sub>3</sub>(<i>r</i>(<i>x</i>))* . . . ,
</div>
</div>
<div class="claim-text">wherein each subscript denotes an object class and * denotes multiplication. </div>
</div>
    </div>
  </div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
        <span itemprop="applicationNumber">US13/440,881</span>
        <span itemprop="priorityDate">2012-04-05</span>
        <span itemprop="filingDate">2012-04-05</span>
        <span itemprop="title">Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
       </span>
        <span itemprop="ifiStatus">Active</span>
        <span itemprop="ifiExpiration">2032-12-20</span>
        <a href="/patent/US8768868B1/en">
            <span itemprop="representativePublication">US8768868B1</span>
            (<span itemprop="primaryLanguage">en</span>)
        </a>
    </section>

    <h2>Priority Applications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="priorityApps" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US13/440,881</span>
                   
                   <a href="/patent/US8768868B1/en">
                        <span itemprop="representativePublication">US8768868B1</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2012-04-05</td>
                <td itemprop="filingDate">2012-04-05</td>
                <td itemprop="title">Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
       </td>
              </tr>
           </tbody>
       </table>

    <h2>Applications Claiming Priority (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="appsClaimingPriority" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US13/440,881</span>
                   <a href="/patent/US8768868B1/en">
                        <span itemprop="representativePublication">US8768868B1</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2012-04-05</td>
                <td itemprop="filingDate">2012-04-05</td>
                <td itemprop="title">Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
       </td>
              </tr>
           </tbody>
       </table>

    

    

    <h2>Publications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Publication Number</th>
                    <th>Publication Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="pubs" itemscope repeat>
                <td>
                   <span itemprop="publicationNumber">US8768868B1</span>
                   
                   <span itemprop="thisPatent">true</span>
                   <a href="/patent/US8768868B1/en">US8768868B1
                       (<span itemprop="primaryLanguage">en</span>)
                   </a>
                </td>
                <td itemprop="publicationDate">2014-07-01</td>
              </tr>
           </tbody>
        </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=50982209</h2>

    <h2>Family Applications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Title</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="applications" itemscope repeat>
                <td>
                    <span itemprop="applicationNumber">US13/440,881</span>
                    <span itemprop="ifiStatus">Active</span>
                    <span itemprop="ifiExpiration">2032-12-20</span>
                    <a href="/patent/US8768868B1/en">
                        <span itemprop="representativePublication">US8768868B1</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                </td>
                <td itemprop="priorityDate">2012-04-05</td>
                <td itemprop="filingDate">2012-04-05</td>
                <td itemprop="title">Optimal multi-class classifier threshold-offset estimation with particle swarm optimization for visual object recognition 
       </td>
              </tr>
           </tbody>
        </table>

    

    

    <h2>Country Status (1)</h2>
      <table>
        <thead>
          <tr>
            <th>Country</th>
            <th>Link</th>
          </tr>
        </thead>
        <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
            <td>
              <span itemprop="countryCode">US</span>
                (<span itemprop="num">1</span>)
              <meta itemprop="thisCountry" content="true">
            </td>
            <td>
              <a href="/patent/US8768868B1/en">
                <span itemprop="representativePublication">US8768868B1</span>
                  (<span itemprop="primaryLanguage">en</span>)
              </a>
            </td>
          </tr>
      </tbody>
    </table>

    <h2>Cited By (7)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20140324762A1/en">
              <span itemprop="publicationNumber">US20140324762A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2013-04-27</td>
          <td itemprop="publicationDate">2014-10-30</td>
          <td><span itemprop="assigneeOriginal">Sas Institute Inc.</span></td>
          <td itemprop="title">Computation of receiver operating characteristic curves 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/CN104143116A/en">
              <span itemprop="publicationNumber">CN104143116A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-07-23</td>
          <td itemprop="publicationDate">2014-11-12</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">System soft protection combinatorial optimization method based on particle swarm optimization 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/CN105184288A/en">
              <span itemprop="publicationNumber">CN105184288A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-11-04</td>
          <td itemprop="publicationDate">2015-12-23</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Face recognition method and system 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2016167796A1/en">
              <span itemprop="publicationNumber">WO2016167796A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-04-17</td>
          <td itemprop="publicationDate">2016-10-20</td>
          <td><span itemprop="assigneeOriginal">Hewlett Packard Enterprise Development Lp</span></td>
          <td itemprop="title">Hierarchical classifiers 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2017052942A1/en">
              <span itemprop="publicationNumber">WO2017052942A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-09-25</td>
          <td itemprop="publicationDate">2017-03-30</td>
          <td><span itemprop="assigneeOriginal">Mcafee, Inc.</span></td>
          <td itemprop="title">Multi-label classification for overlapping classes 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/CN106650791A/en">
              <span itemprop="publicationNumber">CN106650791A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2016-11-21</td>
          <td itemprop="publicationDate">2017-05-10</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Improved particle swarm-based non-supervised remote sensing image classification method 
       </td>
        </tr><tr itemprop="forwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2018188309A1/en">
              <span itemprop="publicationNumber">WO2018188309A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2017-04-10</td>
          <td itemprop="publicationDate">2018-10-18</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Pedestrian identification device and method, and driving assistance device 
       </td>
        </tr>
      </tbody>
    </table>

    

    <h2>Citations (2)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20100141787A1/en">
              <span itemprop="publicationNumber">US20100141787A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-12-05</td>
          <td itemprop="publicationDate">2010-06-10</td>
          <td><span itemprop="assigneeOriginal">Fotonation Ireland Limited</span></td>
          <td itemprop="title">Face recognition using face tracker classifier data 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US7912246B1/en">
              <span itemprop="publicationNumber">US7912246B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2002-10-28</td>
          <td itemprop="publicationDate">2011-03-22</td>
          <td><span itemprop="assigneeOriginal">Videomining Corporation</span></td>
          <td itemprop="title">Method and system for determining the age category of people based on facial images 
       </td>
        </tr>
      </tbody>
    </table>

    

    
    <ul>
      
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2012</span>
        <ul>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2012-04-05</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US13/440,881</span>
            <a href="/patent/US8768868B1/en"><span itemprop="documentId">patent/US8768868B1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
            <span itemprop="thisApp" content="true" bool></span>
            
          </li>
          
        </ul>
      </li>
      
    </ul>
    

    </section>

  <section>
    <h2>Patent Citations (2)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US7912246B1/en">
              <span itemprop="publicationNumber">US7912246B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2002-10-28</td>
          <td itemprop="publicationDate">2011-03-22</td>
          <td><span itemprop="assigneeOriginal">Videomining Corporation</span></td>
          <td itemprop="title">Method and system for determining the age category of people based on facial images 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20100141787A1/en">
              <span itemprop="publicationNumber">US20100141787A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-12-05</td>
          <td itemprop="publicationDate">2010-06-10</td>
          <td><span itemprop="assigneeOriginal">Fotonation Ireland Limited</span></td>
          <td itemprop="title">Face recognition using face tracker classifier data 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Non-Patent Citations (9)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Dollar, P., Wojek, C., Schiele, B., Perona, P., Pedestrian detection: A benchmark, In Computer Vision and Pattern Recognition, 2009, all pages.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Duda, R.O., Hart, P.E., Stork, D.E., Pattern Classification, John Wiley &amp; Sons, Chichester, 2001, Chapter 5.2.2.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Ellis, A., Ferryman, J.M., PET 2010 and PETS2009 evaluation of results using individual ground truthed single views, In IEEE International Conference on Advanced Video and Signal Based Surveillace (AVSS), pp. 135-142, 2010.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Everingham, M., Good, L.V., Williams, C.K.I., Winn, J., Zisserman, A., The pascal visual object classes (voc) challenge, International Journal of Computer Vision, 88, 303-336, 2010.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Hastie, T., Tibshirani, R., Friedman, J., The Elements of statistical Learning. Data Mining, Inference, and Predition, 2nd edn., Springer Series in Statistics, 2009, p. 658.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Kasturi, R., Goldof, D., Soundararajan, P., Manohar, V., Garofolo, J., Bowers, R., Boonstra, M., Korzhova, V., Zhang, J., Framework for performance evaluation of face, text, and vehicle tetction and tracking in video: Data, metrics and protocol, IEEE Transactions on Pattern Analysis and Machine Intelligence, 31, 319-336, 2009.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Kennedy, J.; Eberhart, R.; Neural Networks, 1995, "<a href='http://scholar.google.com/scholar?q="Particle+Swarm+Optimization%2C"'>Particle Swarm Optimization,</a>" Proceedings., IEEE International Conference, Nov./Dec. 1995, 1942-1948 vol. 4.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Oh, S., Perera, A., Cuntoor, N., Chen, C.C., Lee, J.T., Mukherjee, S., Aggarwal, J., Lee, H., Davis, L., Swears, E., Wang, X., Ji, Q., Reddy, K., Shah, M., Vodrick, C., Pirsiavash, H., Ramanan, D., Yuen, J., Torralba, A., Song, B., Fong, A., Roy-Chowdhury, A., Desai, M., A large-scale benchmark dataset for event recognition in surveillance video, In IEEE Computer Vision and Pattern Recognition, 2011, all pages.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Wu, T.F., Lin, C.J., Weng, R.C., Pobability estimates for multi-class classification by pairwise coupling, Journal of Machine Learning Research 5, 975-1005, 2004.</span>
            
            
          </td>
        </tr>
      </tbody>
    </table>
  </section>

  <h2>Cited By (11)</h2>
  <table>
    <caption>* Cited by examiner,  Cited by third party</caption>
    <thead>
      <tr>
        <th>Publication number</th>
        <th>Priority date</th>
        <th>Publication date</th>
        <th>Assignee</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/US20140324762A1/en">
            <span itemprop="publicationNumber">US20140324762A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2013-04-27</td>
        <td itemprop="publicationDate">2014-10-30</td>
        <td><span itemprop="assigneeOriginal">Sas Institute Inc.</span></td>
        <td itemprop="title">Computation of receiver operating characteristic curves 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/US10192166B2/en">
            <span itemprop="publicationNumber">US10192166B2</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2013-04-27</td>
        <td itemprop="publicationDate">2019-01-29</td>
        <td><span itemprop="assigneeOriginal">Sas Institute Inc.</span></td>
        <td itemprop="title">Computation of receiver operating characteristic curves 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/CN104143116A/en">
            <span itemprop="publicationNumber">CN104143116A</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2014-07-23</td>
        <td itemprop="publicationDate">2014-11-12</td>
        <td><span itemprop="assigneeOriginal"></span></td>
        <td itemprop="title">System soft protection combinatorial optimization method based on particle swarm optimization 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/CN104143116B/en">
            <span itemprop="publicationNumber">CN104143116B</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2014-07-23</td>
        <td itemprop="publicationDate">2017-05-10</td>
        <td><span itemprop="assigneeOriginal"></span></td>
        <td itemprop="title">System soft protection combinatorial optimization method based on particle swarm optimization 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/WO2016167796A1/en">
            <span itemprop="publicationNumber">WO2016167796A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2015-04-17</td>
        <td itemprop="publicationDate">2016-10-20</td>
        <td><span itemprop="assigneeOriginal">Hewlett Packard Enterprise Development Lp</span></td>
        <td itemprop="title">Hierarchical classifiers 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/WO2017052942A1/en">
            <span itemprop="publicationNumber">WO2017052942A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2015-09-25</td>
        <td itemprop="publicationDate">2017-03-30</td>
        <td><span itemprop="assigneeOriginal">Mcafee, Inc.</span></td>
        <td itemprop="title">Multi-label classification for overlapping classes 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/US10417579B2/en">
            <span itemprop="publicationNumber">US10417579B2</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          
          
        </td>
        <td itemprop="priorityDate">2015-09-25</td>
        <td itemprop="publicationDate">2019-09-17</td>
        <td><span itemprop="assigneeOriginal">Mcafee, Inc.</span></td>
        <td itemprop="title">Multi-label classification for overlapping classes 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/CN105184288A/en">
            <span itemprop="publicationNumber">CN105184288A</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2015-11-04</td>
        <td itemprop="publicationDate">2015-12-23</td>
        <td><span itemprop="assigneeOriginal"></span></td>
        <td itemprop="title">Face recognition method and system 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/CN105184288B/en">
            <span itemprop="publicationNumber">CN105184288B</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2015-11-04</td>
        <td itemprop="publicationDate">2018-09-07</td>
        <td><span itemprop="assigneeOriginal"></span></td>
        <td itemprop="title">Face identification method and system 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/CN106650791A/en">
            <span itemprop="publicationNumber">CN106650791A</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2016-11-21</td>
        <td itemprop="publicationDate">2017-05-10</td>
        <td><span itemprop="assigneeOriginal"></span></td>
        <td itemprop="title">Improved particle swarm-based non-supervised remote sensing image classification method 
       </td>
      </tr><tr itemprop="forwardReferences" itemscope repeat>
        <td>
          
          
          <a href="/patent/WO2018188309A1/en">
            <span itemprop="publicationNumber">WO2018188309A1</span>
            (<span itemprop="primaryLanguage">en</span>)
          </a>
          <span itemprop="examinerCited">*</span>
          
        </td>
        <td itemprop="priorityDate">2017-04-10</td>
        <td itemprop="publicationDate">2018-10-18</td>
        <td><span itemprop="assigneeOriginal"></span></td>
        <td itemprop="title">Pedestrian identification device and method, and driving assistance device 
       </td>
      </tr>
    </tbody>
  </table>

  

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="6158210420148092107">
              <a href="/scholar/6158210420148092107"><span itemprop="scholarAuthors">Lin et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2008">2008</time>
            
          </td>
          <td itemprop="title">Particle swarm optimization for parameter determination and feature selection of support vector machines</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="5133062490197882089">
              <a href="/scholar/5133062490197882089"><span itemprop="scholarAuthors">Fawzi et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2018">2018</time>
            
          </td>
          <td itemprop="title">Analysis of classifiers robustness to adversarial perturbations</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="9379663896135003975">
              <a href="/scholar/9379663896135003975"><span itemprop="scholarAuthors">Bengio et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2010">2010</time>
            
          </td>
          <td itemprop="title">Label embedding trees for large multi-class tasks</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="15175982703693519457">
              <a href="/scholar/15175982703693519457"><span itemprop="scholarAuthors">Bazi et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2006">2006</time>
            
          </td>
          <td itemprop="title">Toward an optimal SVM classification system for hyperspectral remote sensing images</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="12599986996206879724">
              <a href="/scholar/12599986996206879724"><span itemprop="scholarAuthors">Tahir et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2007">2007</time>
            
          </td>
          <td itemprop="title">Simultaneous feature selection and feature weighting using Hybrid Tabu Search/K-nearest neighbor classifier</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="11148702709852594100">
              <a href="/scholar/11148702709852594100"><span itemprop="scholarAuthors">Yang et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2015">2015</time>
            
          </td>
          <td itemprop="title">Multi-class active learning by uncertainty sampling with diversity maximization</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="15399302916391331952">
              <a href="/scholar/15399302916391331952"><span itemprop="scholarAuthors">Sukhbaatar et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2014">2014</time>
            
          </td>
          <td itemprop="title">Learning from noisy labels with deep neural networks</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="7127186926810478238">
              <a href="/scholar/7127186926810478238"><span itemprop="scholarAuthors">Bertinetto et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2016">2016</time>
            
          </td>
          <td itemprop="title">Staple: Complementary learners for real-time tracking</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20080025568A1/en">
                <span itemprop="publicationNumber">US20080025568A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2008-01-31">2008-01-31</time>
            
            
          </td>
          <td itemprop="title">System and method for detecting still objects in images 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="6809391783707167088">
              <a href="/scholar/6809391783707167088"><span itemprop="scholarAuthors">Zhao et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2014">2014</time>
            
          </td>
          <td itemprop="title">Learning mid-level filters for person re-identification</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/CN101536035B/en">
                <span itemprop="publicationNumber">CN101536035B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2012-09-26">2012-09-26</time>
            
            
          </td>
          <td itemprop="title">Image recognition method, image recognition device, and image recognition program 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="2722378086422211145">
              <a href="/scholar/2722378086422211145"><span itemprop="scholarAuthors">Connolly et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2012">2012</time>
            
          </td>
          <td itemprop="title">An adaptive classification system for video-based face recognition</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="15766121733881161904">
              <a href="/scholar/15766121733881161904"><span itemprop="scholarAuthors">Imam et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2006">2006</time>
            
          </td>
          <td itemprop="title">z-SVM: An SVM for improved classification of imbalanced data</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="790674752619359439">
              <a href="/scholar/790674752619359439"><span itemprop="scholarAuthors">Li et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2010">2010</time>
            
          </td>
          <td itemprop="title">A positive and unlabeled learning algorithm for one-class classification of remote-sensing data</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="17976295457485514997">
              <a href="/scholar/17976295457485514997"><span itemprop="scholarAuthors">Chapelle et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2002">2002</time>
            
          </td>
          <td itemprop="title">Choosing multiple parameters for support vector machines</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="12325140929890847634">
              <a href="/scholar/12325140929890847634"><span itemprop="scholarAuthors">Lempitsky et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2010">2010</time>
            
          </td>
          <td itemprop="title">Learning to count objects in images</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="15420668772064676266">
              <a href="/scholar/15420668772064676266"><span itemprop="scholarAuthors">He et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2011">2011</time>
            
          </td>
          <td itemprop="title">A regularized correntropy framework for robust pattern recognition</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="17555563667651270584">
              <a href="/scholar/17555563667651270584"><span itemprop="scholarAuthors">Chung et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2012">2012</time>
            
          </td>
          <td itemprop="title">A hybrid network intrusion detection system using simplified swarm optimization (SSO)</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="1929078304293208987">
              <a href="/scholar/1929078304293208987"><span itemprop="scholarAuthors">Wu et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2005">2005</time>
            
          </td>
          <td itemprop="title">KBA: Kernel boundary alignment considering imbalanced data distribution</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="16954207470079428084">
              <a href="/scholar/16954207470079428084"><span itemprop="scholarAuthors">Sebe et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2004">2004</time>
            
          </td>
          <td itemprop="title">Skin detection: A bayesian network approach</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US8467599B2/en">
                <span itemprop="publicationNumber">US8467599B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2013-06-18">2013-06-18</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for confusion learning 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="11115423791114309291">
              <a href="/scholar/11115423791114309291"><span itemprop="scholarAuthors">Sznitman et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2010">2010</time>
            
          </td>
          <td itemprop="title">Active testing for face detection and localization</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/CN101965729A/en">
                <span itemprop="publicationNumber">CN101965729A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2011-02-02">2011-02-02</time>
            
            
          </td>
          <td itemprop="title">Dynamic object classification 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/JP2006350645A/en">
                <span itemprop="publicationNumber">JP2006350645A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2006-12-28">2006-12-28</time>
            
            
          </td>
          <td itemprop="title">Object detection device and learning device for the same 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="6438993040212686070">
              <a href="/scholar/6438993040212686070"><span itemprop="scholarAuthors">Triantafillou et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2017">2017</time>
            
          </td>
          <td itemprop="title">Few-shot learning through an information retrieval lens</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2012-04-05">2012-04-05</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">HRL LABORATORIES, LLC, CALIFORNIA</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CHENG, SHINKO Y.;CHEN, YANG;KHOSLA, DEEPAK;AND OTHERS;SIGNING DATES FROM 20120229 TO 20120405;REEL/FRAME:027999/0594</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2014-06-11">2014-06-11</time></td>
          <td itemprop="code">STCF</td>
          <td itemprop="title">Information on status: patent grant</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">PATENTED CASE</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2014-12-23">2014-12-23</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">DARPA, VIRGINIA</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">CONFIRMATORY LICENSE;ASSIGNOR:HRL LABORATORIES, LLC;REEL/FRAME:034695/0941</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Effective date</strong>:
              <span itemprop="value">20120828</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2017-12-14">2017-12-14</time></td>
          <td itemprop="code">MAFP</td>
          <td itemprop="title">Maintenance fee payment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Year of fee payment</strong>:
              <span itemprop="value">4</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>
</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script async="" defer="" src="//www.google.com/insights/consumersurveys/async_survey?site=cxkjf7ipxgbnnjy6k35ezcvbbe"></script>
  </body>
</html>
